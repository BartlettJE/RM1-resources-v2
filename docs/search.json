[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MSc Research Methods 1 Course Information",
    "section": "",
    "text": "Overview\nBook Name: MSc Research Methods 1 Course Information.\nSummary: Key course information such as assessments and lab resources for the Research Methods 1 course on the MSc Psychology conversion at the University of Glasgow School of Psychology & Neuroscience.\nAuthors: James Bartlett, Helena Paterson, & Thinh Pham.\nAim: This course covers introduces students to quantitative research methods in psychology. This is an accompanying book to the course to outline assessments, resources, and lab materials in one place.\nContact: This book is a living document and will be regularly checked and updated. Should you have any issues using the book or queries, please contact James Bartlett or Thinh Pham.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "01-Course_overview.html",
    "href": "01-Course_overview.html",
    "title": "1  Course Overview",
    "section": "",
    "text": "1.1 Intended Learning Outcomes\nBy the end of the course, you will be able to:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Overview</span>"
    ]
  },
  {
    "objectID": "01-Course_overview.html#intended-learning-outcomes",
    "href": "01-Course_overview.html#intended-learning-outcomes",
    "title": "1  Course Overview",
    "section": "",
    "text": "Understand and apply the principles of open and reproducible science;\nGenerate and explore hypotheses and research questions for experimental and observational research;\nSelect appropriate research designs and methodologies for different research questions;\nDemonstrate critical awareness of the assumptions of these methods and analyses and the limitations associated with experimental and observational research designs;\nIdentify the ethical issues involved in experimental and observational research;\nWork as a group to plan and execute a small-scale research project using quantitative research methods;\nDemonstrate critical analysis, evaluation, and synthesis of ideas;\nUse the programming language R to conduct a range of descriptive and inferential statistics.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Overview</span>"
    ]
  },
  {
    "objectID": "01-Course_overview.html#assessments",
    "href": "01-Course_overview.html#assessments",
    "title": "1  Course Overview",
    "section": "\n1.2 Assessments",
    "text": "1.2 Assessments\n\n\nMCQs (5%)\n\nAnswer Multiple Choice Questions (MCQs) related to content covered in weeks 1-4 including lectures, data skills sessions, and labs.\n\n\n\nData skills portfolio (15%)\n\nTwo data skills worksheets using R/RStudio, each worth 7.5%.\n\n\n\nStage 1 group report (30%)\n\nGroup submission of a planned introduction and method to answer a research question you develop.\n\n\n\nStage 2 individual report (50%)\n\nIndividual submission of a reproducible research report containing an abstract, results, and discussion that address the research question you developed in your group.\n\n\n\nPlease check the Assessment and Feedback Information Sheet chapters for detailed information and deadlines.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Overview</span>"
    ]
  },
  {
    "objectID": "01-Course_overview.html#course-overview",
    "href": "01-Course_overview.html#course-overview",
    "title": "1  Course Overview",
    "section": "\n1.3 Course overview",
    "text": "1.3 Course overview\nBelow is a provisional timetable for this course to show you what we will cover in the lecture, lab, research skills and data skills each week, in addition to where your assessments will be. We will notify you of any changes in advance, but feel free to read ahead to help you plan:\nDownload this Word file: PSYCH5088 RM1 Timetable\nLast updated: 25/07/2025",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Overview</span>"
    ]
  },
  {
    "objectID": "01-Course_overview.html#available-support",
    "href": "01-Course_overview.html#available-support",
    "title": "1  Course Overview",
    "section": "\n1.4 Available support",
    "text": "1.4 Available support\nThere is a lot of support in this course to help you build your knowledge and understanding of quantitative research methods and statistics. You do not have to use all the different sources of support, and some will work better for you than others will. Part of learning is about finding what helps you best. Below are a few of the main approaches we have on this course to help you and if in doubt, please just ask:\n\nWeekly lab sessions with your tutor with time for questions in each lab;\nGraduate Teaching Assistant (GTA) support sessions in-person and online;\nRM1 Teams channel for discussion, questions, and support;\nStudent Office Hours (sometimes called Student Drop-in Hours) - just turn up and ask your course leads of lab lead anything;\nAssessment information sheets and common questions and answer documents to support assignments.\n\nThe best approach is to write down your questions when they come up, check the available material for answers, and if you are still unsure after that, use one of the approaches above.\nHowever, please note we would ask that you do not send questions, either about a topic or an assignment, as a direct message on Teams to an individual staff member. While we always want to help, this approach is not sustainable and there is a highly likely chance your question will get missed and go unanswered. We would strongly encourage you to post the question on the course Team channel, as that way staff and students have the opportunity to answer your question, and other students can benefit from the answer. Alternatively, use the student office hours or your lab sessions to ask questions more privately.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Overview</span>"
    ]
  },
  {
    "objectID": "01-Course_overview.html#gta-data-skills-support-sessions",
    "href": "01-Course_overview.html#gta-data-skills-support-sessions",
    "title": "1  Course Overview",
    "section": "\n1.5 GTA data skills support sessions",
    "text": "1.5 GTA data skills support sessions\nBuilding your data skills primarily comes from self-directed learning as you work through the Fundamentals of Quantitative Research Methods book we have developed. These walk through learning R/RStudio and applying data skills such as wrangling data, visualisation, and inferential statistics. There are also walkthrough videos for most of the chapters and several check-in labs over the semester dedicated to data skills. However, we appreciate you may have questions or encounter errors you cannot work out on your own. That is why we schedule weekly support sessions with our GTAs.\nThe GTA support sessions are drop-in sessions, meaning they are not timetabled classes you must attend. They are there to go to if you have a problem, and you can come and ask questions. Our GTAs may demonstrate techniques or how to fix problems, but they are not intended to be chapter walkthroughs. The idea is you engage in self-directed study, and then you can come to the support sessions if you encounter problems.\nEarly in the semester, the support sessions have open invites. This means anyone can drop in and there might be a handful of students present and asking questions. However, as we approach key assessment periods, the sessions will have specific sign up slots to ensure the GTAs can provide clearly defined equitable time to each sign-up.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Overview</span>"
    ]
  },
  {
    "objectID": "01-Course_overview.html#believe-in-yourself",
    "href": "01-Course_overview.html#believe-in-yourself",
    "title": "1  Course Overview",
    "section": "\n1.6 Believe in yourself!",
    "text": "1.6 Believe in yourself!\nOur students have an extremely diverse range of backgrounds, so we assume the knowledge and skills we will help you to learn are new to everybody. The phrase we hear most often is: “everyone else must already know this?!”. If you already knew the content, you would not be on this course or programme. Some of you come from a science background while some of you do not, but no one has covered this combination of quantitative research methods in psychology.\nIt might be challenging and take some trial and error, but every single one of you can do this. Research methods and statistics might not be everyone’s favourite course, but it is our job to convince everyone that you can do it and it is a critical part of psychology training.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Overview</span>"
    ]
  },
  {
    "objectID": "01-Course_overview.html#acknowledgements",
    "href": "01-Course_overview.html#acknowledgements",
    "title": "1  Course Overview",
    "section": "\n1.7 Acknowledgements",
    "text": "1.7 Acknowledgements\nWe put a lot of effort into creating the resources in this book, but occasionally typos or broken links will slip through. When a student helps us and highlights an error or makes a suggestion, we like to acknowledge it. We would like to thank the following students for helping us:\nYee Lam So.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course Overview</span>"
    ]
  },
  {
    "objectID": "02-Resources.html",
    "href": "02-Resources.html",
    "title": "2  Course Resources",
    "section": "",
    "text": "2.1 Fundamentals of Quantitative Analysis\nTo support this course, we have the Fundamentals of Quantitative Analysis book which teaches you data skills in R/RStudio, like programming basics, data wrangling, visualisation, and inferential statistics. We work through chapters 1 to 11 in RM1, then you will continue with chapters 12 to 14 in RM2.\nData skills takes time and trial and error to learn. We direct you to one or two chapters per week to develop your initial skills. Each chapter has a range of “try this” activities to apply what you learnt and check your answers against solutions. We also have “error mode” activities to get you used to making errors in coding. This can be the most intimidating part of learning to code but experienced coders do not stop making mistakes, they just get better at diagnosing and fixing their mistakes. Finally, we have data analysis journey chapters. These provide longer less structured activities to get you wrangling, visualising, and/or analysing data sets. These are meant as the bridge between the core chapters to your assessments where you no longer have solutions to check your answers against.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Course Resources</span>"
    ]
  },
  {
    "objectID": "02-Resources.html#handy-workbook",
    "href": "02-Resources.html#handy-workbook",
    "title": "2  Course Resources",
    "section": "\n2.2 Handy workbook",
    "text": "2.2 Handy workbook\nAn additional resource we will link to time to time is A Handy Workbook for Research Methods & Statisticsby Phil McAleer. From around week 6, we will introduce you to inferential statistics. When you use these practically, you will use R/RStudio to efficiently analyse larger amounts of data. The Handy Workbook works through step-by-step how these statistical tests work on a small data set, so you can gain a better understanding of what numbers go in, what happens to those numbers, and what numbers come out.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Course Resources</span>"
    ]
  },
  {
    "objectID": "02-Resources.html#course-reading-list",
    "href": "02-Resources.html#course-reading-list",
    "title": "2  Course Resources",
    "section": "\n2.3 Course reading list",
    "text": "2.3 Course reading list\nTo support each week, there is a course reading list which is linked on the Moodle page, but you can access it by following this link. We appreciate you only have so much time each week and have other courses to complete, so the resources are labelled as essential, recommended, and further.\nEssential sources are those that we have curated to directly supplement the lecture and lab material, and you should do your best to keep up with reading these each week.\nRecommended sources are those that we think are useful and supplement the course, but you should only read them if you have time.\nFurther sources are those we find interesting and provide a deeper dive if you find you really enjoy the content in this course, or they might be useful for future reference like when you reach your dissertation.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Course Resources</span>"
    ]
  },
  {
    "objectID": "03-Employability.html",
    "href": "03-Employability.html",
    "title": "3  Employability Skills and Knowledge",
    "section": "",
    "text": "3.1 Graduate destinations\nAt the start of your degree, we recommend pretending you are looking for a job tomorrow. You are not locked into a decision but looking early means you can explore what essential and desirable criteria they list on person specifications. If you wanted that job tomorrow and you do not possess several criteria, your odds of getting an interview are slimmer. However, if you check the criteria a year in advance of when you are applying for jobs, it gives you the time to develop your skills and knowledge for when you will be in that position.\nFor some resources, the British Psychology Society (BPS) outline career options in psychology. Predictably, they are psychology-focused and you are probably at least interested in a psychology career since enrolled in this degree. However, a sizable number of graduates do not work in psychology once they graduate. The BPS career destinations survey (2017) reported that 67% of respondents needed a psychology degree for their current job, while 60% had a job in the field of psychology. On the other hand, a Jisc and Prospects report (2024) on what graduates do reported a much wider range of jobs. The highest percentage (page 96) for graduates with a psychology degree include childcare, health, and education; legal, social, and welfare; clerical, secretarial, and numerical clerks; health professionals; and smaller numbers of business, HR, and science professionals.\nA psychology degree can take you lots of places within and outside the field of psychology, so it is important you can identify the skills and knowledge you have. Before we move onto graduate attributes and skills/knowledge mapping, one thing to keep in mind is your position as an MSc conversion students. You simply do not have the time to reach the depth and breadth in one year that an undergraduate psychology student can achieve in three or four years. However, your unique selling point will be your combination of the conversion degree with your previous degree and experience. Many of our MSc conversion students have already completed years in the workplace, so keep this in mind when job criteria ask for related work experience, as that might be the thing that sets you apart from other applicants.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Employability Skills and Knowledge</span>"
    ]
  },
  {
    "objectID": "03-Employability.html#graduate-attributes",
    "href": "03-Employability.html#graduate-attributes",
    "title": "3  Employability Skills and Knowledge",
    "section": "\n3.2 Graduate attributes",
    "text": "3.2 Graduate attributes\nThe University of Glasgow lists graduate attributes which are the academic abilities, personal qualities, and transferable skills that all graduates can develop over their degree at the university. We recommend reading over the document but they separate the attributes into:\n\nSubject specialists\nInvestigative\nIndependent and critical thinkers\nResourceful and responsible\nEffective communicators\nConfident\nAdaptable\nExperienced collaborators\nEthically and socially aware\nReflective learners\n\nYou can find more information on graduate attributes and opportunities available to you on the university Careers, Employability, and Opportunity page.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Employability Skills and Knowledge</span>"
    ]
  },
  {
    "objectID": "03-Employability.html#skills-and-knowledge-mapping-from-rm1",
    "href": "03-Employability.html#skills-and-knowledge-mapping-from-rm1",
    "title": "3  Employability Skills and Knowledge",
    "section": "\n3.3 Skills and knowledge mapping from RM1",
    "text": "3.3 Skills and knowledge mapping from RM1\nFor graduate level jobs, most of the person specification criteria are split into four sections:\n\nEducation\nExperience\nKnowledge\nSkills/abilities\n\nFor example, if you look at jobs.ac.uk for psychology jobs, they are mainly academic roles where you would be in the position to apply for something like a research assistant as you graduate. They would ask for a psychology degree (or related) under education, relevant experience such as working with patients/participants, relevant knowledge dependent on the role like research design or neurodiversity, and skills/abilities such as computer skills, data analysis software, and writing skills.\nIn RM1, we break the course down into three types of skills: subject knowledge, research skills, and data skills. Note the items within each type of skills is a non-exhaustive list for demonstration purposes. As you move through RM1 (and other courses on the degree), we recommend keeping a note of everything you do to refer back to once you start applying for jobs.\n\nFor example, you will learn about research design and statistics for subject knowledge, literature review tools and reference managers for research skills, and using R/RStudio to wrangle, visualise, and analysis data for data skills.\nWe can further break things down for what skills and knowledge you will learn, develop, and demonstrate in the process of completing each assessment on the course:\n\n\n\n\n\n\n\n\nAssessment\nSubject knowledge\nResearch skills\nData skills\n\n\n\nMCQ\nResearch design; Measurement; Probability; Philosophy of science; Metascience; Statistics\nEthics\nRStudio functionality\n\n\nData skills 1\nStatistics\n\nReproducible workflows; Data wrangling; Data visualisation\n\n\nData skills 2\nStatistics\n\nReproducible workflows; Data wrangling; Data visualisation; Data analysis\n\n\nStage One Group Report\nResearch design; Measurement; Subject-specific domain knowledge; Statistics\nEthics; Literature reviewing; Critical evaluation; Academic communication; Computer skills; Team work\n\n\n\nStage Two Individual Report\nResearch design; Measurement; Subject-specific domain knowledge; Probability; Statistics\nLiterature reviewing; Critical evaluation; Academic communication; Computer skills\nReproducible workflows; Data wrangling; Data visualisation; Data analysis",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Employability Skills and Knowledge</span>"
    ]
  },
  {
    "objectID": "03-Employability.html#example-job-specification-criteria",
    "href": "03-Employability.html#example-job-specification-criteria",
    "title": "3  Employability Skills and Knowledge",
    "section": "\n3.4 Example job specification criteria",
    "text": "3.4 Example job specification criteria\nAs a final demonstration, we have taken a real job advert for a research assistant position to outline the kind of skills/knowledge they are looking for, and highlighting whether you will develop it in RM1, your conversion degree, or whether you would need further development.\n\nAn undergraduate degree that has relevance to the project. BPS accredited undergraduate degree in Psychology (desirable).\n\nThis post is multi-disciplinary, so they invite candidates from a range of subjects. However, a BPS-accredited degree is listed as desirable, so the skills and subject knowledge are beneficial. Keep in mind sometimes people do not quite know how to classify an MSc Conversion degree, so you can explain in the cover letter your degree provided BPS-accreditation.\n\nUnderstanding of behavioural research methods and questionnaire design and analysis.\n\nIn RM1, you learn about different quantitative research methods and designing/analysing questionnaire data for your research report. Supplementing this with RM2 and your dissertation would tick off this criterion.\n\nKnowledge of theories and research in traffic and transport psychology and/or behavioural change.\n\nThis is where the specification is asking for subject-specific domain knowledge. You would need to demonstrate this from another course, previous degree, upskilling, or your dissertation if the topic fits.\n\nAn awareness of ethical considerations for conducting research and knowledge of the BPS Code of Human Research Ethics.\n\nWe cover BPS human research ethics on RM1, so you would be able to demonstrate this in addition to RM2 and your dissertation.\n\nCompetence with Word, Excel, and PowerPoint\n\nIn RM1, you will mainly use Word and R Markdown for your stage one and stage two research reports. For data skills, you should have a basic understanding of spreadsheets but you might need to supplement this with further learning about Excel. For example, the university supports Coursera and LinkedIn learning courses if you need to upskill in Excel. We do not cover presentations in RM1, so you would need to demonstrate PowerPoint skills through other courses, previous experience, or upskilling.\n\nGood writing skills\n\nIn RM1, you will demonstrate good writing skills via your stage one and stage two report. You will then supplement this with essays, reports, and your dissertation elsewhere in the degree.\n\nBibliographic research skills\n\nTo support your stage one and stage two research reports, we cover literature review skills and using a reference manager as research skills within RM1. You will also be able to demonstrate this through other essays, reports, and your dissertation elsewhere in the degree.\n\nTime management and organisation of research/teaching schedules\n\nRM1 is a large course with several assessments, combined with all your other courses and commitments. So, you would be able to mention managing multiple assessments and courses in your degree. For organising research/teaching schedules, this will be related to your dissertation and previous/future experience as this job role has potential teaching responsibilities.\n\nConfident communication styles\n\nWe already covered writing skills but oral communication is not something you would be able to demonstrate from RM1 specific to assessments. The stage one report does involve team work though, so you would able to link communicating and problem-solving with a diverse group.\n\nCompetence with standard analytical packages, such as R Studio (Desirable)\n\nIt is a desirable criterion but this position specifically mentions using RStudio. We directly cover data skills using R/RStudio so you would be able to tick this off alongside RM2 and your dissertation.\n\nCompetence with Adobe software including Photoshop, Premiere Pro and After Effects (Desirable).\n\nIt is a desirable criterion but this is not something we cover on the degree. So, you would need to upskill yourself and maybe you have experience using Photoshop from a previous degree or job role. This is a pretty unusual request for a psychology research assistant position, so this is where as an MSc Conversion student your previous degree or work experience might occasionally provide a unique selling point.\n\nExperience in presenting to an audience\n\nWe do not cover presentations on RM1, so you will need other courses involving presentations and previous/future experience to tick off this criterion.\n\nExperience in conducting and management at least one project, collecting and analysing data, and writing a report.\n\nIn RM1, you plan a research project in a team for your stage one report, and analyse data and write a stage two report. You will also write a full research report in RM2. You will not collect data yourself in RM1, but you will for your dissertation if you use primary data.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Employability Skills and Knowledge</span>"
    ]
  },
  {
    "objectID": "04-AIS-01-groupagreement.html",
    "href": "04-AIS-01-groupagreement.html",
    "title": "4  Group Work Agreement",
    "section": "",
    "text": "4.1 General information\nWe use the group work agreement to outline how you and your group will work and communicate with each other, and ensure you are engaging in the group work process for the stage 1 group report. Groups typically experience problems when communication and task responsibilities are built on unspoken assumptions. As you probably do not know the people in your group when we make the allocations, we start the project by facilitating a discussion with you and your group so you can openly outline how you will communicate, respect diversity, and split tasks.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Group Work Agreement</span>"
    ]
  },
  {
    "objectID": "04-AIS-01-groupagreement.html#general-information",
    "href": "04-AIS-01-groupagreement.html#general-information",
    "title": "4  Group Work Agreement",
    "section": "",
    "text": "This is a formative task and is not part of the summative assessment for the course, but everyone must complete the task. We use the group work agreement as a way of identifying engagement and potential problems as early as possible. The course or programme leads will contact students who do not submit their group work agreement and students will potentially be placed on an individual submission if they do not engage with their groups.\nThe deadline is October 10th 2025, where everyone in the group must submit an individual copy of the agreement on Moodle.\nAlthough you will agree on the document as a group, each group member must then individually sign (electronic or a printed name, you do not need to physically sign it) and upload a copy to the submission portal.\nYou should submit a single Word document (.docx) or PDF document to Moodle prior to the deadline. The submission link is open from when the group allocations are available in week 2. You can find the submission portal in the Formative: Allocations and group work agreement submission tab.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Group Work Agreement</span>"
    ]
  },
  {
    "objectID": "04-AIS-01-groupagreement.html#group-agreement-items",
    "href": "04-AIS-01-groupagreement.html#group-agreement-items",
    "title": "4  Group Work Agreement",
    "section": "\n4.2 Group agreement items",
    "text": "4.2 Group agreement items\nThe group work agreement template (available for download in the RM1 Formative: Allocations and group work agreement submission tab) contains five points that we have set, but you may add any additional points that the group agrees.\nThe mandatory points are:\n\nAs a student of the University of Glasgow, I will treat all members of my group with dignity and respect.\nI have read and agree to abide by the Student code of conduct and the Dignity at work and study policy.\nWe all agree to communicate with each other openly and tell the course leads well in advance should any issues arise.\nWe all agree to use a group chat on Microsoft Teams as our main electronic channel of communication.\nWe all agree to contribute to the group project and complete the assigned tasks by a deadline agreed by the group.\nWe all agree that if AI tools are used in any part of the Stage 1 report, this will be discussed within the group, acknowledged transparently, and each member will take responsibility for ensuring that the final submission meets academic integrity standards in line with the University of Glasgow’s policies.\n\nIn addition, there may be other elements of group work that you and your group want to include. You are welcome to create your own additional items but here is a list of potential items you may want to discuss with your group and add to the document:\n\nWe all agree to establish a common timeline for the project and discuss any deviations from the timeline together as a group.\nWe all agree to communicate with each other openly and honestly about the project and get in touch with the course leads in the event of an unsolvable group conflict.\nWe all agree to respect each other’s individual ways of working and discuss these openly as a group.\nWe all agree to respect diversity in our group. This includes cultural differences, neurodiversity, different work/life situations and may manifest in different ways of working/approaching tasks. We agree to discuss our strengths as a group and divide tasks accordingly.\nI agree to stay in touch with the group and communicate as established by the group. If I am struggling and I do not feel comfortable sharing that with the group, I will get in touch with the course/programme leads for support.\nWe all agree to meet on a regular basis as established by the group. If I cannot make a meeting I agree to communicate this openly with my group and get in touch to catch up about things I have missed.\nWe agree to plan out the individual contribution of each team member in advance before group work starting and openly communicate any changes that may arise during the project.\nWe agree to establish the best method of communication for our group that’s inclusive and takes into account everybody’s individual needs.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Group Work Agreement</span>"
    ]
  },
  {
    "objectID": "04-AIS-01-groupagreement.html#group-work-advice",
    "href": "04-AIS-01-groupagreement.html#group-work-advice",
    "title": "4  Group Work Agreement",
    "section": "\n4.3 Effective group work advice",
    "text": "4.3 Effective group work advice\nBelow are some suggestions to organise and manage your group project for the stage 1 report. You are welcome to adapt some of these guidelines to suit your group and the nature of the project. Group work is a critical part of the BPS standards and every workplace will involve some element of splitting a larger output into smaller components for each member to work on. We use the group work agreement process and these guidelines to suggest different ways of working and you can choose the most effective set that suites your group. However, in the event we need to mediate difficulties, this will involve you providing evidence as record/evidence of collaboration (or lack thereof). Please be mindful of this when conducting your project.\nSet up your group Teams chat/channel and a Microsoft Planner for your group\n\nCreate a Teams chat for communication with your group. This part is non-negotiable as it is the university approved communication system which all students have access to.\nConsider creating a Microsoft Planner with all members of your group to assign individual tasks.\n\nCoordinate work schedules/calendars\n\nBe open about when you can meet/study, if you have a busy period coming up, or might be unavailable.\nSchedule a regular ‘check-in’ time. This does not need to be a live meeting but stay connected regularly.\n\nAgree on document collaboration platforms\n\nWe recommend having a shared OneDrive folder or sharing documents within your Teams channel using the files tab.\nConsider using track changes and comments on shared documents when editing to avoid immediately overwriting other people’s work.\nThink about a shared Zotero library to organise papers from your literature review.\n\nWork back from the deadline to create milestones\n\nAgree on specific dates to complete your responsibilities. Life happens though, so make sure you communicate with your group if you are falling behind and you can discuss revised deadlines.\n\nDetermine strengths and assign roles\n\nConsult the Stage 1 group work contributor section below to identify the strengths/preferences of your team.\nRemember though: we expect most of the course content to be new or you would not be enrolled on this degree. You will often need to go outside your comfort zone to develop.\n\nAssign tasks/milestones to roles\n\nAttach names and dates to tasks and assign milestones using something like Microsoft Planner.\nReassign tasks/adjust deadlines as the project progresses if you need to.\n\nCommunicate, communicate, communicate\n\nCheck-in regularly. Everyone will understand if there was a delay in completing a task but the most problematic thing for group dynamics is not keeping everyone up to date with progress and delays.\nAgree to action points at the end of meetings and put these in writing (e.g., in a shared document / to-do list). It is super easy to forget what you discussed, so make sure you keep a note to refer to after meetings.\nThe content is new for everyone and you have a lot to learn in a short space of time, so be kind and compassionate (to yourself and others).\n\nSubmit your assessment\n\nAssign one person to prepare and submit the final documents when everyone has approved them. Remember to turn off track changes and delete any comments.\nGive yourself time to look at the Turnitin Report and factor in editing time.\n\n\n4.3.1 Points about inclusivity\nLanguage: Many/most students in this programme are studying in their second, third, or even fourth language. Consider the challenges you might experience if you were studying beyond your first language and be mindful of making implicit judgements about someone’s writing or communication.\nTiming/working patterns: Be mindful that everyone’s work/life balance and commitments are different. Some people prefer studying during traditional working hours, some in the evenings, and others on weekends. Communicate your preferences openly and as a group be as flexible and accommodating as you can. Can the times/days of meetings be flexible if this helps everyone contribute and feel engaged?\nTechnology: The technology/platforms we recommend might not be your favourites, but we recommend them for a reason. These are things we can directly support, and they are the things that we make sure all students in different countries can access. Using some apps/tools can explicitly exclude some members that want to engage and contribute.\nNeurodiversity: Different people work and think in different ways. If someone discloses that they find particular things challenging, or that they are at their best with a particular type of task or activity, consider how you can support/reflect this in the allocation of roles and tasks.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Group Work Agreement</span>"
    ]
  },
  {
    "objectID": "04-AIS-01-groupagreement.html#stageone-planning",
    "href": "04-AIS-01-groupagreement.html#stageone-planning",
    "title": "4  Group Work Agreement",
    "section": "\n4.4 Stage 1 group work task sharing advice",
    "text": "4.4 Stage 1 group work task sharing advice\nAs you start working in your groups, one key decision will be sharing out the tasks equitably. In the stage 1 report template, there are several sections and sub-sections to complete, and there is a lot of hidden ground work that goes into writing those sections. For each component, try to summarise the following when you first meet with your group:\n\nWhat information have you already established in that section?\nWhat do you still need to think about for that section?\nHow are you going to find answers to the things you do not yet know?\n\nFor example, you might say for the rationale, research question, and hypothesis component of the introduction:\n\nWhat have you already established?: So far, we know the research question and the hypothesis, and we have a general summary of relevant papers written by the team.\nWhat do we still need to think about?: We do not yet have a fully formed rationale or a solid understanding of the general overview.\nHow will you find answers to things you do not yet know? Helena, James, and Ashley will read the papers that have already been collected and the general literature review. From there, they will try to summarise the rationale so that it builds on what previous research has found. They will then present that to the group for further revision and discussion.\n\nOnce you have done that for each section, go through and answer the following question: Who will lead on each section?\nEach group member should make an equal contribution, but this does not mean every group member works on every section. Some sections might work better with one person leading and another editing, while other sections might work better with several people leading and editing.\nThe introduction is a larger section with fewer clearly segmented tasks, whereas the method is shorter with clearly defined sub-sections. It is important you understand all aspects of the project, so we recommend if you work on writing the introduction, you edit or at least proof-read the method, and vice versa.\nFor example, you might separate the tasks as:\n\nIntroduction literature review: Phil, Helena, and Ashley will lead on this section.\nIntroduction rationale, research question, and hypothesis: Helena, James, and Ashley will lead on this section.\nMethod participants: James and Phil will lead on this section.\nMethod materials: James and Wil will lead on this section.\nMethod procedure: Ashley and Sarune will lead on this section.\nMethod design and data analysis: Sarune and Wil will lead on this section.\n\nYou might choose to separate the tasks differently, but this is one suggestion to work through. For this separation or another approach you agree in your group, question what you know, what you still need to think about, and how you will fill in the blanks. If it helps, you can download this template to structure your group discussions.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Group Work Agreement</span>"
    ]
  },
  {
    "objectID": "04-AIS-02-MCQ.html",
    "href": "04-AIS-02-MCQ.html",
    "title": "5  MCQ",
    "section": "",
    "text": "5.1 General information\nYou must answer a set of 22 multiple-choice questions that relate to the course content covered in weeks 1-4. This includes lectures, labs, data skills, and research skills.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>MCQ</span>"
    ]
  },
  {
    "objectID": "04-AIS-02-MCQ.html#general-information",
    "href": "04-AIS-02-MCQ.html#general-information",
    "title": "5  MCQ",
    "section": "",
    "text": "In total, this assessment is worth 5% of your final course grade.\nThe deadline for submitting the MCQ is October 24th 2025.\nYou will have two attempts to complete the quiz and the highest grade will count. So that you get a good sense of where your knowledge and skills are at, please complete the first attempt without referring to any notes, the textbook, or any AI tools. On the second attempt, you can use whatever resource you want. The reason we have done this is to provide a safety net so that you can check your learning without the pressure of it affecting your grade.\nThe quiz will open one week prior to the deadline, so you can complete the quiz in your own time. However, during each attempt, you must start and finish the quiz in one sitting. Once you start, you must finish.\nYou have a total of 30 minutes to complete each sitting but you may find that you do the quiz much quicker than that, and that it completely fine. If you are registered with disability services and have an adjustment, you will be given extra time to complete the quiz depending upon your adjustment. If you think you should have extra time but it is not showing on Moodle, please contact James or Thinh before starting the quiz.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>MCQ</span>"
    ]
  },
  {
    "objectID": "04-AIS-02-MCQ.html#how-to-do-well-in-this-assessment",
    "href": "04-AIS-02-MCQ.html#how-to-do-well-in-this-assessment",
    "title": "5  MCQ",
    "section": "\n5.2 How to do well in this assessment",
    "text": "5.2 How to do well in this assessment\n\nKeep up with the course content on a weekly basis.\nComplete the essential reading for each lecture.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>MCQ</span>"
    ]
  },
  {
    "objectID": "04-AIS-02-MCQ.html#common-mistakes",
    "href": "04-AIS-02-MCQ.html#common-mistakes",
    "title": "5  MCQ",
    "section": "\n5.3 Common mistakes",
    "text": "5.3 Common mistakes\n\nNot keeping up with the lecture content and reading.\nFailing to read the question carefully.\nFailing to answer all questions.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>MCQ</span>"
    ]
  },
  {
    "objectID": "04-AIS-02-MCQ.html#why-am-i-being-assessed-like-this",
    "href": "04-AIS-02-MCQ.html#why-am-i-being-assessed-like-this",
    "title": "5  MCQ",
    "section": "\n5.4 Why am I being assessed like this?",
    "text": "5.4 Why am I being assessed like this?\n\nTesting your knowledge of the course content helps you actively engage with the material, meaning you will learn more.\nDistributed practice is important for learning, so we have a few low-stakes assessments early in the course to encourage you to keep up with the content, while being low weighted to reduce the pressure on your overall course grade.\nEngaging with the material on the course will help build a strong foundation for the rest of the RM1 course and your subsequent assessments.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>MCQ</span>"
    ]
  },
  {
    "objectID": "04-AIS-02-MCQ.html#academic-integrity",
    "href": "04-AIS-02-MCQ.html#academic-integrity",
    "title": "5  MCQ",
    "section": "\n5.5 Academic Integrity",
    "text": "5.5 Academic Integrity\nPlease note that when submitting your work for assessment we accept it on the understanding that it is your own effort and work and unique to the set assignment.\nTo support you in understanding what plagiarism is and in avoiding it, please read the following resources that the University provides:\n\nSRC Advice and Support.\nCode of Student Conduct and Plagiarism Statement.\nAvoiding plagiarism and engage in good academic practice (a Moodle course you can self-enrol in).\nStudent support for AI, plagiarism, and digital skills.\n\nStatement on groupwork: We encourage students to form a study group and peer feedback groups. However, this assignment is not a group work assignment, so your work must be your own individual contribution. If you make a study group or a peer review group, avoid sharing your final answers.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>MCQ</span>"
    ]
  },
  {
    "objectID": "04-AIS-02-MCQ.html#ai-statement",
    "href": "04-AIS-02-MCQ.html#ai-statement",
    "title": "5  MCQ",
    "section": "\n5.6 AI Statement",
    "text": "5.6 AI Statement\nThe University of Glasgow recognises the value of generative artificial intelligence tools in academic and professional workplaces. The university has a responsibility to ensure that students acquire the necessary knowledge, skills and other competencies associated within their discipline. The Student Learning Development service provides general guidance and support for students on the use of generative AI, but each item of assessment in your courses will have specific generative AI guidance about use and misuse in place. Where generative AI restrictions are in place, they have been carefully designed to maximise your learning opportunity whilst discouraging reliance on generative AI in a way that undermines your learning, or development of good professional practice and graduate attributes.\nStatement on use of generative AI: The current assessment is summative, meaning that it contributes to your course grade. The generative AI use for this assessment is categorised as amber and use of generative AI is allowed for some tasks during the preparation of the assessment.\nThere is no expectation that you will use generative AI and we have no evidence that it’s use will confer an advantage for this assessment. The purpose of this assessment is to encourage continuous learning over the semester and check your understanding in a low-stakes assessment. The MCQ has a low course grade percentage to reduce pressure and let you focus on learning. Taking short-cuts now will not provide an accurate overview of your understanding and skill development.\nIf you do use generative AI tools, we recommend using it for the following (non-exhaustive) kind of tasks:\n\nClarify complex concepts and reinforce understanding around intended learning outcomes.\nPlan a revision schedule.\nGenerate practice quizzes and questions.\n\nIf you do use generative AI tools, we strongly recommend not using it for the following (non-exhaustive) kind of tasks:\n\nRelying on AI tools for understanding key concepts.\nHelping you to answer the questions.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>MCQ</span>"
    ]
  },
  {
    "objectID": "04-AIS-02-MCQ.html#feedback-information",
    "href": "04-AIS-02-MCQ.html#feedback-information",
    "title": "5  MCQ",
    "section": "\n5.7 Feedback information",
    "text": "5.7 Feedback information\n\n5.7.1 How is this assessment graded?\nThe MCQ has 22 questions with each question being worth 1 point. Your grade will be converted into an alphanumeric grade on the standard 22-point scale (e.g., a score of 16 = B2).\n\n5.7.2 What type of feedback will I receive for this assessment?\nOnce the quiz has closed for all students, you will be able to see which questions you got right and wrong, what the correct answer was, and your overall grade.\n\n5.7.3 Who assessed my work?\nThe MCQ is scored automatically within Moodle. The course leads created and proof read the quiz to ensure the scoring is accurate.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>MCQ</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html",
    "href": "04-AIS-03-dataskills.html",
    "title": "\n6  Data Skills\n",
    "section": "",
    "text": "6.1 General information\nOver two data skills assignments, you will work on an R Markdown template which includes a series of tasks such as general statistical knowledge questions, data wrangling, visualisation, descriptive and inferential statistics, and interpretation questions.\nWe will not ask you anything that has not been covered yet in either the lectures or the Fundamentals of Quantitative Analysis data skills book. For example, data skills 1 would focus on material from weeks 1 to 5, and would not expect you to know content covered after reading week in week 7 or later.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#general-information",
    "href": "04-AIS-03-dataskills.html#general-information",
    "title": "\n6  Data Skills\n",
    "section": "",
    "text": "In total, this assessment is worth 15% of your final course grade. Each submission is worth 7.5% and you will be awarded a mark out of 22.\nIn each assessment, each question will be worth 1 or 2 marks to sum to the University of Glasgow 22-point Schedule A scale.\nData Skills Assignment 1 deadline: November 7th 2025.\nData Skills Assignment 2 deadline: November 28th 2025.\nThere will be separate submission links for each assignment where you will submit a single .Rmd file. You should only submit the .Rmd file containing your answers.\nWe will release the assignment and open the submission link at least one week before the deadline.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#assessment-support",
    "href": "04-AIS-03-dataskills.html#assessment-support",
    "title": "\n6  Data Skills\n",
    "section": "\n6.2 Assessment support",
    "text": "6.2 Assessment support\n\nAll the coding tasks will have been covered in the data skills book and the activities within the book. Theoretical and interpretation tasks will have been covered in the lectures, labs, and/or data skills book.\nFor coding tasks, it is important to try the code in the book as you go along and ask questions about what you are doing. This will really help you in the assignments.\nYou are free to ask questions regarding the assignment on the available forums, in-class, or in student office hours. However, please do not post answers or code that would be close to giving the answer as this would contravene the University policy on plagiarism. You can see policies on how to use the forums on the RM1 Moodle page. If a member of the team needs to see the code you are trying, they will ask you for it.\nTo reiterate: you are allowed to post code when asking questions about a task in the Fundamentals of quantitative analysis data skills book, but you should not post code relating to a question about either of the data skills assignments unless a member of staff asks you.\nWhen submitting the file, make sure that you submit the completed .Rmd file for that assignment only. You must include your GUID in the filename, followed by ‘MSc_RM1’ and the assignment Number. The template file includes this information as a template, but your final file name should look like, for example, ‘9804672_MSc_RM1_DataSkills1.Rmd’.\nFurther information about the feedback you will receive for this assignment can be found in the Feedback Information Sheet section below.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#how-to-do-well-in-these-assignments",
    "href": "04-AIS-03-dataskills.html#how-to-do-well-in-these-assignments",
    "title": "\n6  Data Skills\n",
    "section": "\n6.3 How to do well in these assignments",
    "text": "6.3 How to do well in these assignments\n\nCompleting all course materials, formative assignments, and summative work on the practical data skills. All the assignments build on each other and information within the formative assignments will help to complete the summative assignments.\nUse the Fundamentals of Quantitative Analysis data skills book activities to guide you. In almost all cases (apart from where we highlight), the answers to the assignments require using skills that you have already covered in these materials.\nAvoid making changes to the .Rmd file other than to provide answers and your GUID (e.g., avoid deleting backticks, changing code chunk names, not using the file provided). If you edit the file in a way that affects how the .Rmd knits, such as deleting backticks or changing code chunk names, your submission may be invalid and be returned with a H grade.\nPlease pay special attention if the question asks for a specific output, e.g. value or a data frame. For example, when asked for a value as an output, make sure it is a single value and not a value stored in a data frame. Finally, when altering code inside the code blocks, do not re-order, rename, or remove the code blocks (e.g. T01, T02, etc.). If you do, this will impact your grade and may result in you receiving a H grade for this assignment. If you are unsure about any of these points, please ask a member of staff.\nRead the question carefully and ensure that you provide exactly what we ask you (e.g., code or a single value). Do not deviate from what the question asks. We encourage you to practice different approaches in your own time, but for these assignments you should only do what the questions ask.\nTest that the .Rmd file you are submitting is reproducible after completing it, by “knitting” it as a html file. This also shows what you have accomplished and allows you to spot potential errors. If your code does not knit, this may result in you receiving an H grade for this assignment, so please check carefully. Note we include a setting where it will still knit when there are errors to maximise the grade you receive, so read through the output carefully to check there are no errors.\nA great test of your code is to close R Studio, restart it, open and knit your code, see that it runs, and go through it to make sure you consider the answers to be correct. This will test whether you have remembered to include essential elements, such as libraries, in your code. This does not necessarily mean that your code is correct, only that your code runs. You need to check the output and compare to the question to see that it matches.\nWhen loading in data, you must use a relative path as opposed to an absolute path. Relative would mean having the data file in the same folder as the .Rmd file and just calling the data file when reading it in, e.g. read_csv(\"data.csv\"). Absolute would be using a path specific to the folder structure of your computer, e.g. read_csv(\"C:/JamesComputer/JamesFolder/data.csv\"). Only use relative paths and under no circumstances should you rename the data file from the one we tell you to use. The file name “data.csv” is different from “data (1).csv” and “data_1.csv”. Only use the name we give you.\nThe following functions are considered forbidden and must not appear anywhere in your code at all. Inclusion of them in your code may result in you receiving a H grade for the assignment. The functions are: install.packages(), help(), vignette(), setwd(),help.start(), or View().\nCollate your notes and learn from your mistakes. These assignments are weighted low to give you the space to make mistakes and to not have a major impact on your overall course grade. Try and take advantage of this opportunity to test your skill development and prepare you for the larger report components and your future dissertation.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#common-mistakes",
    "href": "04-AIS-03-dataskills.html#common-mistakes",
    "title": "\n6  Data Skills\n",
    "section": "\n6.4 Common Mistakes",
    "text": "6.4 Common Mistakes\n\nChanging the .Rmd file to something other than providing your answers and your GUID.\nChanging the name of the data file to something other than the one we provide – e.g., “data.csv” and “data (1).csv” are two different files.\nUsing code that is very different to that taught in the book. We will check any incorrect answers and if you have used different code that produces what is asked you will still get the mark, however, using different code from the book increases the risk that you will produce a different output to the one intended. We designed these tasks based on what we expect you will have learnt.\nFailure to follow instructions (e.g., writing code when we requested a single value).\nIncluding any forbidden code in your .Rmd file, e.g., install.packages(). You should never write code that would change something on someone else’s machine.\nWe always ask students to use the function read_csv() to load in data, yet students often use read.csv(). There is a difference between the output these create, so always do what the questions ask.\nBe very careful with spelling. For example, UK is not the same as Uk.\nNever do more than what the question asks. We check the output of a task to see that it matches what we expect. If it does not match what we expect, then it is wrong. Remember the point is about being reproducible and replicable. Think of this in terms of you are sending your work to a colleague who expects a certain thing, and if your code works differently, then that is not good practice.\nTry things out in the console and in your own scripts, but only put your final answers in the .Rmd.\nFailing to read your feedback from previous assignments.\nFailing to check that your code knits before submitting it.\nFailing to check that you are submitting the right file. Only one file is allowed per submission.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#how-is-the-assessment-related-to-the-lectures-for-this-course",
    "href": "04-AIS-03-dataskills.html#how-is-the-assessment-related-to-the-lectures-for-this-course",
    "title": "\n6  Data Skills\n",
    "section": "\n6.5 How is the assessment related to the lectures for this course?",
    "text": "6.5 How is the assessment related to the lectures for this course?\nThese practical data skills assignments assess your ability to wrangle and visualise data in an open and reproducible way, to interpret and work with data, to understand analysis and research methods, and to present studies in a professional manner, as discussed in the lecture series.\nWhile these assignments are of course most closely related to the Research Methods 1 lectures, understanding data and analysis will help with your critical evaluation of research in all fields of psychology. By understanding where the results come from, it will give you a much deeper approach to critically assessing the claims of research.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#why-am-i-being-assessed-like-this",
    "href": "04-AIS-03-dataskills.html#why-am-i-being-assessed-like-this",
    "title": "\n6  Data Skills\n",
    "section": "\n6.6 Why am I being assessed like this?",
    "text": "6.6 Why am I being assessed like this?\nThe practical data skills taught through these assignments are critical for psychological researchers to develop to understand analysis, methods, and research. Your skills will progress throughout your degree, but the best approach to developing these skills is through regular continuous assessment. Much like learning a language, more practice over a longer period of time will give you better results than cramming at the last minute. Continuous regular practice is better than one big chunk. As such, these assignments ensure that you are maintaining a steady and solid rate of progress throughout the course, while being low weighted in the overall course grade to reduce pressure.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#how-does-this-relate-to-previous-work-i-have-completed",
    "href": "04-AIS-03-dataskills.html#how-does-this-relate-to-previous-work-i-have-completed",
    "title": "\n6  Data Skills\n",
    "section": "\n6.7 How does this relate to previous work I have completed?",
    "text": "6.7 How does this relate to previous work I have completed?\n\nThe individual and generic feedback from previous assignments, and solutions for these assignments will help you complete these assignments. In addition, the data skills book activities will really help you in completing these assignments for your ability to apply what you learnt in one scenario to a new scenario.\nDo not forget that asking questions on the forums, dropping into GTA session, and speaking with the teaching team in labs is also giving you feedback and feed forward. All these sources of support will help you complete this assessment.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#academic-integrity",
    "href": "04-AIS-03-dataskills.html#academic-integrity",
    "title": "\n6  Data Skills\n",
    "section": "\n6.8 Academic Integrity",
    "text": "6.8 Academic Integrity\nPlease note that when submitting your work for assessment we accept it on the understanding that it is your own effort and work and unique to the set assignment.\nTo support you in understanding what plagiarism is and in avoiding it, please read the following resources that the University provides:\n\nSRC Advice and Support.\nCode of Student Conduct and Plagiarism Statement.\nAvoiding plagiarism and engage in good academic practice (a Moodle course you can self-enrol in).\nStudent support for AI, plagiarism, and digital skills.\n\nStatement on groupwork: We encourage students to form a study group and peer feedback groups. However, this assignment is not a group work assignment, so your work must be your own individual contribution. If you make a study group or a peer review group, avoid sharing final drafts or near final drafts of your work.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#ai-statement",
    "href": "04-AIS-03-dataskills.html#ai-statement",
    "title": "\n6  Data Skills\n",
    "section": "\n6.9 AI Statement",
    "text": "6.9 AI Statement\nThe University of Glasgow recognises the value of generative artificial intelligence tools in academic and professional workplaces. The university has a responsibility to ensure that students acquire the necessary knowledge, skills and other competencies associated within their discipline. The Student Learning Development service provides general guidance and support for students on the use of generative AI, but each item of assessment in your courses will have specific generative AI guidance about use and misuse in place. Where generative AI restrictions are in place, they have been carefully designed to maximise your learning opportunity whilst discouraging reliance on generative AI in a way that undermines your learning, or development of good professional practice and graduate attributes.\nStatement on use of generative AI: The current assessment is summative, meaning that it contributes to your course grade. The generative AI use for this assessment is categorised as amber and use of generative AI is allowed for some tasks during the preparation of the assessment.\nThere is no expectation that you will use generative AI and we have no evidence that it’s use will confer an advantage for this assessment. The purpose of this assessment is to encourage continuous learning over the semester and check your understanding in a low-stakes assessment. The data skills assessments have a low course grade percentage to reduce pressure. Taking short-cuts now will not provide an accurate overview of your understanding and skill development.\nIf you do use generative AI tools, we recommend using it for the following (non-exhaustive) kind of tasks:\n\nClarify complex concepts and reinforce understanding around intended learning outcomes.\nPlan a revision schedule.\nDebug your code and help identify the source of errors.\n\nIf you do use generative AI tools, we strongly recommend not using it for the following (non-exhaustive) kind of tasks:\n\nRelying on AI tools for understanding key concepts.\nCopying and pasting code directly from AI tools.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-03-dataskills.html#FIS",
    "href": "04-AIS-03-dataskills.html#FIS",
    "title": "\n6  Data Skills\n",
    "section": "\n6.10 Feedback information",
    "text": "6.10 Feedback information\n\n6.10.1 How is this assessment graded?\nEach data skills assignment will have several questions with each question being worth either 1 or 2 points. Your grade will be converted into an alphanumeric grade on the standard Glasgow 22-point Schedule A scale (e.g., a score of 16 = B2).\n\n6.10.2 How will the feedback from this assessment help me in the future?\nThe practical data skills assignments will help you develop your transferable data skills to complete future work that requires working with data, such as your dissertation, and courses or jobs that require such skills. Additionally, as you will see, these skills can be used for tasks such as writing reports, creating reference sections, conducting text analyses and building websites, as well as a wealth of other tasks and is therefore an extremely useful transferable skill. These skills also give you a much deeper understanding of data and research.\n\n6.10.3 What type of feedback will I receive for this assessment?\nFor these assignments, you will get a feedback sheet for each assignment that tells you whether you received full, partial, or no credit for each task/question within the assignment.\nYou will receive individual feedback on each task within an assignment, telling you where your answer was acceptable or telling you what was incorrect about your answer. You will also see the correct answer to each task within an assignment along with a short piece of generic feedback for that task.\nWe will also make a solution to the assignment available that you should compare to your own work to see alternative approaches, or to see where you have gone wrong, and to see what you have done correctly.\n\n6.10.4 Who assessed my work?\nThe assignments will be graded by an experienced member of staff using computer-assisted marking. Note that this is not automated marking as the member of staff has the final say on all submitted answers and checks the process at every step. In the first instance, we compare the output of your answer to the expected output or the code used to the code requested. If these comparisons match then you are given full credit for the task. If your answer does not match what was asked for in the task, then the member of staff manually checks your output to the expected output, or your code to the expected code, and to the question asked, to see if your code/output still answers the question or not. A decision is then made on whether to award full, partial, or no credit for that task.\n\n6.10.5 Can I get more feedback?\nYes! We encourage you discuss your assessment first with the marker or course lead (regardless of what grade you received) and you can do so either by messaging the marker or course lead directly to arrange an appointment. You can also speak to the GTA team about your coding skills for further development. All staff contact details can be found on the University of Glasgow directory.\n\n6.10.6 Can I have my work regraded?\nFurther feedback meetings with the person who marked your assignment is purely about additional information to help you improve and is not about changing your grade or having your work regraded. That said, even if you are unhappy with your grade, your first point of contact should be to arrange an additional feedback meeting with your marker for further discussion to help explain your feedback and grade. Following this, if you still have concerns you should consult the guidance from the SRC which provides a clear explanation of the University appeals procedures.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Skills</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html",
    "href": "04-AIS-04-stage1.html",
    "title": "7  Stage 1 Group Report",
    "section": "",
    "text": "7.1 General information\nThe group stage 1 report sets out the introduction (background research, rationale for your study, and your hypothesis where applicable) and planned methods. In your group, you will write about one of the two project options on sustainability or belonging.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#general-information",
    "href": "04-AIS-04-stage1.html#general-information",
    "title": "7  Stage 1 Group Report",
    "section": "",
    "text": "The deadline is November 14th 2025.\nThis assessment is worth 30% of your final course grade and will be a group mark. Everyone in your group will receive the same grade and feedback. This means it is important that everyone contributes to the project equitably and agrees on decisions as a group.\nOne member of your group should submit your complete stage 1 submission to Moodle. This will consist of an introduction and method section that would make up a stage 1 registered report submission prior to collecting data.\nIn this course, you will not be creating or designing the study yourself, just helping to add data to the pool which you will use as the data set to apply your planned analyses to for the final individual stage 2 submission. For further information on the individual stage 2 report, please refer to the Assessment Information Sheet.\nYou should submit a single Word document (.docx) to Moodle prior to the deadline. The submission link will open at least one week prior to the deadline and will be in the Assessment: Stage 1 Group and Stage 2 Individual Reports tab on Moodle.\nAs a formative task and to outline ground rules for working in your group, you will complete and submit a group work agreement. We will introduce this document to you in week 2 when you will know your group allocation, but it will involve agreeing to how you will work in and contribute to your group. This will help to plan your assignment and recognise how people may work and interact differently.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#word-count-and-formatting",
    "href": "04-AIS-04-stage1.html#word-count-and-formatting",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.2 Word count and formatting",
    "text": "7.2 Word count and formatting\n\nThe maximum word count for this assignment is 1500 words.\nThis includes all text within the introduction and method sections including in-text citations. However, it does not include the references or any appendix items.\nPlease note that there is no 10% rule, 1500 words is a strict upper limit.\nYour work should be presented in a professional sans-serif font, e.g. Arial or Calibri, 12-point font, double-spaced with 1-inch (2.54cm) margins.\nAll citations and references should follow APA 7th edition guidelines.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#type-of-assessmentstructure",
    "href": "04-AIS-04-stage1.html#type-of-assessmentstructure",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.3 Type of assessment/structure",
    "text": "7.3 Type of assessment/structure\n\nThe stage 1 group report is modeled on the first half of a registered report. This is a relatively new type of journal article where the research background, rationale, hypothesis, and planned methods are peer-reviewed prior to conducting a study. Instead of peer-review, your group work will be marked as an assessment.\nYour stage 1 group report will include an introduction and method section, plus references and appendices (where relevant). You will receive a template outlining the key sections and sub-sections to help with formatting.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#assessment-criteria",
    "href": "04-AIS-04-stage1.html#assessment-criteria",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.4 Assessment Criteria",
    "text": "7.4 Assessment Criteria\nYour stage 1 group report will be assessed on the three University of Glasgow Intended Learning Outcomes (ILOs), which we split into the following assessment criteria:\nQuality of the Knowledge and Research\n\nDemonstrate theoretical knowledge by providing a detailed evidence-based understanding of the topic of the report.\nDemonstrate technical knowledge by correctly reporting the design, materials, and procedure of the study in the method section.\n\nQuality of the Evaluation\n\nUse and show academic evidence to support all arguments and discussion.\nEvaluate the current literature to provide a clear, evidence-based rationale for your research question and hypothesis (where appropriate).\n\nQuality of the Academic Communication\n\nWrite clearly and succinctly with appropriate use of paragraphs, spelling, and grammar.\nReference all sources and report all information in line with APA guidelines.\nEnsure that all parts of the report have a logical structure, e.g., a broad-to-narrow scope in the introduction, and the method section should be organized into appropriate subheadings.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#assessment-support",
    "href": "04-AIS-04-stage1.html#assessment-support",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.5 Assessment support",
    "text": "7.5 Assessment support\n\nGuidance on how to complete the stage 1 group report will form part of the weekly course activities, such as content covered in the lectures and labs.\nWe cover the assumptions of simple linear regression (and relatedly, correlations and t-tests) and how to match your statistical model to your design and research question in the lectures and associated reading, such as the relevant sections of the PsyTeachR Fundamentals of Quantitative Analysis book.\nFurther information about assessment criteria and feedback can be found in the Feedback Information Sheet section below.\nYou can find additional writing and study advice, including 1-to-1 guidance on the Student Learning Development (SLD) website.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#how-to-do-well-in-this-assessment",
    "href": "04-AIS-04-stage1.html#how-to-do-well-in-this-assessment",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.6 How to do well in this assessment",
    "text": "7.6 How to do well in this assessment\n\nMeet each of the assessment criteria; use these as a checklist when you are writing and editing your work.\nAllow time for one or two members of your group to proof-read your work before submission.\nComplete all relevant sections and sub-sections of the stage 1 template to structure your submission.\nProvide an evidence-based rationale for your research question and hypothesis.\nUse the available materials to ensure the accuracy of your decisions.\nExplain your decisions and support them with evidence. Note that there are often multiple decisions you can make and there is not one “right” answer – this is absolutely fine. What matters is that you can explain and support your decisions and it is the sophistication of these explanations that is important.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#common-mistakes",
    "href": "04-AIS-04-stage1.html#common-mistakes",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.7 Common mistakes",
    "text": "7.7 Common mistakes\n\nNot explaining the decisions that you make and not using evidence to support them.\nWriting that is unclear and/or imprecise.\nInaccuracies in the explanation of planned methodological and statistical information.\nFailure to adhere to the word limit. There is no 10% leeway, we must stop reading when we reach the word count which affects the communication ILO.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#how-is-the-assessment-related-to-the-lectures-for-this-course",
    "href": "04-AIS-04-stage1.html#how-is-the-assessment-related-to-the-lectures-for-this-course",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.8 How is the assessment related to the lectures for this course?",
    "text": "7.8 How is the assessment related to the lectures for this course?\nThe stage 1 report provides you the opportunity to apply many of the concepts you learn in the course materials by collating and synthesising research, and planning your analysis approach based on your research question and design.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#why-am-i-being-assessed-like-this",
    "href": "04-AIS-04-stage1.html#why-am-i-being-assessed-like-this",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.9 Why am I being assessed like this?",
    "text": "7.9 Why am I being assessed like this?\n\nRegistered reports are increasingly common in psychological research and it is a process that will serve you well should you continue with research as it demonstrates a commitment to open and reproducible science.\nThe stage 1 report allows you to think through the background and rationale of your research question, and your planned methods and analyses prior to completing the individual stage 2 report.\nThe stage 1 report is a group submission to reflect the fact that in most research, these decisions will be made as a team and it allows you to pool your collective knowledge to design the best study possible.\nWe follow a scaffolded approach to develop your understanding of writing research reports across the programme. In RM1, you write the introduction and method sections in a group. You then write the results and discussion individually. In RM2 and your dissertation, you work up to writing the full report and dissertation individually.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#how-does-this-relate-to-previous-work-i-have-completed",
    "href": "04-AIS-04-stage1.html#how-does-this-relate-to-previous-work-i-have-completed",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.10 How does this relate to previous work I have completed?",
    "text": "7.10 How does this relate to previous work I have completed?\n\nYou can gain informal feedback by talking to your lab tutors, lecturers, and/or by attending student office hours.\nFeedback on any previous written assignment will help with academic communication and using evidence to support your arguments.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#academic-integrity",
    "href": "04-AIS-04-stage1.html#academic-integrity",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.11 Academic Integrity",
    "text": "7.11 Academic Integrity\nPlease note that when submitting your work for assessment we accept it on the understanding that it is your own effort and work and unique to the set assignment.\nTo support you in understanding what plagiarism is and in avoiding it, please read the following resources that the University provides:\n\nSRC Advice and Support.\nCode of Student Conduct and Plagiarism Statement.\nAvoiding plagiarism and engage in good academic practice (a Moodle course you can self-enrol in).\nStudent support for AI, plagiarism, and digital skills.\n\nStatement on groupwork: This is a group assignment and one person from the group should be nominated to submit the draft and final version of the assignment on Moodle. Your group’s work should not be exactly the same as that of another group in the class, however, as you worked closely in a larger group and from common templates, we know that there may be some unavoidable similarities between team members in the method and results, but it should never be identical or close to identical.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#ai-statement",
    "href": "04-AIS-04-stage1.html#ai-statement",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.12 AI statement",
    "text": "7.12 AI statement\nThe University of Glasgow recognises the value of generative artificial intelligence tools in academic and professional workplaces. The university has a responsibility to ensure that students acquire the necessary knowledge, skills and other competencies associated within their discipline. The Student Learning Development service provides general guidance and support for students on the use of generative AI, but each item of assessment in your courses will have specific generative AI guidance about use and misuse in place. Where generative AI restrictions are in place, they have been carefully designed to maximise your learning opportunity whilst discouraging reliance on generative AI in a way that undermines your learning, or development of good professional practice and graduate attributes.\nStatement on use of generative AI: The current assessment is summative, meaning that it contributes to your course grade. The generative AI use for this assessment is categorised as amber and use of generative AI is allowed for some tasks during the preparation of the assessment.\nThere is no expectation that you will use generative AI and we have no evidence that its use will confer an advantage for this assessment. If you do use generative AI, please clearly acknowledge its use in-text via citations and referencing and in an appendix with a declaration of AI use as appropriate – please see the title page on Moodle for further instructions. If you choose to use it, we recommend that you use the Microsoft Edge browser with Copilot and sign into your university account using the two-factor authentication to ensure that your work is private and secure. Please keep a log of all AI use.\nThe purpose of this assessment is to work on your quantitative research methods skills and your understanding of a research project from developing a research question to writing an APA-formatted report. This is a group assignment to collectively write an introduction and methods to scaffold learning, but you will write whole reports in RM2 and your dissertation. Any short-cuts you take now will have a knock-on effect in future. So, try and embrace the skill development component to the course and assessment.\nIf you do use generative AI tools, we recommend using it for the following (non-exhaustive) kind of tasks:\n\nClarify complex concepts and reinforce understanding around intended learning outcomes.\nPlan a structure for your assessment.\nRecommend keywords and other tips for effective literature searches.\nAssist with referencing format.\n\nIf you do use generative AI tools, we strongly recommend not using it for the following (non-exhaustive) kind of tasks:\n\nConducting your whole literature review for you, as you may miss out on potentially useful sources and AI tools are notorious for making up references.\nWrite whole paragraphs or sections of your report for you.\nRewrite bulleted lists or notes into sentences and paragraphs.\n\n\n\n\n\n\n\nWarning\n\n\n\nThe references you use and cite in your work are your responsibility, regardless of whether you use generative AI tools or not. Assessments containing hallucinated references that do not exist in peer-reviewed journals may be subject to exploratory interviews and reporting to student conduct.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-04-stage1.html#stage1-FIS",
    "href": "04-AIS-04-stage1.html#stage1-FIS",
    "title": "7  Stage 1 Group Report",
    "section": "\n7.13 Feedback information",
    "text": "7.13 Feedback information\n\n7.13.1 What type of feedback will I receive for this assessment?\nYou will receive feedback on your attainment of the overall marking criteria (Knowledge and Research, Critical Evaluation, Academic Communication) in terms of the verbal descriptors from Schedule A and feed forward comments as to how to develop your knowledge and skills for future assignments.\nAssessments are graded on the 22-point scale using the Schedule A marking criteria. There are three equally weighted Assessment Criteria (Knowledge and Research, Critical Evaluation, Academic Communication). You can find out more about Schedule A by downloading this PDF but the important thing to help you interpret your feedback is the use of the verbal descriptors, i.e., the words like “excellent” and “good” used to describe different grades. You should look out for these words to help you understand how you performed on each ILO.\n\n7.13.2 Can I get more feedback?\nYou are more than welcome to receive additional feedback after the marking process:\n\nIf you would like to discuss your feedback you should first contact the person that marked your assignment. However, we ask that you wait 24 hours after the release of the feedback before you do so to give you time to fully reflect on the feedback given.\nWhen meeting with the person who marked your assignment, you can discuss feedback and how it relates to your overall grade to help you improve in future assignments. However, do not be worried about attending to discuss how to maintain your standard if you have done better than you expected. You are more than welcome to come discuss any aspect of your feedback or the assignment in general.\nTo help any discussion about your feedback, we would ask that you complete the reflection form available on the Moodle page and send that to the person who marked your assignment as part of the discussion, when arranging a meeting.\n\n7.13.3 How will feedback from this assessment help me in the future?\nPrimarily, the feedback on this assessment will help support the analysis and write-up of the stage 2 individual report in this course. Additionally, the feedback will help support your qualitative report in RM2, as well as your dissertation and in any future research work you conduct that requires data analysis, decision-making, and evidence-based justification.\n\n7.13.4 Who assessed my work?\nThe first marker for your report will be a member of the Research Methods 1 team within the School of Psychology and Neuroscience.\nFollowing University policy, as part of the marking procedures, the assignment marking will be moderated. The moderator will be another member of the research methods team who will moderate a range of work from across the cohort to ensure that appropriate academic standards have been applied in marking the assignments and that they have been applied consistently across the cohort of students being assessed.\n\n7.13.5 Can I have my work regraded?\nFurther feedback meetings with the person who marked your assignment is purely about additional information to help you improve and is not about changing your grade or having your work regraded. That said, even if you are unhappy with your grade, your first point of contact should be to arrange an additional feedback meeting with your marker for further discussion to help explain your feedback and grade. Following this, if you still have concerns you should consult the guidance from the SRC which provides a clear explanation of the University appeals procedures.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Stage 1 Group Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html",
    "href": "04-AIS-05-stage2.html",
    "title": "8  Stage 2 Individual Report",
    "section": "",
    "text": "8.1 General information\nThe stage 2 individual report builds on your stage 1 group report, but this time you individually report your abstract, results, and discussion. You will still write about one of the two project options on sustainability or belonging that you developed in the stage 1 report as a group.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#general-information",
    "href": "04-AIS-05-stage2.html#general-information",
    "title": "8  Stage 2 Individual Report",
    "section": "",
    "text": "The deadline is December 12th 2025.\nThis assessment is worth 50% of your final course grade.\n\nYou will combine all the research and data skills you have developed in the course to produce a reproducible research report. You will submit three files to allow the marker to check both the reproducibility of your work alongside marking the content:\n\nThe .Rmd file using the stage 2 template we provide to include the title page, abstract, results, discussion, references, and appendices. We will use this file and the data you provide to check your file knits.\nA knitted Word document created from the .Rmd file. Given we only have so much time in the course for you to learn about formatting in Markdown, you can edit the formatting of the Word document to make sure your work is consistent with APA 7th edition. This is the file we will mark and add feedback to.\nThe data as a .csv file for the project you worked on. We will use this and the .Rmd file you provide to check your document knits.\n\n\nThe submission link will open at least one week prior to the deadline and will be in the Assessment: Stage 1 Group and Stage 2 Individual Reports section of Moodle. Remember you must upload all three files.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#word-count-and-formatting",
    "href": "04-AIS-05-stage2.html#word-count-and-formatting",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.2 Word count and formatting",
    "text": "8.2 Word count and formatting\n\nThe maximum word count for the knitted Word document component of the stage 2 report is 1500 words.\nThis includes all text within the abstract, results, and discussion sections including in-text citations. However, it does not include the references or any appendix items.\nPlease note that there is no 10% rule, 1500 words is a strict upper limit.\nYour work should be presented in a professional sans-serif font, e.g. Arial or Calibri, 12-point font, double-spaced with 1-inch (2.54cm) margins.\nAll citations and references should follow APA 7th edition guidelines.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#type-of-assessmentstructure",
    "href": "04-AIS-05-stage2.html#type-of-assessmentstructure",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.3 Type of assessment/structure",
    "text": "8.3 Type of assessment/structure\n\nThe stage 2 individual report is modeled on the second half of a registered report. When a research team has their stage 1 submission approved, they go out and collect data, then write up their results and discussion. You are working with secondary data all the groups contribute to, so you did not create or design a study yourself, but you are putting your stage 1 plan in action and justifying any deviations from your plan.\nThe knitted Word document component of your stage 2 individual report will include an abstract, results, and discussion section. You will also have a reference list and any appendix items beyond the generative AI declaration. You will receive a .Rmd template outlining the key sections as part of the course.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#assessment-criteria",
    "href": "04-AIS-05-stage2.html#assessment-criteria",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.4 Assessment Criteria",
    "text": "8.4 Assessment Criteria\nYour stage 2 individual report will be assessed on the three University of Glasgow Intended Learning Outcomes (ILOs) which we split into the following assessment criteria, in addition to a separate item on reproducibility:\nQuality of the Knowledge and Research\n\nDemonstrate technical knowledge by correctly reporting and interpreting the results.\nDemonstrate theoretical knowledge by providing a detailed evidence-based understanding of the topic of the report.\n\nQuality of the Evaluation\n\nUse and show academic evidence to support all arguments and discussion.\nEvaluate your study and how your results fit into the wider literature.\n\nQuality of the Academic Communication\n\nWrite clearly and succinctly with appropriate use of paragraphs, spelling, and grammar.\nReference all sources and report all information in line with APA guidelines.\nEnsure that all parts of the report have a logical structure, e.g., the results should present descriptive statistics before inferential statistics, and the discussion should follow a narrow-to-broad scope.\n\nReproducibility\n\nProvide a reproducible document that can be knitted without any errors.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#assessment-support",
    "href": "04-AIS-05-stage2.html#assessment-support",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.5 Assessment support",
    "text": "8.5 Assessment support\n\nGuidance on how to write a psychology report and how to do APA referencing form part of the weekly course activities. You should consult the resources provided throughout the course to help you write your stage two report.\nThe Fundamentals of Quantitative Methods book covers writing reproducible documents and your experience from the data skills assessments will help work reproducibly.\nFurther information about assessment criteria and feedback is available in the Feedback Information Sheet section.\nAdditional writing and study advice, including 1-to-1 guidance is available via the Student Learning Development (SLD) website.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#how-to-do-well-in-this-assessment",
    "href": "04-AIS-05-stage2.html#how-to-do-well-in-this-assessment",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.6 How to do well in this assessment",
    "text": "8.6 How to do well in this assessment\n\nMeet each of the assessment criteria; use these as a checklist when you are writing and editing your work.\nAllow time to proof-read your work before submission.\nRead peer-reviewed journal articles (preferably registered reports to see the specific approach) as these will help guide your tone and help you develop your academic writing. Remember that you can read anything for content and style. These are different mindsets when reading so go into your reading with a given purpose - what do I want to get from this paper? - and that will help use your time more efficiently.\nWrite clearly, concisely, with a professional academic tone and logical structure.\nAvoid using quotations. Rephrasing the writing in your own words and with appropriate citation is much more effective in conveying information.\nConcisely and accurately report and interpret descriptive statistics, diagnostic checks for assumptions, and inferential statistics. Note and justify any deviations from the stage 1 report.\nPresent appropriate visualisations for the analyses that you conduct.\nInterpret the results of the project in the context of the wider literature.\nDemonstrate evidence of evaluation, both of the wider literature and of the current project.\nProvide a concise conclusion and an overall summary that covers each section of the report in the form of an abstract.\nAdhere to APA 7th edition conventions for referencing, formatting, and the reporting of results.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#common-mistakes",
    "href": "04-AIS-05-stage2.html#common-mistakes",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.7 Common mistakes",
    "text": "8.7 Common mistakes\n\nWriting that contains grammatical errors, a lack of clarity, or an informal tone. Reading published articles in comparison to scientific blogs or newspapers will greatly help get the correct tone. The key is to focus on how they are writing and phrasing differently across different media.\nMissing detail and/or unnecessary detail in the result sections.\nFailure to report the results of statistical tests according to APA convention.\nFailure to provide necessary visualisations or the inclusion of unnecessary visualisations. You do not need to provide visualisations for any diagnostic checks in the main report (although you should include these in the appendix).\nA lack of evaluation of the wider literature and the current project and/or a discussion of the limitations that is not supported by evidence.\nFailure to adhere to the word limit. Part of the skill development is writing concisely.\nNot considering reproducibility and including features like absolute file paths which will not work on someone else’s computer.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#how-is-the-assessment-related-to-the-lectures-for-this-course",
    "href": "04-AIS-05-stage2.html#how-is-the-assessment-related-to-the-lectures-for-this-course",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.8 How is the assessment related to the lectures for this course?",
    "text": "8.8 How is the assessment related to the lectures for this course?\n\nThe stage 2 report assesses your ability to apply the concepts that you have learned about during the lectures. This includes methodology and research design, statistics, communicating research, and reproducible research practices.\nDepending on the topic you chose in your group, the project may also be related to content from other courses such as social psychology or human development.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#why-am-i-being-assessed-like-this",
    "href": "04-AIS-05-stage2.html#why-am-i-being-assessed-like-this",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.9 Why am I being assessed like this?",
    "text": "8.9 Why am I being assessed like this?\n\nRegistered reports are increasingly common in psychological research and it is a process that will serve you well should you continue with research as it demonstrates a commitment to open and reproducible science.\nBy providing your work as a reproducible report, you demonstrate open and reproducible research skills. Learning how to use R/RStudio is a big investment, so by assessing reproducibility you will receive feedback on both your coding and the content of your report.\nThe stage 2 report allows you to address your research question using your planned methods and analyses from the stage 1 report. You will then put your findings in context and explore how your results were either consistent or inconsistent with past research, while noting any important limitations in your methods.\nThe stage 2 report will help you with your qualitative RM2 report, dissertation, and with any other written research-focused work you may conduct in the future.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#how-does-this-relate-to-previous-work-i-have-completed",
    "href": "04-AIS-05-stage2.html#how-does-this-relate-to-previous-work-i-have-completed",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.10 How does this relate to previous work I have completed?",
    "text": "8.10 How does this relate to previous work I have completed?\n\nYou can gain informal feedback by talking to your lab tutor, by attending student office hours, by asking questions on Teams, and by discussing papers you have read with peers and/or staff.\nFeedback from your stage 1 group report may help you with justifying any deviations from your data analysis plan, in your discussion to identify limitations, and your use of technical terminology.\nFeedback on your two data skills assignments will help develop your reproducible research skills.\nFeedback on any written assignment will help with academic communication.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#academic-integrity",
    "href": "04-AIS-05-stage2.html#academic-integrity",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.11 Academic Integrity",
    "text": "8.11 Academic Integrity\nPlease note that when submitting your work for assessment we accept it on the understanding that it is your own effort and work and unique to the set assignment.\nTo support you in understanding what plagiarism is and in avoiding it, please read the following resources that the University provides:\n\nSRC Advice and Support.\nCode of Student Conduct and Plagiarism Statement.\nAvoiding plagiarism and engage in good academic practice (a Moodle course you can self-enrol in).\nStudent support for AI, plagiarism, and digital skills.\n\nStatement on groupwork: This report is not a group work assignment, so your work must be your own individual contribution. However, as you worked closely in a small team and from common templates, we know that there may be some unavoidable similarities between team members in the results, but it should never be identical or close to identical.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#ai-statement",
    "href": "04-AIS-05-stage2.html#ai-statement",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.12 AI statement",
    "text": "8.12 AI statement\nThe University of Glasgow recognises the value of generative artificial intelligence tools in academic and professional workplaces. The university has a responsibility to ensure that students acquire the necessary knowledge, skills and other competencies associated within their discipline. The Student Learning Development service provides general guidance and support for students on the use of generative AI, but each item of assessment in your courses will have specific generative AI guidance about use and misuse in place. Where generative AI restrictions are in place, they have been carefully designed to maximise your learning opportunity whilst discouraging reliance on generative AI in a way that undermines your learning, or development of good professional practice and graduate attributes.\nStatement on use of generative AI: The current assessment is summative, meaning that it contributes to your course grade. The generative AI use for this assessment is categorised as amber and use of generative AI is allowed for some tasks during the preparation of the assessment.\nThere is no expectation that you will use generative AI and we have no evidence that its use will confer an advantage for this assessment. If you do use generative AI, please clearly acknowledge its use in-text via citations and referencing and in an appendix with a declaration of AI use as appropriate – please see the title page on Moodle for further instructions. If you choose to use it, we recommend that you use the Microsoft Edge browser with Copilot and sign into your university account using the two-factor authentication to ensure that your work is private and secure. Please keep a log of all AI use.\nThe purpose of this assessment is to work on your quantitative research methods skills and your understanding of a research project from communicating your findings to putting your results in context. The stage two report is the culmination of your skill development in RM1, as you are applying your data wrangling, visualisation, and analysis skills, plus your subject knowledge and research skills for writing the results and discussion. You will write whole reports in RM2 and your dissertation, so this is the chance to develop your own skills. Any short-cuts you take now will have a knock-on effect in future. So, try and embrace the skill development component to the course and assessment.\nIf you do use generative AI tools, we recommend using it for the following (non-exhaustive) kind of tasks:\n\nClarify complex concepts and reinforce understanding around intended learning outcomes.\nPlan a structure for your assessment.\nRecommend keywords and other tips for effective literature searches.\nHelp debug code by working out the source of errors.\nAssist with referencing format.\n\nIf you do use generative AI tools, we strongly recommend not using it for the following (non-exhaustive) kind of tasks:\n\nConducting your whole literature review for you, as you may miss out on potentially useful sources and AI tools are notorious for making up references.\nWrite whole paragraphs or sections of your report for you.\nConduct your whole data analysis or generate summaries of data for you.\nRewrite bulleted lists or notes into sentences and paragraphs.\n\n\n\n\n\n\n\nWarning\n\n\n\nThe references you use and cite in your work are your responsibility, regardless of whether you use generative AI tools or not. Assessments containing hallucinated references that do not exist in peer-reviewed journals may be subject to exploratory interviews and reporting to student conduct.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-05-stage2.html#stage2-FIS",
    "href": "04-AIS-05-stage2.html#stage2-FIS",
    "title": "8  Stage 2 Individual Report",
    "section": "\n8.13 Feedback information",
    "text": "8.13 Feedback information\n\n8.13.1 What type of feedback will I receive for this assessment?\nYou will receive feedback on your attainment of the overall marking criteria (Knowledge and Research, Critical Evaluation, Academic Communication) in terms of the verbal descriptors from Schedule A and feedforward comments as to how to develop your knowledge and skills for future assignments.\nAssessments are graded on the 22-point scale using the Schedule A marking criteria. There are three equally weighted Assessment Criteria (Knowledge and Research, Critical Evaluation, Academic Communication). You can find out more about Schedule A by downloading this PDF but the important thing to help you interpret your feedback is the use of the verbal descriptors, i.e., the words like “excellent” and “good” used to describe different grades. You should look out for these words to help you understand how you performed on each ILO.\n\n8.13.2 Can I get more feedback?\nYou are more than welcome to receive additional feedback after the marking process:\n\nIf you would like to discuss your feedback you should first contact the person that marked your assignment. However, we ask that you wait 24 hours after the release of the feedback before you do so to give you time to fully reflect on the feedback given.\nWhen meeting with the person who marked your assignment, you can discuss feedback and how it relates to your overall grade to help you improve in future assignments. However, do not be worried about attending to discuss how to maintain your standard if you have done better than you expected. You are more than welcome to come discuss any aspect of your feedback or the assignment in general.\nTo help any discussion about your feedback, we would ask that you complete the reflection form available on the Moodle page and send that to the person who marked your assignment as part of the discussion, when arranging a meeting.\n\n8.13.3 How will feedback from this assessment help me in the future?\nThe feedback on this assessment will help you in writing future research reports, such as the qualitative report in semester 2, your MSc dissertation, and in any future research work you conduct that requires academic writing and evidence-based evaluation.\n\n8.13.4 Who assessed my work?\nThe first marker for your report will be a member of the Research Methods 1 team within the School of Psychology and Neuroscience.\nFollowing University’s policy, as part of the marking procedures, the assignment marking will be moderated. The moderator will be another member of the research methods team who will moderate a range of work from across the cohort to ensure that appropriate academic standards have been applied in marking the assignments and that they have been applied consistently across the cohort of students being assessed.\n\n8.13.5 Can I have my work regraded?\nFurther feedback meetings with the person who marked your assignment is purely about additional information to help you improve and is not about changing your grade or having your work regraded. That said, even if you are unhappy with your grade, your first point of contact should be to arrange an additional feedback meeting with your marker for further discussion to help explain your feedback and grade. Following this, if you still have concerns you should consult the guidance from the SRC which provides a clear explanation of the University appeals procedures.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Stage 2 Individual Report</span>"
    ]
  },
  {
    "objectID": "04-AIS-06-Projects.html",
    "href": "04-AIS-06-Projects.html",
    "title": "9  Registered Report Project Starter Packs",
    "section": "",
    "text": "9.1 General overview of the registered report\nIn this course, we are preparing you to read/appraise journal articles, know how to conduct your own project, and write up an empirical quantitative research project. Throughout the lectures, labs, and independent learning, you will learn how to formulate a research question, design a study, apply statistical analyses, and write up your results to communicate to others as a research report.\nIn your group, you will decide on a topic and collectively write a stage one registered report (see the stage one AIS) which contains an introduction and method section for how you plan on addressing your research question. Individually, you will then write a stage two registered report (see the stage two AIS) which contains a results, discussion, and abstract section. You have more than enough to learn about in this course without worrying about designing a study, applying for ethics, and collecting data yourselves. Therefore, we have developed two projects for you and your group to choose from and pick your own adventure.\nOne project focuses on sustainability and the other project focuses on inclusion/belonging. The British Psychological Society (BPS) identified both of these topics as two key areas that psychology graduates can contribute to for evidence-based understanding, policy, and intervention. As psychology students, you will learn about research methods and statistics with an applied focus, to robustly and reproducibly address research questions relevant to psychology.\nWe have already designed and prepared the projects you will work with in your groups. You will write a stage one and stage two registered report from the perspective of the researcher as if you conducted the studies yourselves, but you will only help us to collect data and add to the participant pool. This reduces pressure and gives you time to focus on learning about research methods and statistics before you design your own studies in future courses and in your dissertation. Autonomy is important in education though, so you have the choice between two projects to decide on as a group, and within each project there is flexibility in the research questions you can develop.\nThe rest of this chapter outlines starter packs to learn more about the two projects and give you a starting point for your research, so please read through in advance of your first lab.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Registered Report Project Starter Packs</span>"
    ]
  },
  {
    "objectID": "04-AIS-06-Projects.html#sustainability-starter-pack",
    "href": "04-AIS-06-Projects.html#sustainability-starter-pack",
    "title": "9  Registered Report Project Starter Packs",
    "section": "\n9.2 Sustainability starter pack",
    "text": "9.2 Sustainability starter pack\n\n9.2.1 Study background\nEating meat is a key contributor to greenhouse gas emissions. One potential low cost intervention to reduce meat eating is using dynamic norms in the messaging behind adopting more sustainable behaviours. A dynamic norm is where you highlight the change of a norm over time, such as more people recently changing their behaviour to eat less meat. In contrast, a static norm describes it’s current state. Sparkman & Walton (2017) demonstrated that dynamic norms would lead to greater intention to eat less meat than static norms. However, studies like Aldoh et al. (2024) have struggled to replicate the finding and question whether it translates to actual behaviour.\nIn our study, we include items on meat eating for a replication of previous work on the effect of dynamic norms but we also offer an extension opportunity to explore the effect of dynamic norms on alternative types of sustainable behaviour like using public transport and reusable cups/bottles.\n\n9.2.2 Why is this topic important?\nThe BPS highlight the role of psychology research in responding to challenges/opportunities relating to the United Nation’s (UN) sustainable development goals. Psychologists have the tools to conduct research to inform evidence-based policy and interventions in addressing these goals. The goals most relevant to this project are 11 (sustainable cities and communities) and 13 (climate action).\n\n9.2.3 Relevant theory\nOne popular theory relating to behaviour change is the COM-B model of behaviour (Michie et al., 2011). The aim of this theory is to explain why a specific behavior occurs and how to create interventions that lead to effective change in that behaviour. COM-B stands for capability (C), opportunity (O), and motivation (M), relating to a given behaviour (B). Ask yourselves the following questions:\n\nHow well regarded is the COM-B model? Does empirical evidence generally support it as a theory of human behaviour?\nHow might the COM-B model apply to understanding adopting more sustainable behaviours such as meat eating, using public transport, and using reusable cups/bottles?\nBased on the theory, what kind of effect from dynamic norms do you predict to find?\n\n9.2.4 Research design\nYou will be unfamiliar with a lot of this terminology at the start of the course, but we outline it nice and early to help refine your research question and know what variables you will have available since you did not design the study yourself.\nThere is one independent variable with two levels. We randomise participants into one of two groups: they receive a dynamic norm statement or they receive a static norm statement.\nThere are three potential dependent variables which measure interest in adopting a more sustainable behaviour. For this course, we heavily recommend choosing just one of the measures given the word count of the stage one and stage two registered report assessments. The three dependent variables are:\n\nHow interested are you in eating less meat? We measure this on a 0 (not at all interested) to 100 (extremely interested) scale.\nHow interested are you in using more public transport? We measure this on a 0 (not at all interested) to 100 (extremely interested) scale.\nHow interested are you in using a reusable cup or bottle for takeout purchases? We measure this on a 0 (not at all interested) to 100 (extremely interested) scale.\n\nWe then have a selection of others variables available for reporting or identifying a specific sample such as age, gender, vegetarian status, political position, student status, and self-reported data quality. You will see more information on the wording and options behind these variables in the code book and Qualtrics walkthrough.\n\n9.2.5 Potential research questions\nIn this introductory course, we focus on analysing research designs with two variables. Most relevant to this project is one independent variable (dynamic vs static norms) and one dependent variable of your choice from the three sustainable behaviours. For example, you might focus on a replication with a research question on eating meat like:\n\n“Do dynamic norms lead to greater intentions to eat less meat compared to static norms?”\n\nOn the other hand, you might explore one of the other dependent variables as an extension and develop a research question like:\n\n“Do dynamic norms lead to greater intentions to use more public transport compared to static norms?”\n\nWhile we focus on two variables for the design and analysis in this course, you could develop a more specific research question in your stage one report by identifying a specific sample/population:\n\n“Do dynamic norms lead to greater intentions to eat less meat compared to static norms in international students?”\n\nThese are only examples for inspiration and you are welcome to develop an alternative evidence-based research question in your groups providing it is possible within the constraints of the study design.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Registered Report Project Starter Packs</span>"
    ]
  },
  {
    "objectID": "04-AIS-06-Projects.html#culture-shock-starter-pack",
    "href": "04-AIS-06-Projects.html#culture-shock-starter-pack",
    "title": "9  Registered Report Project Starter Packs",
    "section": "\n9.3 Culture shock starter pack",
    "text": "9.3 Culture shock starter pack\n\n9.3.1 Study background\nStudying abroad provides international students with opportunities to develop their identity, language proficiency, academic achievement, and employability. These benefits are most likely realised when students are equipped with the skills and knowledge to navigate an intercultural educational setting. However, the study-abroad journey is not always smooth. Many international students, for example, experience culture shock, which can involve feelings of stress, uncertainty, and discomfort as they adapt to a new cultural environment (Ward et al., 2001; Zhou et al., 2008).\nCulture shock is frequently depicted as an unavoidable component of studying abroad. Yet international students are often regarded as a homogeneous group (Lomer & Mittelmeier, 2023), with insufficient attention to the diverse ways they experience and navigate this transition. At the same time, culture shock, while described as difficult, can also foster growth by giving students fresh perspectives and helping them integrate unfamiliar cultural experiences into their existing worldview (Devito, 2004).\nStill, more research is needed to better understand how international students experience culture shock in the UK. This study, therefore, seeks to provide a clearer understanding of these experiences in higher education.\n\n9.3.2 Why is this topic important?\nCulture shock affects how international students adjust socially and academically in the UK. Investigating these experiences is important because the findings can inform support in concrete areas such as orientation programmes, academic advising, peer networks, and wellbeing services. Strengthening these forms of support can help students settle with greater confidence, succeed in their studies, and participate more fully in university life.\n\n9.3.3 Relevant theory\nResearchers who study transitions note that it is not always clear when culture shock actually begins (Brown & Holloway, 2008). One of the first attempts to describe the process came from Lysgaand (1955), who proposed the U-curve model of adjustment. According to this idea, newcomers typically start out feeling enthusiastic and optimistic, but these early impressions often give way to periods of difficulty or disorientation. Over time, many gradually regain balance and move toward a more stable sense of adjustment.\nA few years later, Oberg (1960) introduced the term culture shock and outlined it as a four-stage process. The first, the honeymoon stage, is characterised by excitement and curiosity in response to the new environment. This enthusiasm can fade into what Oberg called the regression stage, when frustration and irritation with cultural differences become more noticeable. As people spend longer in the new setting, they usually begin to find practical ways of managing daily life, marking the adjustment stage. Eventually, some reach a point of recovery, where cultural differences are not only accepted but also valued as part of a deeper adaptation.\nWard et al. (2001) put forward what they called the ABC model of culture shock, which looks at the affective (A), behavioural (B), and cognitive (C) sides of adjusting to a new culture. The affective part is about emotions, for example, the stress, homesickness, or anxiety that can come with moving abroad. Behaviour covers the skills people need, such as using the language, managing routines, or finding ways to connect with others. The cognitive side has more to do with how people think about cultural differences, and how they form views of both their host and home cultures. Taken together, these three areas show that adjustment is not just a matter of passing through fixed stages, but involves emotions, actions, and thoughts working alongside each other.\n\n9.3.4 Research design\nIn this study, international students in the UK are asked to complete the 12-item Culture Shock Questionnaire (Mumford, 1998), which is designed to assess culture shock. In addition, participants provide demographic information, including:\n\nAge (in years)\nGender (male, female, non-binary)\nLevel of study (undergraduate, postgraduate taught, postgraduate research)\nLength of stay in the UK (in months)\nSelf-rated English proficiency (measured on a scale from 0 = ‘not proficient at all’ to 100 = ‘extremely proficient’)\nFirst-time study abroad (Yes/No)\n\n9.3.5 Potential research questions\nIn this course, our emphasis is on exploring research designs that involve two variables. The first type of research question focuses on the relationship between two variables. For example:\n\nIs there a relationship between international students’ culture shock and their self-rated English proficiency?\nIs culture shock among international students associated with their length of stay in the UK?\n\nThe second type of research question investigates group differences, asking whether different groups of participants show variation on a particular outcome. In this project, examples might include:\n\nDo international postgraduate taught students experience greater culture shock than international undergraduate students?\nDo first-time study abroad students report higher culture shock than students who have studied abroad before?\n\nThese are only examples for inspiration and you are welcome to develop an alternative evidence-based research question in your groups providing it is possible within the constraints of the study design.\n\n\n\n\n\n\nCan I still change my mind?\n\n\n\nThis seems like a big decision to make so early, but we use your initial interests to arrange people into groups when you might not know other people in your lab yet. We expect most groups will have a mix of preferences for the sustainability or culture shock study, so the first few weeks will be working with your group to decide on the project and your specific research question. You must make any decision on the project and research question in collaboration with all the members of your group. Once you settle on two variables, you might also focus on a specific population in your group as you develop your rationale, so there is still plenty of creative freedom within each project.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow you have read through the project starter packs, think about which project interests you the most and complete the project interest form (available on Moodle). We will start putting you in groups in week 2 so you have as much time as possible to work on your group project.\n\n\n\n\n\n\nAldoh, A., Sparks, P., & Harris, P. R. (2024). Shifting norms, static behaviour: Effects of dynamic norms on meat consumption. Royal Society Open Science, 11(6), 240407. https://doi.org/10.1098/rsos.240407\n\n\nBrown, L., & Holloway, I. (2008). The initial stage of the international sojourn: Excitement or culture shock? British Journal of Guidance & Counselling, 36(1), 33–49. https://doi.org/10.1080/03069880701715689\n\n\nDevito, J. A. (2004). The Interpersonal Communication Book (10th ed.). Pearson Education.\n\n\nLomer, S., & Mittelmeier, J. (2023). Mapping the research on pedagogies with international students in the UK: A systematic literature review. Teaching in Higher Education, 28(6), 1243–1263. https://doi.org/10.1080/13562517.2021.1872532\n\n\nLysgaand, S. (1955). Adjustment in a foreign society: Norwegian Fulbright grantees visiting the United States. International Social Science Bulletin, 7, 45–51.\n\n\nMichie, S., Stralen, M. M. van, & West, R. (2011). The behaviour change wheel: A new method for characterising and designing behaviour change interventions. Implementation Science, 6(1), 42. https://doi.org/10.1186/1748-5908-6-42\n\n\nMumford, D. B. (1998). The measurement of culture shock. Social Psychiatry and Psychiatric Epidemiology, 33(4), 149–154. https://doi.org/10.1007/s001270050037\n\n\nOberg, K. (1960). Cultural Shock: Adjustment to New Cultural Environments. Practical Anthropology, os-7(4), 177–182. https://doi.org/10.1177/009182966000700405\n\n\nSparkman, G., & Walton, G. M. (2017). Dynamic Norms Promote Sustainable Behavior, Even if It Is Counternormative. Psychological Science, 28(11), 1663–1674. https://doi.org/10.1177/0956797617719950\n\n\nWard, C., Bochner, S., & Furnham, A. (2001). The psychology of culture shock (2nd ed.). Routledge.\n\n\nZhou, Y., Jindal-Snape, D., Topping, K., & Todman, J. (2008). Theoretical models of culture shock and adaptation in international students in higher education. Studies in Higher Education, 33(1), 63–75. https://doi.org/10.1080/03075070701794833",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Registered Report Project Starter Packs</span>"
    ]
  },
  {
    "objectID": "06-Writing-01-Reading.html",
    "href": "06-Writing-01-Reading.html",
    "title": "10  Finding, Reading, and Organising Journal Articles",
    "section": "",
    "text": "10.1 Finding journal articles",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Finding, Reading, and Organising Journal Articles</span>"
    ]
  },
  {
    "objectID": "06-Writing-01-Reading.html#finding-journal-articles",
    "href": "06-Writing-01-Reading.html#finding-journal-articles",
    "title": "10  Finding, Reading, and Organising Journal Articles",
    "section": "",
    "text": "10.1.1 Identifying key words\nBefore you can read journal articles, you need to find them. The first step in a literature review is working out what your keywords will be. You will be looking in databases, so you need to select the appropriate terms to ensure your search results return the content you are looking for. It takes patience to identify and tweak the search terms that identify the content you are looking for. As a starting point, these might be your topic or variables.\nOnce you identify some useful articles, these can provide further inspiration and specificity. Many journal articles will give you a helping hand as the authors must provide several keywords relating to the article. For example, Figure 10.1 from Schroeder and Epley (2015) highlights the keywords that describe their article.\n\n\n\n\n\n\n\nFigure 10.1: Keywords on the front page of Schroeder and Epley (2015).\n\n\n\n\nThe majority of articles will post keywords under the abstract. Here, we can see there are seven words or short phrases that summarise the content of the article. Sometimes they are not truly relevant to the topic (e.g., open data here), so you will need to skim a few articles to recognise recurring themes and potentially useful keywords.\n\n10.1.2 Search strategies\nOnce you have some keywords, your next step will be to try and find more articles. The two main data bases you will use are the University of Glasgow library and Google Scholar.\nYou can access the University of Glasgow library through your student portal. This is the database that the university uses to pay for access to journal articles and ebooks. Glasgow has a huge number of journals available, so this will be one of your best resources as you may be asked to pay for articles if you access journal websites directly, never pay for articles though, there is always a way to find them. Google Scholar is also a valuable resource that can return different results. A combination of these two databases will be a good starting point for any essay or report.\n\n\n\n\n\n\nWarning\n\n\n\nNever pay for journal articles. We have a huge library at Glasgow, so you will almost always find the article by searching for the title. If it is not available, then there are other strategies like searching the title on Google Scholar or regular Google and there might be a PDF someone has posted. Authors can often freely share an author manuscript (also known as a post-print) which contains the same text as the final article but without the fancy journal formatting.\n\n\nEnter your keywords in the search bar of these data bases. You can enter one word or phrase and the data base will try to locate resources that contain that word. For example, we might want to find additional articles investigating job candidates’ speech (Figure 10.2).\n\n\n\n\n\n\n\nFigure 10.2: Searching for articles using one keyword.\n\n\n\n\nHowever, it is usually much more powerful to combine search terms to provide more precise results. If you enter single words or phrases, you might find there are thousands of results which contain mostly irrelevant articles. You can use two or more keywords to look for more specific articles (Figure 10.3).\n\n\n\n\n\n\n\nFigure 10.3: Searching for articles using multiple keywords.\n\n\n\n\nHere, you can see we have used speech AND decision making AND hiring. The capitalised AND is called a Boolean operator. It is used to link together the three words. It means we only want articles that contain the three words. Not one of them, not two of them, but all three. Using AND narrows down your search. Alternatively, you can use OR which expands your search to look for two or more terms. AND will provide fewer results and OR will provide more. You can also use NOT to rule out particular terms.\n\n\n\n\n\n\nNote\n\n\n\nYou can do this in the single search bar by entering the Boolean operators yourself. Alternatively, if you click advanced search, you can add search boxes and choose from AND, OR, and NOT for each term. You can also start to filter your results to only return results from a date range, if you only wanted articles from say the past 5 years.\n\n\nYou can also use Boolean operators in Google Scholar to combine the search terms gender AND “hiring decisions”. This means we only want search results that contain both elements (Figure 10.4).\n\n\n\n\n\n\n\nFigure 10.4: Using Boolean operators in Google Scholar.\n\n\n\n\nWe surround the phrase “Hiring decisions” with quotes. This forces databases to search for the specific phrase exactly as typed in the quotes. If we did not surround it by quotes, we can get search results that contain the words hiring and decisions separately or together. If they are separate, the results might not be quite what we are looking for.\nAs a final literature searching tip, once you find an article that is precisely on the topic you are searching for, you can look at articles in it’s reference list and at articles that have since cited it. This is no guarantee there will be something useful, but you can often benefit from the citation trees of your key articles.\nOn the library portal, you can see articles that your target articles cites, which will show the articles in its reference list that are readable by the library database (Figure 10.5).\n\n\n\n\n\n\n\nFigure 10.5: Identifying articles that a target article cites in the library portal.\n\n\n\n\nAlternatively, on Google Scholar, you can look through the articles that have since cited your target article (Figure 10.6). You will get fewer hits for more recent articles as there has been less time for another article to be published, but its another useful strategy for identifying potentially useful articles.\n\n\n\n\n\n\n\nFigure 10.6: Identifying articles that have since cited your target article in Google Scholar.\n\n\n\n\nFor further tips, see the University of Glasgow library guide on how to search for articles and a brief video navigating around the library search function.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Finding, Reading, and Organising Journal Articles</span>"
    ]
  },
  {
    "objectID": "06-Writing-01-Reading.html#using-a-reference-manager-to-store-your-results",
    "href": "06-Writing-01-Reading.html#using-a-reference-manager-to-store-your-results",
    "title": "10  Finding, Reading, and Organising Journal Articles",
    "section": "\n10.2 Using a reference manager to store your results",
    "text": "10.2 Using a reference manager to store your results\nThroughout the programme, you must use APA 7th edition. Although you could download each article and manually enter the citation and reference list entries, there are more efficient ways to provide you with more time in other areas of your report or essay writing. A reference manager will help to keep your research organised and it will do a lot of the heavy lifting when it comes to entering citations and creating the reference list.\nOur recommendation is Zotero which you can download for free at https://www.zotero.org/. There are alternatives (such as EndNote which the university endorses as approved software), but most of the psychology team prefer Zotero. Under preferences, make sure you select APA 7th edition to format the citations and references correctly.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAs third-party software which requires you to create an account, we recommend not using the same password as your university account.\n\n\nUsing Zotero, you can:\n\nInstall a plugin to save articles you find through your web browser.\nIf there is an open access version of the article PDF, Zotero will automatically save it.\nManually upload PDFs and Zotero will try to find the key metadata such as the title, volume number etc.\nCreate folders to keep your research organised into folders, such as one for each assignment.\nCreate shared folders to add and access the same articles with people you are working with.\nCopy citation and reference lists into your assignment.\nUse the Zotero plugin in Word or Google Docs to enter citations and automatically create a reference list.\nAdd notes and highlights to each article you read within Zotero.\nSync your library across devices, so you can download articles on your laptop, but read the articles on your phone or tablet.\n\nJust keep in mind, Zotero cannot always find all the information or it gets some of the details wrong. So, you may have to manually enter/edit the details for the citation/reference to be formatted correctly. This is why it is still important to learn the key details of APA formatting, but you are using your understanding more efficiently to spot mistakes rather than manually format each entry in your assignment.\nIf you like to follow along to a video, there are some helpful resources on YouTube to guide you through a lot of the basics:\n\nMcGill University has a playlist of a short tutorials.\nThere are also longer tutorials working through the features of Zotero.\n\nThe Zotero website also has a quick start guide if you prefer a written explanation in addition to detailed documentation.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Finding, Reading, and Organising Journal Articles</span>"
    ]
  },
  {
    "objectID": "06-Writing-01-Reading.html#reading-journal-articles",
    "href": "06-Writing-01-Reading.html#reading-journal-articles",
    "title": "10  Finding, Reading, and Organising Journal Articles",
    "section": "\n10.3 Reading journal articles",
    "text": "10.3 Reading journal articles\nNow you have one or two articles, the ability to read them might sound obvious, but research (e.g., Kershaw et al., 2018) consistently shows students find it difficult at first to summarise and critically evaluate empirical research. Our students have a range of backgrounds, so we want to make sure everyone has the skills to read and evaluate published research.\nJournal articles have a different structure and writing style than textbooks or news articles. Usually, they are not written to be a thrilling bedtime read. They can be quite dense with lots of technical jargon. This means - particularly early in your degree - you must be quite strategic in how you read journal articles.\nUntil you learn about different statistical tests, the introduction and discussion sections will be most accessible. The introduction provides the background to the study and outlines what the study is trying to achieve. The discussion recaps what results the authors think they found and puts them in context. As you progress through your research methods courses, you will understand more of the method and results.\n\n10.3.1 Types of Journal Article\nBefore we introduce the QALMRI method, it is important you recognise there are different types of journal article. The QALMRI method mainly applies to original quantitative research, so here is a list of common journal articles and types of research you may come across:\n\nOriginal research: quantitative studies: Potentially the most common type of research in psychology. These articles contain an individual study or a series of studies where the researchers collect numeric data to answer their research question. This is what we will focus on for this tutorial.\nOriginal research: qualitative studies: Some research follows a different methodological philosophy where they collect non-numerical data, such as identifying themes in forum posts. The QALMRI method would not totally apply here as qualitative research typically does not test hypotheses, but you would identify the authors’ broad and specific research questions and their important results.\nSystematic reviews and/or meta-analyses: Researchers may want to identify all the relevant articles on a topic and collate their findings. In a systematic review, the authors provide an overview of the findings in words. In a meta-analysis, the authors apply statistical techniques to calculate the average effect size across studies and how much the effect sizes vary.\nReview article: Instead of trying to identify all relevant articles in a systematic review, a review is less comprehensive. Researchers typically write review articles to explain a topic to readers or outline a theory.\nEditorials: Editors of a journal may write short introductions to a collection of articles they are publishing or announce a new policy for their journal.\nCommentary or opinion articles: Commentary or opinion articles allow authors to present their viewpoint on a topic, typically in response to another article. For example, if a set of authors disagree with the methods or interpretation of an original article, they can write a commentary or opinion article to explain why they disagree. ### The QALMRI Method\n\nOne evidenced-based strategy to learn how to read journal articles containing original quantitative research is known as the QALMRI (Question, Alternatives, Logic, Method, Results, and Inferences) method (Brosowsky et al., 2020). You can read more about the method on Crump’s (2018) Research Methods Lab Manual. When reading an article, try and answer the following questions:\nQuestions\n\nWhat was the broad question (the general topic of interest) being asked by this research project?\nWhat was the specific question (what this specific experiment will address) being asked by this research project?\n\nAlternatives\n\nWhat was the author’s hypothesis (the hypothesis they are testing)?\nWhat were the alternative hypotheses (what other explanations could there be that the authors ruled out)?\n\nLogic\n\nWhat was the logic of the hypothesis? i.e., if the hypothesis was true, what should we expect to happen?\n\nMethods\n\nBriefly describe the study design (i.e., experimental or correlational?) and sample.\nWhat were the variables? i.e., independent and dependent variables for experiments; variables for correlations.\nBriefly describe the study procedure in everyday terms.\n\nResults\n\nWhat were the important results?\n\nInferences\n\nWhat did the authors conclude from their study?\nHow did the authors use the results to make inferences and conclusions about the hypothesis and research question?\n\n10.3.2 The QALMRI Method in Action\nThe authors of the QALMRI method (Brosowsky & Parshina, 2017) provide a worked example in Appendix A so you can see what information you must identify in a journal article. The following answers are reproduced from Brosowsky and Parshina with some minor edits. They evaluated the study “Ecological validity of the testing effect: The use of daily quizzes in introductory Psychology” by Batsell et al. (2017):\n\n10.3.2.1 Questions\n\nWhat was the broad question (the general topic of interest) being asked by this research project?\n\nWhat kinds of teaching techniques will improve student learning in a classroom?\n\nWhat was the specific question (what this specific experiment will address) being asked by this research project?\n\nWill daily quizzes enhance retention of assigned study material?\n\n10.3.2.2 Alternatives\n\nWhat was the author’s hypothesis (the hypothesis they are testing)?\n\nHypothesis 1: Daily quizzes will improve memory for study material whether the material had appeared in a quiz or not.\n\nWhat were the alternative hypotheses (what other explanations could there be that the authors ruled out)?\n\nHypothesis 2: Daily quizzes will only improve memory for study material that appeared in the quizzes.\nHypothesis 3: Daily quizzes will not improve memory for study material.\n\n10.3.2.3 Logic\n\nWhat was the logic of the hypothesis? i.e., if the hypothesis was true, what should we expect to happen?\n\nIf hypothesis 1, then a quizzed group will perform better than a study-only group on a memory test for all the studied material.\nIf hypothesis 2, then a quizzed group will perform better than a study-only group on a memory test, but only for the material that appeared on the tests.\nIf hypothesis 3, then a quizzed group will not perform better than a study-only group on a memory test for the studied material. Note: In essence, this is the null hypothesis of no difference.\n\n10.3.2.4 Methods\n\nBriefly describe the study design (i.e., experimental or correlational?) and sample.\n\nThe study used a 2x3 factorial design (quasi-experimental). The sample included 64 university students from a range of levels in the authors’ department.\n\nWhat were the variables? i.e., independent and dependent variables for experiments; variables for correlations.\n\nIndependent Variable A: Class (study-only and quiz): - One class received daily quizzes while the other did not.\n\nThis variable is between-subjects and quasi-experimental (students were not randomly assigned to classes).\n\nIndependent Variable B: Question-Type (identical, similar, and new):\n\nMemory test questions were either identical to those used in the quizzes (identical), similar in content to those used in the quizzes (similar), or did not appear in the quizzes (new).\nThis variable is within-subjects and experimental (questions were randomly assigned to each condition).\n\nDependent Variable: Accuracy averaged across three memory tests.\n\nBriefly describe the study procedure in everyday terms.\n\nStudents enrolled in two Introduction to Psychology courses took part in the study. The participants were all assigned textbook readings which consisted of material not taught during the lectures. One class received daily quizzes (21 total), while the other did not. Memory was tested three times throughout the term using 15 multiple-choice questions. Test questions were either identical to the quiz questions (identical), similar in content to the quiz questions (similar), or questions that did not appear in the quizzes (new).\n\n10.3.2.5 Results\n\nWhat were the important results?\n\nThe Class x Question-Type ANOVA and follow-up t-tests show that the quiz group outperformed the study-only group on all three question types. However, this difference was greatest for identical questions (21.8%), then similar questions (17.6%), and smallest for new questions (12.7%).\nANOVAs with follow-up t-tests were also run separately on the quiz and study-only groups. The results for the study group showed no significant differences in performance across the identical (58.4%), similar (62.8%), and new (60.4%) question types. The results for the quiz group however, showed that performance for the identical (80.2%) and similar (80.4%) questions was significantly better than performance for the new questions (73.1%).\n\n10.3.2.6 Inferences\n\nWhat did the authors conclude from their study?\n\nThe results of the experiment show enhanced retention of studied material when participants were quizzed daily regardless of whether the study material was actually presented during the quizzes or not.\nThe authors conclude that they successfully replicated the testing effect, previously shown in laboratory settings, in a naturalistic classroom setting. Furthermore, they conclude that the testing benefit generalizes to non-quizzed material and therefore instructors do not need to quiz all of the study material to gain the testing effect benefit.\n\nHow did the authors use the results to make inferences and conclusions about the hypothesis and research question?\n\nThese results are consistent with the original hypothesis (Hypothesis 1) and suggest that periodic quizzes can enhance the retention of assigned material (specific question) and testing could be used as an effective teaching technique to improve student learning in a classroom setting (big question).\n\n10.3.3 Exercise: Applying the QALMRI Method\nNow you have read about the QALMRI method and saw how you can answer the 11 questions based on the information in a journal article, it is time to practice yourself on a new article.\nPieger et al. (2018) is available open access through the journal Frontiers in Education. They studied the disfluency effect: the idea that writing information in a harder to read font requires greater concentration which can lead to improved recall when quizzed on the topic. Read through the article and try to answer the questions from the QALMRI method. The activity below is based on downloading the article as a PDF to see page numbers, but you could check your understanding of the QALMRI questions using either the web or PDF version.\nEach question has two elements: the page number that includes the information and a hidden solution providing a longer explanation. Make sure you attempt each question on your own first and then check you identified the correct information by looking at the solution.\n\n10.3.3.1 Questions\n\nWhat was the broad question (the general topic of interest) being asked by this research project?\n\nPage  best includes this information.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOn the middle left of page 2, their broad question can best be described as “is disfluency a desirable difficulty and does it activate analytic monitoring?”.\n\n\n\n\nWhat was the specific question (what this specific experiment will address) being asked by this research project? There are two research questions the authors are interested in here, but they are both on the same page.\n\nPage  best includes this information.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOn the bottom right of page 3, their specific research questions are helpfully in the research questions sub-section. They are asking two questions: (1) does viewing disfluent then fluent test activiate analytic monitoring and (2) does viewing fluent then disfluent text activate surface level monitoring?\n\n\n\n\n10.3.3.2 Alternatives\n\nWhat was the author’s hypothesis (the hypothesis they are testing)?\n\nPage  best includes this information.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOn the bottom right of page 3, hypothesis 1: when participants view disfluent then fluent texts, they expect no difference between disfluent text and fluent text on their outcomes.\n\n\n\n\nWhat were the alternative hypotheses (what other explanations could there be that the authors ruled out)?\n\nPage  best includes this information.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOn the bottom right of page 3, hypothesis 2: when participants view fluent then disfluent texts, they expect the outcomes such as ease of learning to be lower for disfluent text than fluent text. Note: This is slightly different to the previous example. Pieger et al. (2018) did not outline competing hypotheses, they just outlined their predictions in two parts for each presentation order.\n\n\n\n\n10.3.3.3 Logic\n\nWhat was the logic of the hypothesis? i.e., if the hypothesis was true, what should we expect to happen? There is no page number to identify here, you just need outline what results would support each hypothesis.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nFor hypothesis 1, there will be no difference in the dependent variables between disfluent text and fluent text when participants are shown the materials in the disfluent then fluent order.\nFor hypothesis 2, the dependent variables will be lower for disfluent text than fluent text when participants are shown the materials in the fluent then disfluent order.\n\n\n\n\n10.3.3.4 Methods\n\nBriefly describe the study design (i.e., experimental or correlational?) and sample.\n\nPage  best includes this information.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOn the left middle of page 4, the study is a 2x2 mixed design. Note: the authors do not specifically outline the design in shorthand, but they describe each independent variable. The sample included 65 university students from the authors’ department.\n\n\n\n\nWhat were the variables? i.e., independent and dependent variables for experiments; variables for correlations.\n\nPage  best includes this information.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nIV1 is between-subjects and includes the contrast group for which order they see the text. IV2 is within-subjects and includes both fluent and disfluent text conditions. The study has several dependent variables including ease of learning, prediction of performance, and actual memory performance.\n\n\n\n\nBriefly describe the study procedure in everyday terms.\n\nPages  and  best include this information. There is also a diagram to help explain the procedure on page .\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nFor each fluent and disfluent text, participants briefly saw the text and completed the dependent variables related to the first monitoring judgments. For example, rating how confident they were about their performance. Then the participants studied the text for up to 15 minutes and completed the second monitoring judgments. Depending on IV1, they either read the disfluent text first or the fluent text first. When they finished reading both texts, they completed knowledge tests for both texts at the end.\n\n\n\n\n10.3.3.5 Results\n\nWhat were the important results? There are several pages of results to cover each dependent variable, so for the purposes of this exercise, focus on the performance results. Did participants recall more information about the fluent or disfluent text?\n\nPage  best includes this information.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOn the bottom left of page 7, performance is the last dependent variable they analyse before summarising all their results. There was a statistically significant main effect of fluency. This means if you ignore which contrast group they were allocated to, performance was higher for fluent text than disfluent text. Note: the authors also use something called Bayesian statistics which we do not cover in this course.\n\n\n\n\n10.3.3.6 Inferences\n\nWhat did the authors conclude from their study?\n\nPage  best includes this information.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOn the top and middle of page 7, the authors recap their results at the start of the discussion. When the fluent text was presented first, participants use fluency as a cue for all learning judgements (e.g., ease of learning and prediction of performance). Participants rated these variables as lower for the disfluent text than for the fluent text. However, when the disfluent text was presented first, participants no longer use fluency as a cue for learning judgments and there was no significant difference between fluent and disfluent texts.\n\n\n\n\nHow did the authors use the results to make inferences and conclusions about the hypothesis and research question?\n\nPage  best includes this information.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOn the top and middle of page 7, the authors concluded their results support both hypothesis 1 and hypothesis 2. Hypothesis 1 predicted there would be no difference in learning judgments when participants read the disfluent then the fluent text. Hypothesis 2 predicted learning judgments would be lower for the disfluent text when participants read the fluent then the disfluent text.\n\n\n\n\n10.3.4 Organising journal articles\nThe QALMRI method applies to individual journal articles, but in your assignments, we expect you to read several articles to build a literature review. You can take the QALMRI method and create a table using something like Word or Excel to collate the articles you read. For example:\n\n\n\n\n\n\n\n\n\n\n\n\n\nCitation\nQuestion\nAlternative\nLogic\nMethods\nResults\nInference\n\n\n\nBatsell et al. (2016)\n1. What kinds of teaching techniques will…\n3. Hypothesis 1: Daily quizzes will improve memory…\n5. If hypothesis 1, then a quizzed group will…\n6. The study used a 2x3 factorial design…\n9. The Class x Question-Type ANOVA…\n10. The results of the experiment show…\n\n\nPieger et al. (2018)\n1. Is disfluency a desirable difficulty…\n3. Hypothesis 1: When participants view disfluent…\n5. For hypothesis 1, there will be no difference…\n6. The study is a 2x2 mixed design…\n9. There was a statistically significant main effect of fluency…\n10. When the fluent text was presented first…\n\n\n\n\n\nEach row can be one article you read and you can group each section of the QALMRI method as separate columns. As you build your literature review, you can see similarities and differences across the studies. You also have prompts for critical evaluation where you can comment on features like the sample and sample size. Organising your notes like this will help you stay organised as its unlikely you will remember every key feature of the 10th or 20th article.\nIn addition, you might find these blog posts by Dr. Raul Pacheco-Vega - a political scientist - helpful when thinking about how you can approach a literature review and keep your reading organised:\n\nHow to undertake a literature review: This post talks about how you can approach searching for literature in a new area or in your case, a new assignment.\nSynthesizing different bodies of work in your literature review: This post demonstrates Raul’s approach to recording the results of a literature review. You might find it helpful for structuring your own approach. Just keep in mind as a political scientist, there is a lot of emphasis on quotes which we do not tend to use in psychology.\n\n10.3.5 Summary and Additional Resources\nLike any skill, learning how to recognise the key information in journal articles takes time and practice. Journal articles are typically written for expert audiences, so they may not specifically label key information you are looking for. For example, in the exercise above, Pieger et al. did not say they used a 2x2 mixed design. You had to recognise the information in the main text and piece it together. As you read more journal articles, you will get quicker at recognising this information, allowing you to focus more time on reading the article critically than simply understanding it.\nIf you would like additional tips and resources on reading journal articles, you might find the following articles useful:\n\nThis short blog by Raff (2016) aims to explain journal articles to non-scientists, so it should provide an accessible introduction.\nThis short article by Pain (2016) has quotes from several high-profile researchers where they explain how they approach reading a scientific paper.\nThis long article by Carey et al. (2020) discusses how to approach reading a journal article for different purposes by presenting 10 rules to follow.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Finding, Reading, and Organising Journal Articles</span>"
    ]
  },
  {
    "objectID": "06-Writing-02-Rationale.html",
    "href": "06-Writing-02-Rationale.html",
    "title": "11  Introductions and Identifying the Rationale",
    "section": "",
    "text": "11.1 The introduction\nThe introduction provides the background to your study for what influenced your work. Relating back to the hypothetico-deductive model, the introduction focuses on the cycle between previous research and identifying your research question. You need to know what research and theory already exists before you can identify an opportunity for your own work. There are four key components:\nThe introduction is the top of the hourglass shape of a report, starting broad and becoming more specific as you get closer to the end (Figure 11.2). You do not typically have sub-headings to present these components as specific sub-sections or dedicate just one paragraph to each part, rather they are key concepts to cover as you move through the introduction.\nFigure 11.2: The introduction highlighted as the focus of this chapter.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introductions and Identifying the Rationale</span>"
    ]
  },
  {
    "objectID": "06-Writing-02-Rationale.html#the-introduction",
    "href": "06-Writing-02-Rationale.html#the-introduction",
    "title": "11  Introductions and Identifying the Rationale",
    "section": "",
    "text": "Introduction to the general topic and research question.\nEvaluation of relevant research and theory.\nEstablish a rationale for the current study.\nPresent the research question and hypothesis (where applicable).\n\n\n\n\n11.1.1 Introduction to the general topic and research question\nThe opening paragraph or two to the introduction is the broadest section. We are at the top of the hourglass and this is where you introduce your reader to the key concepts. You are trying to provide the rationale behind your overall topic, so you might include statistics to highlight the extend of a given problem. You might also present definitions for key concepts to make it clear to your reader what you are researching. This part of the introduction is all about setting the scene to your reader and establishing why it is a topic worth addressing.\n\n11.1.2 Evaluation of relevant research and theory\nThe literature review should provide a critical and focused exploration of your topic area. You do not need to try and summarise all the research that has ever been done on your topic, you are trying to identify what is most relevant and up-to-date.\nCritical evaluation is an important skill that takes time to develop. Instead of just listing and describing the studies in your literature review, you must add narrative and identify gaps in current knowledge. Try and ask yourself as you are documenting the studies you find:\n\nAre the findings consistent across studies, or do they provide a more complicated mixed picture?\nAll studies are not created equally, each will have their own strength and weaknesses. You do not need to walk through the strengths and limitations of each study, but you will make an assessment on how reliable you consider the evidence base to be.\nIs there a relevant theory or framework that explains the observations of previous research? Do the studies support this theory or suggest there are limitations?\n\n11.1.3 Establish a rationale for the current study\nBy the end of the introduction, you are trying to clearly communicate what opportunity you have identified in past research and present your argument for why it is important to address that opportunity. This is the rationale as the reasoning behind why your study is necessary. Sometimes the opportunity is to explore something new, other times you could identify limitations in past research that need addressing. There is not one single valid approach to the rationale, it all depends on the strength of your argument you presented throughout the introduction.\nTo show the range of possibilities for the strategy behind your rationale, we wrote a specific section and activities on identifying the rationale below.\n\n11.1.4 Present the research question and hypothesis\nThe final part of your introduction should be a summary of what you want to find out in your study (your research question) and what you predict you will find based on previous research (your hypothesis). The most effective introductions will present a clear narrative from the start to the end, so the reader can almost guess what your rationale, research question, and hypothesis is before you tell them.\nDepending on the aim of your study, remember a research question is essential, but a hypothesis is not. If your study is exploratory, there might not be enough research to make a prediction, so the aim of your study is gather evidence. If you study is confirmatory, there will be a larger research base and the aim of your study is to test a specific prediction.\n\n11.1.4.1 Research questions\nResearch Questions (RQs) are broad overarching questions of interest. They are posed literally as questions and summarise what you hope to answer through your study. Research questions should be:\n\nClear: specific enough to be understood without further explanation.\nFocused: narrow enough that you can answer it with your project.\nComplex: there is enough discussion to create a report out of it.\nConcise: to the point so it is more likely to be understood.\nArguable: there is not already a clearly accepted answer and there is a rationale for your project, regardless of whether it is more of a novel approach or it is a direct replication of one specific study.\n\nIt is crucial to base your research question on previous research. Make sure you have read enough to pose your research question as you need to know what is already out there before you can present the rationale for your study.\nAn example of a poor research question could be: Do undergraduate students suffer from text anxiety? It is quite vague and the context is unclear for what is being compared and how. A better research question could be: Do undergraduate students self-report greater test anxiety than postgraduate students? This is more focused on the actual research at hand, showing who you are comparing and giving more detail on what you want to measure.\n\n11.1.4.2 Hypotheses\nHypotheses are specific statements making a prediction for what you will find. Hypotheses should be:\n\nClear: you can easily understand the statement.\nSpecific: you cover all the key information, such as who, what, and how.\nFalsifiable: you should be able test the prediction to show how evidence either supports or refutes it.\nOperationalised: to state how you are measuring your constructs.\n\nTo break down these features, we can start with a good example of: We hypothesise that there will be a positive correlation between effort regulation scores and help-seeking scores in mature students, as measured through the MSLQ. We can then manipulate different features for emphasis:\n\nMissing operationalisation: We hypothesise that there will be a positive correlation between effort regulation scores and help-seeking scores in mature students.\nNot testable: We hypothesise that there might be a positive correlation between effort regulation scores and help-seeking scores in mature students.\nNot a hypothesis: Is there a positive correlation between effort regulation and help-seeking?\n\nDepending on how much previous literature is out there and how convinced you are by it, you can pose a directional or non-directional hypothesis. A directional hypothesis makes a prediction in a specific direction, for instance group A will be faster than group B. On the other hand, a non-directional hypothesis predicts there will be an effect, but it is not clear what direction it will be. For example, the speed of group A will be different to the speed of group B.\nYou might pose a non-directional hypothesis for exploratory research to help your focus. For confirmatory research, you should be able to specify a clear directional prediction to test.\n\n11.1.4.3 How does this relate to your stage one group report?\nFor your stage one group report, you will be focusing on either the relationship between two variables or comparing the difference in one outcome between two groups. Depending on which approach you and your group are taking, the terminology you use for the research question and hypothesis will differ.\nCorrelations assess whether there is a relationship between two variables. You might have a non-directional prediction where you think two variables are correlated, but you are not sure how. Alternatively, you might have a directional prediction where you expect a certain correlation direction. Positive correlations are where if one variable increases, the other variable tends to increase. Negative correlations are where if one variable increases, the other variables tends to decrease. If some of the terminology is unfamiliar to you at this point, we do not cover correlations and continuous predictors until week 7 after reading week.\nIn contrast, comparing groups assesses whether there is a difference between two groups on your outcome. If you have a non-directional hypothesis, you think there might be a difference between the two groups, but you are not sure which direction. If you have a directional hypothesis, you expect one group to score higher than the other group. You will learn about t-tests and categorical predictors for the analysis techniques suited to this kind of research question in week 8.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introductions and Identifying the Rationale</span>"
    ]
  },
  {
    "objectID": "06-Writing-02-Rationale.html#rationale",
    "href": "06-Writing-02-Rationale.html#rationale",
    "title": "11  Introductions and Identifying the Rationale",
    "section": "\n11.2 Identifying the rationale",
    "text": "11.2 Identifying the rationale\nNow we have introduced the key components of an introduction, we want to spend a little more time on different strategies for the rationale. As much as we would love to just tinker as scientists, each study tries to address some kind of problem the authors have identified in previous research. These are often small tweaks. Keep the phrase “standing on the shoulders of giants” in mind as science typically advances through minor changes rather than completely revolutionary ways of studying a topic. Approaches for the rationale will differ by discipline and sub-discipline but there are some common strategies you can look out for.\nIn this section, we have provided seven examples of the rationale from different empirical psychology articles, including exploration, replications, testing competing theories, applying the methods from one study to a new sample/population or topic, and addressing limitations in past research. The rationale should be built as a thread running throughout the introduction as you narrow down to what your study focuses on, but we have isolated paragraphs that specifically comment on the opportunity they have identified. For each example, we have explained the general approach, provided an extract, and described in our own words the authors’ line of argument.\nAt the end, we have some activities to test if you can recognise different strategies. By the end of this resource, you will be able to identify different strategies behind the rationale in published research and hopefully clearly communicate the rationale in your own reports.\n\n11.2.1 Exploring an under researched topic\nAlthough completely novel research is rare, there are times when there is little knowledge about a population or topic. For example, there might be a change in practice or a cultural phenomenon that means you have little prior research to turn to. This means your study would follow more of an exploratory approach to gather information and learn about a new population or topic.\nExample: Beaudry et al. (2022, pg. 2) were interested in what incoming undergraduate students knew about open science practices. Moving out of the replication crisis, increasing numbers of researchers adopted open science practices and more journals were encouraging or enforcing them. As this was a rapid shift in how researchers conducted studies, Beaudry et al. explored undergraduate students’ beliefs about open science practices as they had little prior research for this cultural shift.\n\n“…An understanding of contemporary methodological practices—and problematic methodological practices—is essential for becoming informed and critical consumers of psychological knowledge. Studies have explored strategies for educating psychology students about replicability and open science practices (e.g., Chopik et al., 2018; Grahe et al., 2012; Jekel et al., 2020). These initiatives may help ingrain open science norms and change attitudes about research practices, but we know little about what students know or believe about open science research practices prior to entering the university classroom. This knowledge could be useful for two main reasons… [two paragraph gap]\n\n\nTo examine this, we conducted a descriptive study, asking incoming students in undergraduate psychology courses about their beliefs regarding reproducibility and open science practices. Our survey encompassed questions concerning norms (how students felt research should be conducted), norms in practice (how students believe psychological research is conducted), and replicability (how replicable students believe psychological research is). Our study was exploratory (see Wagenmakers et al., 2012) and descriptive; as such, we did not specify or test hypotheses.”\n\n\n11.2.2 Direct replication of a previous study\nAuthors can argue it is important to verify the results of a specific previous study. This means they would use the exact same method as the target study but in a new sample to find out if you can get the same results. The rationale for a direct replication often explains why it is important to replicate individual studies in general or why the target study should be replicated. For different features of a study you might highlight to motivate a direct replication, Alister et al. (2021) polled researchers on features that would increase or decrease their confidence in replicating the study’s results.\nExample: Micallef and Newton (2022, pg. 2) investigate the use of concrete examples in learning abstract concepts. Their article is a direct replication of a specific study they highlight. They explain Rawson et al. is an influential study but other research questions the consistency of the findings, so they want to replicate their method as closely as possible to see if they get the same results.\n\n“Thus, the evidence base for the use of concrete examples in teaching would appear to be mixed. Given the potential significance of Rawson et al. for the teaching of psychology, but set against some mixed findings from other studies, we tested the replicability of the key finding from Rawson et al. Rawson gave their participants definitions of some abstract ideas from psychology, followed by multiple different concrete examples of those ideas. A control group received only the definitions, repeatedly. Both groups were then tested to determine whether they could match examples to definitions. The group which had received the concrete examples were better able to match definitions to examples including, critically, examples that they had not previously seen. Rawson et al. suggested their study was amongst the first study of its kind to use a ‘no-example’ control group, a design which considerably strengthened the conclusions but highlighted the paucity of well-controlled research into the application of this idea to learning and teaching, and further emphasised the need for replication of the findings from this key study.”\n\n\n11.2.3 Conceptual replication of a previous study\nWhereas a direct replication wants to copy the method of a study as closely as possible, a conceptual replication tries to test the same idea or hypothesis using different methods (Nosek & Errington, 2017). The aim is to find out if you can make similar conclusions under different methods and increase your confidence in an explanation or theory of human behaviour.\nKeep in mind there is a continuum between a direct and conceptual replication. It comes down to judgement and subject expertise on what differences would turn a direct replication into a conceptual replication. For instance, Lebel et al. (2018) present a replication recipe where authors rate their methods as exact, close, or different on features including measures, procedure, and location.\nExample: Ekuni et al. (2020, pg. 5) wanted to learn about study strategies in a different population. They highlighted previous studies focused on US American samples which tend to be relatively higher in education level and socioeconomic status than some other countries. Therefore, they took the method of Karpicke et al. (2009) - a US-based study - and applied it to a sample in Brazil to investigate if they could find a similar pattern of results.\n\n“This is even more important in countries in which educational outcomes are poorer than those in the U.S. and in which the need for interventions that can help improve academic success and reduce educational inequities is dire (see UNESCO, 2015; Master, Meltzoff, & Lent, 2016), such as Brazil. To do so, it is necessary to carry out a conceptual replication on preference of study techniques in more diverse non-WEIRD contexts to analyze whether culture of origin, SES, and sex can influence students’ study strategies, because designing adequate interventions may have to consider tailoring to fit particular characteristics of different types of students.”\n\n\n11.2.4 Testing competing theories or conflicting research\nAs you research a given area, you recognise patterns across the findings of articles. Imagine you are studying the effectiveness of an intervention treatment compared to a control treatment. Do all the studies show the intervention works, do most studies show the intervention works, or is there completely mixed evidence on whether the intervention performs better than the control? If there are conflicting findings, then the aim of your study could be to add more evidence.\nRelatedly, there might be competing theories on the same phenomenon. One theory might expect participants to score higher in one condition compared to another, while another theory expects participants to score higher in the other condition. This means the aim of your study could be to find out which theory is best supported.\nExample: Bartlett et al. (2022, pg. 2) combined both components after observing some studies showed daily smokers’ attention would gravitate towards smoking images more than non-daily smokers, whereas other studies showed the opposite pattern. There were theories which could support each observation, so Bartlett et al. aimed to test which theory and pattern of results would receive the most support.\n\n“…Collectively, these studies show that smokers consistently display greater attentional bias towards smoking cues than non-smokers, but it is not clear whether lighter or heavier smokers show greater attentional bias.\n\n\nTo address this inconsistency, the current study focused on comparing attentional bias towards smoking cues in daily and non-daily smokers. While most studies use the visual probe task to measure attentional bias, their relatively small sample sizes and inconsistent research design features complicate drawing conclusions from the mixed findings. Therefore, we used a much larger sample size than previous studies and manipulated different features of the visual probe task.”\n\n\n11.2.5 Applying the methods of one study to a new sample/population\nIt is important to consider whether your planned measures and/or manipulations are valid and reliable. This means you could identify components of the method you consider robust in previous research, but you apply them to a new sample or population that would let you address your research question.\nThis is similar to the argument in the conceptual replication example, but there is a subtle difference in the aims of the approach. In a conceptual replication, you want to know whether you can find similar results using different methods. The emphasis is on comparing your findings to a target study to see if they are similar or different. On the other hand, in this approach, you want to learn something new by applying methods from one study to a new sample. The emphasis is on addressing a new research question using methods that have a precedent in past research.\nExample: Veldkamp et al. (2017, pg. 128/129) investigated the storybook image of scientists in scientists themselves. In their introduction, they outlined studies on the general public’s perception of scientists’ characteristics like honesty and objectivity. However, the authors explained they were unaware of similar research of scientists’ perception of scientists’ characteristics. This means they were applying methods to a new sample that was previously under researched.\n\n“…More recently, European and American surveys have demonstrated that lay people have a stable and strong confidence both in science (Gauchat 2012; Smith and Son 2013) and in scientists (Ipsos MORI 2014; Smith and Son 2013). For example, the scientific community was found to be the second most trusted institution in the United States (Smith and Son 2013), and in the United Kingdom, the general public believed that scientists meet the expectations of honesty, ethical behavior, and open-mindedness (Ipsos MORI 2014).\n\n\nAs far as we know, no empirical work has addressed scientists’ views of the scientist. Although preliminary results from Robert Pennock’s “Scientific Virtues Project” (cited in “Character traits: Scientific virtue,” 2016) indicate that scientists consider honesty, curiosity, perseverance, and objectivity to be the most important virtues of a scientist, these results do not reveal whether scientists believe that the typical scientist actually exhibits these virtues…”\n\n\n11.2.6 Applying the methods of one study to a new topic\nRelated to the previous strategy, you might not have a new sample/population you want to learn about, but you might want to apply the methods of a past study to a new topic. For instance, your research question might focus on alcohol but previous studies you are aware of might have used smoking images. The emphasis in this strategy is that you want to learn something new by applying the methods of one study to a different topic.\nExample: Irving et al. (2022, pg. 2) studied the effect of correcting statistical misinformation. Making causal claims about correlations is a common mistake in science journalism when you lose some of the nuance of full journal articles and the authors wanted to know if you could correct that statistical misinformation. Previous studies had corrected other types of misinformation using this technique, but Irving et al. wanted to know whether it would be effective in reducing statistical misinformation. This means they applied the method from one study to a new topic it had not been used on before.\n\n“In this study, we applied the continued influence paradigm, which has traditionally been used to examine general misinformation, to a novel context. We investigated whether it is possible to correct a common form of statistical misinformation present in popular media: inappropriately drawing causal conclusions from correlational evidence. Participants were randomized to one of two experimental conditions: no-correction or correction. They read a fictional news story about the relationship between extended TV watching and cognitive decline, inspired by an article in The New York Times (Bakalar, 2019). Informed by previous research, we designed the correction to be as powerful as possible. We therefore included an alternative explanation, in recognition of the fact that individuals prefer to maintain a complete but incorrect model of an event until they are given an alternative explanation to sufficiently fill the gap left by a simple negation (Lewandowsky et al., 2012). Similarly, we ensured that the correction was from a credible source, that it maintained coherence with the story, and explained why the misinformation was inaccurate (Lewandowsky et al., 2012). The primary, confirmatory hypotheses were that participants in the correction condition would make fewer causal inferences (i.e., rely on the misinformation) and more correlational inferences (i.e., rely on the correction) than those in the no-correction condition, in response to the coded inference questions.”\n\n\n11.2.7 Addressing limitations in the method of a previous study\nEvery study has its strengths and weaknesses, the important thing is being able to justify your choices and acknowledge the limitations. One set of researchers might value a tightly controlled environment at the expense of a more realistic but messier environment, whereas you value a more realistic environment. In this strategy, your research question aims to learn something new by designing a study that addresses the limitations you identify in a past study.\nExample: Bostyn et al. (2018, page 2) were interested in the classic trolley dilemma where participants have the option of letting a tram run over five people or intervene and divert the tram so it runs over one person. Often, this is only a hypothetical dilemma, so the authors wanted to create a more realistic version. Instead of choosing to divert a tram, participants were faced with the option of shocking a cage of five mice or intervening and shocking a cage containing one mouse (the participants were unaware the mice would not actually be shocked). This means the authors wanted to investigate if participants would behave similarly in a more ecological valid task.\n\n“Until recently, this judgment–behavior discrepancy has been an academic concern plaguing only moral psychologists. However, trolley-dilemma-like situations are becoming increasingly relevant to model the moral decisions of artificial intelligence, such as self-driving autonomous vehicles (Bonnefon, Shariff, & Rahwan, 2016). Accordingly, whether or not hypothetical moral judgment is related to real-life behavior is prone to become a matter of public interest. We are aware of one study that has directly compared hypothetical moral judgment with real-life behavior: FeldmanHall et al. (2012) found that people are more willing to harm others for monetary profit in a real-life scenario than they are in a hypothetical version of the same scenario, thus confirming that real-life behavior can differ dramatically from hypothetical judgment. The current research was a first attempt to study this difference in the trolley-dilemma context through the admission of a”real-life” dilemma that required participants to make a trolley-dilemma-like decision between either allowing a very painful electroshock to be administered to five mice or choosing to deliver the entire shock to a single mouse.”\n\n\n11.2.8 Summary\nSo far, we have outlined the strategies behind the rationale from a selection of empirical psychology articles. This is not an exhaustive list, but we wanted to demonstrate the common lines of argument researchers take when explaining what opportunity they identified in past research and how their studies will address that opportunity.\nIt will be rare for studies to neatly fit into just one strategy. They might focus on one component or it might be a combination. Bostyn et al. (2018) addressed limitations in past research but you could also argue it was a conceptual replication by using a more ecologically valid task to see if they could observe similar findings to studies using hypothetical tasks. Likewise, Bartlett et al. (2022) tested competing theories, but also wanted to address limitations in the method of past studies.\nThe important lesson to take away from this is to clearly communicate your line of argument behind the rationale of your study. By the end of your introduction, it should be clear what opportunity you identified in previous research and why it is important for you to address that opportunity with your study.\n\n11.2.9 Activities\nNow that you have read about different strategies for a rationale and explored different examples, it is time to see if you can recognise key features of these strategies yourself. Remember, these are broad descriptions to capture the main features and there are many ways of presenting your argument for the rationale.\n\n11.2.9.1 Independent judgement 1: Muir et al. (2020)\nIn the following extract, Muir et al. (2020) explain their study on promoting classroom engagement through the use of an online student response system.\nAs you read through the extract, consider and select which strategy you think best fits their rationale. After selecting the type of rationale you think best fits, check the explain the answer box to see why we placed it there.\n\n“The use of Socrative has been investigated across a variety of disciplines including physics (Coca and Slisko 2013), physiology (Rae and O’Malley 2017), science (Wash 2014), sports management (Dervan 2014), computing (Awedh et al. 2014), English language (Kaya and Balta 2016), economics (Piatek 2014), and engineering (Dabbour 2016). Statistics courses are another area that may benefit from using Socrative given its potential positive effect on the student learning experience and considering that course evaluations by students taking statistics units tend to indicate poor engagement (Gladys, Nicholas, and Crispen 2012). To the authors’ knowledge, only one study has previously investigated the effect of Socrative specifically for statistics students. Balta and Guvercin (2016) found that the final grades of students enrolled in a statistics class who chose to engage with Socrative-based learning materials prior to their exam were significantly higher than the grades achieved by students who chose not to engage with the Socrative-based learning materials. Although this result is encouraging, the use of a non-randomized, post-test design means that we cannot confirm from this study that there is a beneficial effect for using Socrative, or if the difference in exam scores was due to underlying scholastic aptitude or motivation of the students who chose to engage with the OSRS. Hence, there is a need for further research exploring the use of Socrative specifically within statistics classrooms”\n\n\nWhat is the most fitting type of rationale?\n\nExploring an under researched topic.Direct replication of a previous study.Conceptual replication of a previous study.Addressing limitations in the method of a previous study.\n\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nIn this article, the authors highlight there is one key article that studied a previous topic but they identified several flaws in the method that affect the conclusions. The earlier study by Balta and Guvercin (2016) uses a non-randomised post-test design which is prone to confounds and you cannot make a strong causal conclusion. In the next paragraph not shown here, the authors explain their study will target these limitations by randomising participants into conditions.\n\n\n\n\n11.2.9.2 Independent judgement 2: Harms et al. (2018)\nIn the following extract, Harms et al. (2018, pg. 2) explain their study on the rounded price effect.\nAs you read through the extract, consider and select which strategy you think best fits their rationale. After selecting the type of rationale you think best fits, check the explain the answer box to see why we placed it there.\n\n“In recent years, studies from nearly all subfields of psychology have been under increased scrutiny in the context of the ‘replication crisis’ [2-5]: as several studies suggest, we cannot take reported effects in the scientific literature at face value. As the findings by Wadhwa and Zhang have practical relevance to marketers, independent replication of the effect and a reasonable estimation of its size are desirable. From the theoretical outline of the effect one can expect the effect to be contingent on various factors. As a first step towards a better understanding of these external influences on the effect, a close replication under the same or at least very similar conditions as in the original study is warranted.”\n\n\nWhat is the most fitting type of rationale?\n\nExploring an under researched topic.Direct replication of a previous study.Conceptual replication of a previous study.Addressing limitations in the method of a previous study.\n\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nHopefully, this was quite an obvious one. The authors mention a few times they want to replicate the rounded price effect that was first observed in Wadhwa and Zhang. They justify the direct replication by explaining it has practical implications to marketers and want to repeat the study as close as possible to the original methods.\n\n\n\n\n11.2.9.3 Independent judgement 3: Rode and Ringel (2019)\nIn the following extract, Rode and Ringel (2019, pg. 320) explain their study on comparing the use of R and SPSS software in introductory statistics courses.\nAs you read through the abstract, consider and select which strategy you think best fits their rationale. After selecting the type of rationale you think best fits, check the explain the answer box to see why we placed it there.\n\n“Professors of courses without lab components, and/or courses in which students have high levels of statistics anxiety and diverse mathematical and computational backgrounds, may be left wondering whether it is worthwhile to introduce students to R over other software types. Indeed, ongoing debates in online education communities suggest that the use of R with undergraduates, and how the experience compares to teaching software such as SPSS, is very much an open question that many educators would like to see answered empirically (e.g., see https://www.researchgate.net/post/Is_it_easier_for_students_to_learn_statistics_using_SPSS_or_R). Statistics professors have likewise written blogs about the benefits and drawbacks of R and SPSS (e.g., Anglim, 2013; Franklin, 2018; Wall, 2014). These debates capture the concern that R is a highly useful program for students but comes with a steeper learning curve and fewer resources available for beginners compared to other software, leading instructors to question whether it is wise to emphasize R in an introductory course (especially those for non-statistics majors). To the best of our knowledge, no study has explicitly compared the teaching of R to statistical software more commonly used with undergraduates, such as SPSS. Moreover, there is little research on incorporating statistical output in the introductory classroom, much less whether one type of output is more advantageous than another.”\n\n\nWhat is the most fitting type of rationale?\n\nExploring an under researched topic.Direct replication of a previous study.Conceptual replication of a previous study.Addressing limitations in the method of a previous study.\n\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe key details are in the final two sentences to explain they are not aware of past research comparing the software and they want to explore this under researched topic. Previously, Rode and Ringel discussed statistics anxiety and the use of different software to teach introductory statistics courses. However, they were not aware of previous studies that compared software and investigated whether one was better than the other.\n\n\n\n\n11.2.10 How does this apply to my stage one group report?\nNow you have read different strategies and worked through activities to identify potential arguments for the rationale, you can think in your group what your line of argument will be. As you conduct your literature review for the introduction, you will start to develop a sense of what research is out there on your topic and what research is missing.\nFor example, there might be research on test anxiety and self-efficacy in isolation, but maybe there are seemingly no studies looking at the direct relationship between them. You might find lots of research looking at the relationship between intrinsic motivation and age in undergraduate students, but maybe there are no studies on postgraduates. There is one key study comparing meta-cognitive self-regulation in undergraduates and postgraduates, but it has not been independently directly replicated.\nThe strategies for the rationale above was not an exhaustive list, so do not worry if your rationale does not neatly fit into one of these categories. There is not one correct approach as it will depend on how you present the literature review and work towards the gap you identified in past research. By the end of the introduction, it is just important to clearly communicate and justify your rationale to the reader so they can see your line of argument.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introductions and Identifying the Rationale</span>"
    ]
  },
  {
    "objectID": "06-Writing-03-Method.html",
    "href": "06-Writing-03-Method.html",
    "title": "12  Structure of the Method",
    "section": "",
    "text": "12.1 Participants\nNormally, this would appear first in the method. The aim here is to explain who your sample were (or your planned sample in this scenario and how you recruited them. You would normally include elements such as:",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Structure of the Method</span>"
    ]
  },
  {
    "objectID": "06-Writing-03-Method.html#participants",
    "href": "06-Writing-03-Method.html#participants",
    "title": "12  Structure of the Method",
    "section": "",
    "text": "Method of recruitment\n\nOpportunity/convenience, volunteer, or random sampling?\nHow were they encouraged to take part? Was there any incentive?\n\n\n\nRelevant demographic information\n\nWhat is relevant depends on what you are testing. This is about contextualising your sample to the reader.\nSo, we tend to give an overall description of the sample and then we give a description relevant to what we are testing. However, if you are not testing any groups then you might not need this and you just need the overall view.\nHowever, it is not necessary to go into lots of detail about something like nationality or other demographics if you do not think it is relevant to the outcome of your study.\n\n\n\nAny inclusion or exclusion criteria\n\nInclusion criteria are features you are looking for in your sample.\nExclusion criteria are features that you would exclude people from your sample.\nThese are not necessarily opposites, think of it as inclusion criteria are what would get people into your sample, and exclusion criteria are what would remove people from your sample once you recruited them.\n\n\n\nThink about the order that you present information within a section.\n\nRemember you are leading a reader through the methods, so it is important for them to be able to follow what you are saying. This means thinking about what they will know at certain points and what they will understand. Ask yourself, “will this make sense to a reader if I present this information now, or should I present it later/earlier?”\nFor example, if you plan on excluding people and this changes the possible demographics of your groups, then it would make sense to present the demographics after you have presented the exclusion criteria, so it is clear the demographics are of those left in your study and do not include people you removed.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Structure of the Method</span>"
    ]
  },
  {
    "objectID": "06-Writing-03-Method.html#materials",
    "href": "06-Writing-03-Method.html#materials",
    "title": "12  Structure of the Method",
    "section": "\n12.2 Materials",
    "text": "12.2 Materials\nThis would normally come second in your method section and it covers the software and questionnaires in this study, or about any stimuli, questionnaires, software, and/or additional materials in other studies. Assume the reader knows nothing about the questionnaires and software here and you are trying to explain the materials to them so they can understand what they are and how you used them.\nA well-written materials section should allow someone who was not part of the research team to replicate the study. You are trying to give them as much detail as possible that they could run your study, but sometimes longer details (such as a full list of questions) can be included in the appendix to save space in the main report.\nYou would normally include aspects such as:\n\n\nDemographic questions\n\nHow many questions were there?\nWhat were the response options?\nGive an example of a question or two. It does not have to detail every question but you can summarise the main points.\nFor example: “We asked {state number} demographic questionnaires to establish age, nationality… with dropdown category options to respond to … and free-response boxes to answer..”\nAgain, think about what is relevant. Focus on detailing the demographics you are using for the analysis. If you are not using a demographic variable, then keep this just as a broad overview of the types of question you ask participants.\n\n\n\nMotivated Strategies for Learning Questionnaire (MSLQ)\n\nYou should describe the full MSLQ and state which subscale/s you will use data from.\nYou do not have to list all the subscales but give an overview of the general purpose of the questionnaire and then focus on the subscale(s) you are using and what construct they measure.\nThe MSLQ should have an APA citation (available in the MSLQ overview document).\nExplain details like how many questions there were in total and how many questions are in your relevant subscale/s.\nWhat were the response options for the subscale/s?\nFor example: “The help-seeking subscale is made up of 5 questions such as”example question” and “example question”, with potential responses on a 5-point Likert scale where 1 means .. and 5 means..”\n\n\n\nYou should also cite the software you (from your perspective as the researcher) used to host the questionnaire.\n\nFor example: “We collected data using the platform Experimentum (DeBruine et al., 2020)…”\nDeBruine, L., Lai, R., Jones, B., Abdullah, R., & Mahrholz, G. (2020). Experimentum (Version v.0.2). Zenodo. doi:10.5281/zenodo.2634355",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Structure of the Method</span>"
    ]
  },
  {
    "objectID": "06-Writing-03-Method.html#procedure",
    "href": "06-Writing-03-Method.html#procedure",
    "title": "12  Structure of the Method",
    "section": "\n12.3 Procedure",
    "text": "12.3 Procedure\nThe procedure details what happened in the study. This section normally comes after the materials section as the reader needs to understand what you used before they can understand how you used them. It can take a while to recognise the distinction between the two sections as you are trying to avoid overlap wherever possible between the sections. Consider the materials as what participants completed and the procedure as when in the study they completed each component of the materials.\nThe main point to keep in mind when writing this section is to think about reproducibility. After reading this sub-section, a reader should be able to reproduce your study exactly, based on what you have written in the materials and procedure.\nFor studies like this, you often only need one paragraph to explain the procedure, but it does not necessarily need to be if it makes more sense to break things up. However, try and avoid your writing becoming too granular by using one sentence paragraphs or bullet points.\nYou would normally include aspects such as:\n\nWhat the participants did in the study, what order they did things in, how the study looked to them, and roughly how long it took them to complete.\nTry to think about how the participant accessed the study. Remember you can watch the screencast on Moodle to remind yourself of any details of how participants worked through the study.\nThe procedure is typically where you outline the ethics processes, such as reading the information sheet and providing consent at the start, and reading the debrief at the end. You do not need to explain what information these documents contain, just when they read them and how the participants interacted with them.\nYou can include the colour of font and background colour.\nYou explain the order participants completed the materials: did they do the demographics and then the MSLQ, or vice versa? Did all participants complete the materials in the same order or was there any randomisation?\nWere all the questions on one screen or did participants see one question at a time?\nHow did participants respond: did they use the mouse, did they use certain keys, did they speak their answer?\nDid participants have a time limit to respond by or could they take as long as they want? What could participants do if they did not want to respond to a question?\n\nIf you find you are repeating a lot of information from the materials, then there is a good chance you are mixing up what information goes where. Remember: the procedure is about what participants saw and did, and how the study was presented to them. The main goal here is to find a balance between providing enough detail for someone to replicate your study without taking up too much of the word count better spent elsewhere.\nFor example, you could reduce: “Participants saw an advert on social media and then they clicked on the link and then they read the consent form and then if they decided they wanted to do the study they consented and then they started answering the questions”\nTo be more concise: “Participants accessed the study through a link on social media. Before starting the study, participants read an information sheet and gave consent to taking part.”",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Structure of the Method</span>"
    ]
  },
  {
    "objectID": "06-Writing-03-Method.html#design-and-data-analysis",
    "href": "06-Writing-03-Method.html#design-and-data-analysis",
    "title": "12  Structure of the Method",
    "section": "\n12.4 Design and Data Analysis",
    "text": "12.4 Design and Data Analysis\nThis subsection usually comes last in the method to transition to the results. You focus on what you planned on doing with the data to link your research question/hypothesis, design, and statistical test.\nThinking about logical flow again, if you were to present this at the start of the method section, then it would not make much sense to the reader as they just do not know enough information about the study yet.\nYou would normally include details such as:\n\n\nYour research design\n\nIs it within-subjects, between-subjects, correlational?\nIf you have more than one analysis in your study, you present them all, either as one paragraph or separate paragraphs depending on the complexity.\n\n\n\nYour dependent/measured variables\n\nIf you are comparing groups/conditions, then it’s better to talk about your dependent variable.\nIf you are interested in a relationship/association, then it’s better to talk about measured variables as there is no independent and dependent variable in a correlational design.\nRemember to be precise. You are testing the mean score on a subscale of the MSLQ, it is not just something like self-efficacy as an abstract concept.\n\n\n\nWhere applicable, state the independent variable and it’s levels (conditions or groups depending on your design)\n\nYou can clarify it is a quasi-experimental variable in this study since they were only self-selecting groups.\n\n\n\nYou could report a power analysis here to outline how many participants you estimates you need to detect your smallest effect size of interest. However, because of the structure of the course and how we must cover all the key concepts, we do not consider it essential for this report. Alternatively, you could report it at the start of your results section. If you and your group do attempt a power analysis, think about:\n\nYou will want to state and justify the alpha value, the power value, and the smallest effect size of interest. Typically, you will be calculating the sample size as the output here. These concepts will be unfamiliar to you in week 4, but you will learn about them in week 5 and beyond.\n\n\n\nBriefly state how you planned on analysing the data\n\nYou would state the type of test/model, use of R (with citations), and any relevant packages.\nThe idea here is to constrain those researcher degrees of freedom, so you are outlining how you plan on analysing the data to the best of your knowledge, so you can explain and justify any deviations from this plan in your stage two individual report.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Structure of the Method</span>"
    ]
  },
  {
    "objectID": "06-Writing-03-Method.html#top-tips-on-writing-a-good-methods-section",
    "href": "06-Writing-03-Method.html#top-tips-on-writing-a-good-methods-section",
    "title": "12  Structure of the Method",
    "section": "\n12.5 Top tips on writing a good methods section",
    "text": "12.5 Top tips on writing a good methods section\n\nMethod sections are quite formulaic and work by putting the right information in the right sections. Try to follow the guidance above on what goes where.\nYou must use sub-headings and we would highly recommend the sub-headings we have stated here.\nTry to avoid repeating information across sections. If you find you are doing that, then it is likely that you are including information in the wrong sections. Each section has a different focus and it will be an important part of the editing process to identify and cut this out.\nIt’s difficult to balance being concise but detailed enough that someone could replicate your work. It will take work in the editing process to consider what is essential and what you can cut, but try not to waste words in the method section on redundant details. Save words for building your narrative in the introduction and discussion sections.\nReading journal articles and focusing on the method section is a good way to see what information can go where. There is a lot of variation in published articles though and they are not often perfect examples, so another thing to think about when reading papers is “what is missing here that would allow me to replicate this study?”",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Structure of the Method</span>"
    ]
  },
  {
    "objectID": "06-Writing-03-Method.html#manipulating-examples-of-materials-and-procedure-sections",
    "href": "06-Writing-03-Method.html#manipulating-examples-of-materials-and-procedure-sections",
    "title": "12  Structure of the Method",
    "section": "\n12.6 Manipulating examples of materials and procedure sections",
    "text": "12.6 Manipulating examples of materials and procedure sections\nTo finish, we are going to manipulate elements of a materials and procedure section to help drive home some of the key points. Try to think about the questions and advice here when you look at your own materials and procedure sections, and see how you can generalise these key points to your participants and design and data analysis sections.\n\n12.6.1 Example 1: A procedure sub-section\nThis is the procedure section from Tsantani et al. (2016) which one of the team worked on. Although it’s published, it does not mean it is a perfect example. You are always learning and you might look back at something you wrote and wonder why you did it like that in the first place. Read the paragraph, then look at the highlighted sections after.\n\n“The experiment took place in the experimental laboratories of the University of Glasgow. Participants were required to complete a 2AFC task during which they listened to pairs of voices comprising high- and low-pitched versions of the original recordings. The sound samples were presented through headphones (participants’ own) connected to a computer with the sound set at approximately 80 dB Sound Pressure Level (SPL): System volume was measured prior to the experiment using a standard headphone set (Sennheisser Beyerdynamic DT 770 PRO 250 OHM) and sound meter. At the beginning of the experiment, participants were informed, via on-screen instructions, that they would hear pairs of voices in two blocks, by trait, and would be asked to make a decision regarding each pair. Participants were told that there was no time limit to their decision but were encouraged to answer with their first impression. After each pair of voices the question”Which voice did you perceive as more {dominant} {trustworthy}?” was displayed on the screen. Pressing the “s” key would mean that they perceived Voice 1 as being most dominant or trustworthy, whereas the “k” key represented Voice 2. The definitions of dominance and trustworthiness used in the instructions were “Dominance means having power and influence over others” and “Trustworthiness means able to be relied on as honest or truthful.” The order of the dominance and trustworthiness blocks, as well as the order in which the voice trials were presented within the block, were counterbalanced across participants. Male and female trials were presented randomly within the same block, as opposed to being presented in different blocks, to avoid an additional potential block-order effect caused by the gender of the voice. Finally, the order of the high- and low-pitched versions of the recordings within each trial was counterbalanced by including two trials of each pair in a block, with the high- and low-pitched versions in a different order. Therefore, within each block, the 20 pairs of voice samples were presented twice. The voices within each pair were played consecutively with a 1-s pause between the first voice and the second voice, and participants proceeded to the next trial by pressing “space.” The experiment lasted approximately 14 min.”\n\n\n12.6.1.1 Highlighted section 1\n\n“After each pair of voices the question”Which voice did you perceive as more {dominant} {trustworthy}?” was displayed on the screen. Pressing the “s” key would mean that they perceived Voice 1 as being most dominant or trustworthy, whereas the “k” key represented Voice 2.”\n\n\nThis is clear on which keys participants had to use. This is quite specific detail, but clearly the authors had a reason for this. Normally, this will be because it helps reduce reaction times if you use specific keys and participants hold their fingers on those keys at all times.\nHowever, it does not say whether they told participants to always have their fingers on those keys and whether participants could see this “key-mapping” (what key represents what answer) all the time, just at the start, or just at breaks.\n\n12.6.1.2 Highlighted section 2\n\n“The definitions of dominance and trustworthiness used in the instructions were”Dominance means having power and influence over others” and “Trustworthiness means able to be relied on as honest or truthful.”\n\n\nThis is really clear on what the specific definitions were that participants were instructed to use but they do not state if these definitions were displayed throughout or just at the start. Would this make a difference if you tried to replicate the study? It might help to add one or two words to make it clear what actually happened.\n\n12.6.1.3 Highlighted section 3\n\n“The order of the dominance and trustworthiness blocks, as well as the order in which the voice trials were presented within the block, were counterbalanced across participants.”\n\n\nWords like “counterbalanced” are technical terms to help clarify what happened but reduce the word count of a longer explanation. However, it is a bit unclear what it means in terms of “voice trials”, so that might need further clarification.\n\n12.6.1.4 Highlighted section 4\n\n“Finally, the order of the high- and low-pitched versions of the recordings within each trial was counterbalanced by including two trials of each pair in a block, with the high- and low-pitched versions in a different order. Therefore, within each block, the 20 pairs of voice samples were presented twice. The voices within each pair were played consecutively with a 1-s pause between the first voice and the second voice, and participants proceeded to the next trial by pressing”space.”\n\n\nThis is getting rather complex and you could improve the explanation with an example (A vs B, B vs A) and the total number of trials (40). The main thing though is that it is trying to give enough detail for someone to replicate (1 second gap, press space etc.).\n\n12.6.1.5 Highlighted section 5\n\n“The experiment lasted approximately 14 min.”\n\n\nIt is always good to include the approximate time for participants to complete the study. If someone is replicating your study and their version takes 45 minutes, they know something is wrong.\n\n12.6.2 Example 2: A materials sub-section\nThis is adapted from the materials section of a first draft of a paper by Stuart McLaren and Phil McAleer in the department.\n\n“The Statistical Anxiety Rating Scale (STARS; Cruise et al., 1985) consists of 51 items comprised of two sections and six subscales. The first section includes 23 statements rated on a 5-point Likert scale that range from”1 = No Anxiety” to “5 = Strong Anxiety”. This section addresses three factors related to how individuals experience specific statistical situations: (a) Test and Class Anxiety (8-items with scores that range from 8 to 40), (b) Interpretation Anxiety (11-items with scores that range from 11 to 55) and (c) Fear of Asking for Help (4-items with scores that range from 4 to 20). For instance, statements include “Doing an examination for a statistics course” or “Going to ask my statistics teacher for individual help with material I am having difficulty in understanding”. The second section consists of 28 statements rated on a 5-point Likert scale that range from “1 = Strongly Disagree” to “5 = Strongly Agree”. This section examines levels of attitudes towards scenarios that involve statistics and statistics teachers over three factors: (d) Worth of Statistics (16-items with scores that range from 16 to 80), (e) Fear of Statistic Teachers (5-items with scores that range from 5 to 25), and (f) Computational Self-Concept (7-items with scores that range from 7 to 35). For example, statements include “I wish the statistics requirement would be removed from my academic program” or “Statisticians are more number orientated than they are people orientated”. A compound score of each subscale is calculated by summing item scores in each subscale, with higher scores indicating higher levels of statistics anxiety. The six subscales show good Cronbach’s alpha reliabilities between .81 and .94 (Chew et al., 2018).”\n\n\n12.6.2.1 Highlighted section 1\n\n“The Statistical Anxiety Rating Scale (STARS; Cruise et al., 1985) consists of 51 items comprised of two sections and six subscales.”\n\n\nAlthough we may have stated this information earlier in the introduction, we are now in the method section and all that relevant information needs to be here.\n\n12.6.2.2 Highlighted Section 2\n\n“The first section includes 23 statements rated on a 5-point Likert scale that range from”1 = No Anxiety” to “5 = Strong Anxiety”.\n\n\nNote here that we are talking about the scales for how it looked but not how the participants responded. Think about what information goes where at all times. In addition, would it help if we stated whether or not the values 2, 3, and 4 had labels on them or not? It would at least help if we said they had no labels.\n\n12.6.2.3 Highlighted Section 3\n\n“A compound score of each subscale is calculated by summing item scores in each subscale, with higher scores indicating higher levels of statistics anxiety.”\n\n\nThis works here, but it could also appear in the data analysis subsection. The idea is that by the time you get to the results, you know what is happening with the scales and how they are calculated and interpreted. A key observation here is that there is not one perfect approach but often when you start to think about the logical flow of information, the better approach sticks out.\n\n12.6.2.4 Highlighted Section 4\n\n“The six subscales show Cronbach’s alpha reliabilities between .81 and .94 (Chew et al., 2018).”\n\n\nFinally, we have not explored reliability of scales in much detail (briefly in lecture 2) but if you had that information from a previous paper, then it can be useful and helps give context to the scales to show they are valid and reliable. For one improvement, you could explain what the values mean for whether they suggest high or low reliability.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Structure of the Method</span>"
    ]
  },
  {
    "objectID": "06-Writing-04-Qualtrics.html",
    "href": "06-Writing-04-Qualtrics.html",
    "title": "13  Creating Questionnaires and Behavioural Tasks",
    "section": "",
    "text": "13.1 Common tools and software\nThere are a range of common tools you will come across as you read journal articles and talk to different lecturers. One of the most important considerations though is making sure any tools and software are GDPR compliant for data protection. When it comes to your dissertation, your supervisor will help with this. In this course, all the tools we recommend are GDPR compliant. As a starting point, the university maintains a software and online tools page which outline all the major approved services. Just note that not all of the tools we outline below are included on this site as the page is mainly about the services that the university purchases.\nMicrosoft Forms\nThis Microsoft product is included in everyone’s Office 365 suite. It is one of the university’s preferred tools and we recommend using it for simple surveys. You can ask for free text responses or pre-set response options like select a category or rating scales.\nQualtrics\nThis is possibly the most common survey platform you will come across within universities and across different workplaces. It is incredibly popular for market research and feedback, so you will come across it even if you do not want to work in academia. It has more advanced functions than Microsoft Forms and it is what we use for the projects in RM1. You can add features like randomisation and branching between questions which makes it great for psychology research.\nGorilla\nGorilla is an online experiment platform where you can create both surveys and a range of behavioural tasks. You can create simple experiments using the builder interface or with some Javascript programming, you can make incredibly complex experiments. If you just want to make surveys, then you are better off using Forms or Qualtrics. However, if you need behavioural tasks or build experiments alongside survey questions, it is probably the most user friendly tool to create online studies.\nPsychoPy\nPsychoPy is a piece of software for developing behavioural tasks or experiments. It it based on Python, so you can either interact through the user interface or write Python code to build experiments. The software is local to a computer to collect data in-person or you can integrate it with their Pavlovia system to run experiments through a web browser.\nOpenSesame\nOpenSesame is very similar to PsychoPy where it is a Python-based experiment builder featuring a user interface or the possibility to write Python code. There is also an online platform called OSWeb to run experiments in a browser. The two tools are very similar so it is more down to personal preference or what your supervisor already uses.\nMatlab\nMatlab is a programming language for generating experiments, stimuli, and analysing data. The university provides access and many researchers have experience using Matlab over Python or PsychoPy. It is popular in brain imaging research due to extensive libraries supporting processing pipelines, but again it will be down to your supervisor’s experience for whether they would support you using Matlab for a project.\nProlific\nOne further tool you will hear about is Prolific - a participant recruitment service. In contrast to the previous tools, you do not create studies within Prolific, but integrate it with something like Gorilla or Qualtrics. You pay participants and select inclusion criteria from their participant pool and direct them to your study via a URL. Prolific has become one of the most popular recruitment services as it is GDPR compliant and recognised for higher participant quality. Many psychology studies use something called Amazon Mechanical Turk but it is not approved by many UK universities and the participant quality can be questionable given the far lower payment guidelines.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Creating Questionnaires and Behavioural Tasks</span>"
    ]
  },
  {
    "objectID": "06-Writing-04-Qualtrics.html#questionnaires-and-scales",
    "href": "06-Writing-04-Qualtrics.html#questionnaires-and-scales",
    "title": "13  Creating Questionnaires and Behavioural Tasks",
    "section": "\n13.2 Questionnaires and scales",
    "text": "13.2 Questionnaires and scales\nOne of the most common ways of measuring human behaviour is through questionnaires or surveys. These rely on self-report for participants to select a response most consistent with how they are currently feeling or identify with. Survey studies normally consist of one or more psychometric scales, demographic questions to record participants’ characteristics, and potentially free-text responses.\n\n13.2.1 Scales\nThe idea behind scales is that you can measure an element of human behaviour by inferring a construct or latent variable through responses to multiple items. These are often in the form of Likert scales where participants indicate agreement or disagreement to an item. Often this will be on a 1 to 7 scale where 1 corresponds to strongly disagree and 7 corresponds to strongly agree. Across the items, you then take the sum or mean of each item to create an overall scale score. The response options and summary statistic for the scale score varies from scale to scale, so it is important you find and refer to the instructions and scoring information.\n\n\n\n\n\n\nValid and reliable measures\n\n\n\nPsychometric scales are carefully designed to measure an element of human behaviour in a valid and reliable way. It takes a lot of time and participants to validate a scale and we could easily dedicate a whole course to psychometrics. If you want an introduction to the stages involved in scale development, we recommend Boateng et al. (2018).\nYou do not want to make up your own scales on the fly, so you are looking out for measures described and cited in previous studies. They will normally cite a validation article where authors describe the steps to create and validate the scale. For example, Alter et al. (2024) validated a new scale on the value of software to statistical learning. They started with 10 items and identified the most effective 7 items. They demonstrated the internal consistency of items to measure the construct and evaluated how it compares to similar measures.\n\n\nFor example, one common scale for measuring depressive symptoms is the Center for Epidemiological Studies-Depression(CES-D). You can then find the items and scoring information via the APA. Participants are prompted with instructions “Below is a list of the ways you might have felt or behaved. Please tell me how often you have felt this way during the past week” and they respond to 20 items, such as “My sleep was restless”. Participants then have four response options:\n\nRarely or none of the time (less than 1 day )\nSome or a little of the time (1-2 days)\nOccasionally or a moderate amount of time (3-4 days)\nMost or all of the time (5-7 days)\n\nFor this scale, you take the sum of the items where the options relate to a score of 0 for the first response and a score of 3 for the fourth response. The lowest possible score is 0 and the highest possible score is 60, with a higher score indicating more severe depression.\nThis chapter explains the principles behind the instructions and items behind a scale. In the accompanying lab / weekly activity, you will learn the practical side of recreating a scale in Qualtrics.\n\n\n\n\n\n\nFinding scales and restrictions\n\n\n\nFor academic research, you normally find the items and instructions in validation articles. The authors put in the work to develop the scales and you cite the article to acknowledge the source and credit. However, prepare for detective work to find all of the information. Not all validation articles provide all the instructions, items, and/or scoring instructions. Sometimes you will need to search the name of the scale and find information from other researchers.\nRelatedly, one thing to be aware of is that you can freely reuse most academic scales and cite the authors for acknowledgement. However, some scales (particularly diagnostic tools) have quite restrictive licences meaning the creators expect you to pay for using the scale. This is normally quite obvious when searching for the details of scales. We would never expect you to pay for using scales, so if you are ever unsure about the restrictions on using a scale, make sure you discuss it with your supervisor or course lead.\n\n\n\n13.2.2 Demographics\nA psychology study often includes a one or more demographic questions to contextualise your sample for reporting, or they might be included as key predictors in your study. It is normally a good idea to put demographics at the end of your study before the debrief to avoid influencing other responses and making sure people respond to the key scales or tasks first.\nThe main consideration is what demographic questions to include. Common options are age and gender, but it depends on the topic of your study for what demographic information would be useful to report. You do not need to collect every piece of information you can think of as it will waste your and your participant’s time if you are not going to use it. See what similar studies report as this will help compare your sample characteristics to the studies that influenced you, and consider what demographics are relevant to your study and research question.\nThe other consideration is making sure the demographics are inclusively and respectfully worded. For concepts like gender and ethnicity, you will see large variance in the categories available to participants, particularly in older articles. Take gender, it is normally a good idea to make it optional for people to respond to the question “What gender do you identify with?” and providing inclusive options over binary man/woman, such as:\n\nWoman\nMan\nNon-binary\nOther (and allow people to type a free-text response)\nPrefer not to say\n\n13.2.3 Free-text responses\nInstead of pre-set responses participants can choose from, you can also ask people for a free-text response to a given question. This could be asking someone a simple question like how old they are in years which takes two characters or it might ask for a longer typed response in a qualitative or mixed methods survey. Like demographic questions, it is just a question of thinking about what you need to address your research question to make sure it is worth your and your participant’s time. You will learn more about designing questions and studies for qualitative methods in RM2.\n\n\n\n\n\n\nAdd validation criteria\n\n\n\nOne mistake you often learn about the hard way is recognising how participants can make mistakes in the questions you give them. For example, if you want people’s age in years and you give them a free-text box, could they type that in words and cause you data processing headaches? In James’ PhD, one of his free-text responses asked participants how many cigarettes they smoked per day but some people’s internet browsers would autocorrect it to a date, messing up how it was read into R.\nTo solve this, many tools like Qualtrics let you set validation criteria for what information is allowed in a box. For example, it must be a valid email address, or it must be numeric with minimum and maximum allowed values. Try and take advantage of this validation criteria to avoid headaches further down the line.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Creating Questionnaires and Behavioural Tasks</span>"
    ]
  },
  {
    "objectID": "06-Writing-04-Qualtrics.html#behavioural-tasks-and-experiments",
    "href": "06-Writing-04-Qualtrics.html#behavioural-tasks-and-experiments",
    "title": "13  Creating Questionnaires and Behavioural Tasks",
    "section": "\n13.3 Behavioural tasks and experiments",
    "text": "13.3 Behavioural tasks and experiments\nIn contrast to self-report questionnaires, another way to measure behaviour is through behavioural tasks or experiments. You will come across tasks all the time in behavioural psychology research, but here we loosely define them as any task or experiment where you manipulate stimuli over multiple trials and record responses. We do not have time to teach you how to create them yourself in this course, but we explain how people design them and provide some examples to help you understand the method sections of articles. We then provide some recommended resources to learn more which might be useful to refer back to if you need it for your dissertation.\n\n13.3.1 The Stroop task\nTo help explain the idea, the most famous example of a behavioural task is probably the Stroop task. In each trial, participants see a word relating to a colour (e.g., Blue or Red) in the middle of the screen. The researcher manipulates the font colour of the word to either be congruent or incongruent. For example, the word Blue written in blue in a congruent trial:\n\nBlue.\n\nAlternatively, the word Blue written in red in an incongruent trial:\n\nBlue.\n\nIn each trial, the participant must indicate the font colour of the word as quickly as possible using the keyboard. Over tens or hundreds of trials, the participants completes all the variations of words and whether the font colour is congruent or incongruent. What you tend to find is that on average, participants respond quicker to the congruent words than the incongruent words. The explanation is that there is a Stroop interference effect as reading the word is quicker than processing the font colour, so incongruent trials take additional processing time to respond.\nThis is the basic idea behind a behavioural task. You want to measure some kind of human behaviour, so you use a behavioural task to manipulate stimuli and measure responses to tap into that behaviour. In contrast to questionnaires which rely on self-report and introspection, behavioural tasks are trying to measure behaviour people may not be consciously aware of, like the subtle processing difference between congruent and incongruent colours.\nThere are many somewhat standardised tasks out there that have been designed to measure different elements of human behaviour, so like questionnaires, it is not usually a good idea to simply make up your own as you want it to be valid and reliable. This means you must understand how researchers report the tasks they use to potentially recreate yourself.\n\n\n\n\n\n\nTry this\n\n\n\nIf you have not tried the Stroop task before, you can complete a demo in your web browser via PsyToolKit. In the demo, you complete 40 trials and it will tell you your average response time to congruent and incongruent trials to show the Stroop interference effect.\n\n\n\n13.3.2 Understanding the design of tasks\nNow we have walked through the Stroop task which many people have experienced, imagine you identified a task you want to recreate from a published paper but you have not completed one yourself before. Where do you find out how to create them? In all empirical psychology articles, there will be a method section outlining how the authors conducted their study. If this is written well enough (and in an ideal world, they should share their task script or design in their supplementary materials), it should allow you to recreate their study as close as possible. In many studies that use behavioural tasks, the authors provide diagrams of their task design, such as Figure 13.1 from an EEG study by Rass et al. (2014).\n\n\n\n\n\n\n\nFigure 13.1: A figure copied from Rass et al. (2014) showing the design of a Eriksen Flanker task.\n\n\n\n\nThis is called the Eriksen Flanker task. It follows a similar principle to the Stroop task as it aims to measure the impact of interference on task performance. However, instead of looking at word colour, it uses distracting information. The aim of the task is to identify the middle letter in a five letter string (there are many variations of this, such as using arrows instead of letters). The four outer letters are distractors, and on some trials they are congruent, and on others they are incongruent. Studies usually find that response times are slower in the incongruent condition than the congruent condition.\nWe will go through the diagram above step by step to decode the design. In this experiment, a trial consists of a central fixation cross which stays on the screen for a random interval between 150-250 milliseconds (ms). This randomness is usually introduced to stop participants just mindlessly clicking buttons to predictable stimuli. A stimulus then appears on the screen for 80ms. This period is sometimes called the Stimulus Onset Asynchrony (SOA), or for how long the stimuli remain on the screen. There are two conditions for the stimuli: congruent (HHHHH or SSSSS) or incongruent (SSHSS or HHSHH). For this task, the participant must identify the middle letter by pressing either the letter ‘s’ or ‘h’ on the keyboard. After the stimulus has disappeared, there is a blank screen where the participant has up to 800ms to provide a response. After the response, a blank screen is presented for 300ms. The participant is then provided feedback to let them know whether they pressed the correct button or not. A ‘+’ is shown for a correct response and a ‘-’ is shown for an incorrect response. Finally, an inter-trial interval (ITI; although confusingly this is called an inter-stimulus interval despite indicating the end of a trial) is shown on the screen for 500ms to indicate the end of a trial.\nNow that we know how one trial is structured, we can see how many times this is repeated to form a block of trials. In the method section, there are more details about how many trials are included. For the participants to understand they are completing the task accurately, they complete 20 trials in a practice block. The authors then explain that participants completed four blocks each containing 100 trials for a total of 400 trials. Between each block, there is a rest period for the participant, but it does not say how long this period is. For demonstration purposes, we will say they receive a short 30 second break. Finally, we know that there are an equal number of congruent and incongruent stimuli in each block. As we have two types of congruent and incongruent stimuli, we can take a good guess that each one of these is presented 25 times in each block. The authors provide us with a diagram of each trial, but we can visualise the structure of the whole experiment like Figure 13.2.\n\n\n\n\n\n\n\nFigure 13.2: The block design from Rass et al. (2014) showing the number of trials per block.\n\n\n\n\nThis is the amount of information you need from an article to enable you to recreate the task the authors used. This is a good example with the only missing information being the duration of the breaks; a relatively minor detail. You should be prepared to come across substantially less helpful authors that do not provide sufficient details. This is usually the case when it comes to tasks that use images. Researchers do not normally share these and often do not even describe them. Hopefully, this will also demonstrate the importance of fully describing your experiment in a report or dissertation. Try and imagine you are the other researcher trying to recreate the task from your instructions.\n\n\n\n\n\n\nTry this\n\n\n\nIn the previous chapter, we invited you to read the method section (pages 2 and 3) of Registered Replication Report: Testing Disruptive Effects of Irrelevant Speech on Visual-Spatial Working Memory by Kvetnaya (2018). At that point, the materials, design, and procedure might have been quite difficult to follow. Now we have explained the basic principles of breaking down behavioural tasks, try and revisit Kvetnaya’s method section to see if you can understand how they designed and presented their task.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Creating Questionnaires and Behavioural Tasks</span>"
    ]
  },
  {
    "objectID": "06-Writing-04-Qualtrics.html#online-vs-in-person-data-collection",
    "href": "06-Writing-04-Qualtrics.html#online-vs-in-person-data-collection",
    "title": "13  Creating Questionnaires and Behavioural Tasks",
    "section": "\n13.4 Online vs in-person data collection",
    "text": "13.4 Online vs in-person data collection\nFinally, we have the choice between online or in-person data collection in relation to designing questionnaires and behavioural tasks. Historically, behavioural tasks were restricted to a physical lab room due to technological limitations but over the last 10 to 20 years, you can easily administer questionnaires and tasks via a web browser. This means the choice is now about participant access and data quality rather than technical limitations.\nIf you want to collect data in-person, you are relying on people who live in close proximity to the university and who have the time and motivation to complete your study. Often, these will be university students through something like a participant pool. This means you might only have access to a specific sample which might be a problem depending on your target population. On the other hand, you might have access to fewer participants in total but your conversion rate for participants who start and complete the study will often be much higher. You also have more control over the environment and number of distractions available to the participant.\nIn contrast, online studies potentially provide a much larger potential source of participants as there are no geographical or physical restrictions. In theory, anyone can complete your study in their own time once they have a link. If you are targeting a specific sample / population, then you potentially have access to a larger pool of potential participants. However, you have much less control over who is participating in your study and the data quality they provide. Since participants complete the study in their own time and space, you have no control over potential distractions or whether they actually meet your inclusion criteria. The conversion rate is often much lower in an online study too as people can start the survey and if they get bored, simply close the link.\nThere is no universal right answer for which method of data collection is best, it depends on the pros you desire and the cons you are willing to accept. This is all part of the research design process to weigh up the pros and cons, so you recognise and accept potential limitations from the start. It just means you must consider the wider concept of data quality, such as verifying participants, attention checks, and manipulation checks. Note we are not going to provide a literature review for each concept, just outline what they are before we provide a list of further resources for future reference.\n\n13.4.1 Participant verification\nWhen we conduct psychology research, we want to learn about human behaviour. This means one of the key considerations is making sure real participants are completing your study. When you share a study link online - particularly when there is payment involved - there is the potential for bots to complete your study. This is where people create computer programs to complete questionnaires and tasks, and enter information. Some tools such as Qualtrics include security settings you can activate to detect bots and repeat submissions using things like reCAPTCHA (think of when you access a website and you need to select all the images containing a car). With the rise of generative AI tools, this adds another potential verification issue as people can outsource the study to enter information from something like ChatGPT.\nTo verify participants, you can ask for free-text responses to some questions or upload files for which generative AI tools (currently) find more difficult. For recruitment services like Prolific, this is another way of verifying participants as everyone in the pool provided an ID check when they signed up and they are developing tools to deter participant generative AI use.\n\n13.4.2 Attention checks\nData quality is not a unique problem to online studies. Participants can mindlessly scroll and click through studies, so one strategy is including attention checks to potentially use as exclusion criteria. For example, people periodically embed a question within scales which will say something like “for this question, select the option 5”. For people who do not respond 5, you suspect they were not reading the questions carefully and did not follow the instructions. Other strategies include asking people to self-report their data quality for whether they completed the study properly or excluding people if they completed the study quicker than plausibly possible.\n\n13.4.3 Manipulation checks\nSomewhat related to making sure participants are paying attention while completing your study, you might also check whether they have been influenced in the way you intend by some kind of manipulation. For example, James worked on a study about predicting unethical workplace behaviour. Participants were randomly allocated into different conditions to manipulate things like a high or low quality workplace in a vignette. We asked people a series of questions to see if they recognised the manipulation such as “how would you describe the quality of the workplace?” with options including good, neither good nor poor, or poor. You do not necessarily need to exclude participants who fail the manipulation check but it is one way to investigate the efficacy of your manipulation which can help interpret your findings.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Creating Questionnaires and Behavioural Tasks</span>"
    ]
  },
  {
    "objectID": "06-Writing-04-Qualtrics.html#further-resources",
    "href": "06-Writing-04-Qualtrics.html#further-resources",
    "title": "13  Creating Questionnaires and Behavioural Tasks",
    "section": "\n13.5 Further resources",
    "text": "13.5 Further resources\nGiven you do not create your own study in RM1, we do not expect you to spend the time learning how to do all of this stuff yourself now. So, we end on some further resources to learn about data quality in online studies and creating behavioural tasks which might be useful later in your journey, such as when you are starting your dissertation.\n\n13.5.1 Data quality in online studies\n\nProlific have a series of resources for creating online studies and one explains How to improve data quality in online studies. It explains things like verifying participants, performing attention checks, and AI detection.\nExperimentology by Frank et al. is an excellent online book on an open science approach to experimental psychology methods and they have a chapter on Data Collection. They extensively explain best practices for online and in-person data collection and cite a wide range of sources you can refer to.\n\n13.5.2 Creating behavioural tasks\n\nIt is possibly a little out of date now, but James wrote a guide to Creating Experiments using OpenSesame.\nIn the reading list for RM1, we have included a link to Building Experiments in PsychoPy (2nd edition) by Peirce et al. (2022) which you can access via the library. This books explains how to create behavioural tasks using PsychoPy.\nSimilarly, we also included a link to Python for Experimental Psychologists (2nd edition) by Dajmaier et al. (2024) which also demonstrates how to code experiments and analyses using Python and PsychoPy.\nThis video by Xiaojin Ma is quite long, but it walks through Using PsychoPy to build a cognitive psychology experiment from scratch.\n\n\n\n\nFigure 13.1: A figure copied from Rass et al. (2014) showing the design of a Eriksen Flanker task.\nFigure 13.2: The block design from Rass et al. (2014) showing the number of trials per block.\n\n\n\nAlter, U., Dang, C., Kunicki, Z. J., & Counsell, A. (2024). The VSSL scale: A brief instructor tool for assessing students’ perceived value of software to learning statistics. Teaching Statistics, 46(3). https://doi.org/10.1111/test.12374\n\n\nBoateng, G. O., Neilands, T. B., Frongillo, E. A., Melgar-Quiñonez, H. R., & Young, S. L. (2018). Best Practices for Developing and Validating Scales for Health, Social, and Behavioral Research: A Primer. Frontiers in Public Health, 6. https://doi.org/10.3389/fpubh.2018.00149\n\n\nRass, O., Fridberg, D. J., & O’Donnell, B. F. (2014). Neural correlates of performance monitoring in daily and intermittent smokers. Clinical Neurophysiology, 125(7), 1417–1426. https://doi.org/https://doi.org/10.1016/j.clinph.2013.12.001",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Creating Questionnaires and Behavioural Tasks</span>"
    ]
  },
  {
    "objectID": "06-Writing-05-power.html",
    "href": "06-Writing-05-power.html",
    "title": "14  Reporting Power Analyses",
    "section": "",
    "text": "14.1 Recommended resources for statistical power\nIn semester 1, the concept of statistical power and how it applies to specific statistical tests are spread across materials and several weeks of lectures:",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting Power Analyses</span>"
    ]
  },
  {
    "objectID": "06-Writing-05-power.html#recommended-resources-for-statistical-power",
    "href": "06-Writing-05-power.html#recommended-resources-for-statistical-power",
    "title": "14  Reporting Power Analyses",
    "section": "",
    "text": "Lecture week 5 - Hypothesis testing.\nLectures week 7-9 - Inferential statistics for correlations, t-tests, and regression.\nChapter 10 of the PsyTeachR book Fundamentals of Quantitative Analysis outlines how to perform power analysis in R for different statistical tests.\nBartlett and Charles (2022) provide a beginner’s tutorial to power analysis. Part 1 outlines the concept of statistical power and part 2 discusses justifying the inputs you use in power analysis. Ignore part 3 as you will be using R instead of jamovi.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting Power Analyses</span>"
    ]
  },
  {
    "objectID": "06-Writing-05-power.html#statistical-power-recap",
    "href": "06-Writing-05-power.html#statistical-power-recap",
    "title": "14  Reporting Power Analyses",
    "section": "\n14.2 Statistical power recap",
    "text": "14.2 Statistical power recap\nIn null hypothesis significance testing (NHST), we can put a limit on two types of error. Type I errors (false positives) are when we reject the null hypothesis and conclude a test was statistically significant, when really the null hypothesis is true. Type II errors (false negatives) are when we retain the null hypothesis and conclude a test was non-significant, when really the null hypothesis is false.\nStatistical power is related to the second type of error (type II). The definition of power is the long run probability of your study design correctly rejecting the null hypothesis when there is a true effect to be found. In short, “if an effect exists, how likely am I to detect it”? If a study has high statistical power, you would reliably detect a given effect size. If a study has low statistical power, you would not reliably detect a given effect size.\nIn null hypothesis significance testing, there are four key concepts:\n\nAlpha: The predetermined cut-off in your design at which you reject the null hypothesis (normally set at \\(\\alpha\\) = .05). This is your false positive error rate to limit the number of type I errors you would be willing to make.\nPower: The ability of a design to find an effect based on 1 - \\(\\beta\\), where beta is normally set at .20 or .10, producing power = .80 or .90. Beta is the false negative error rate to limit the number of type II errors you would be willing to make.\nEffect size: A number that expresses the magnitude of the phenomenon related to your research question. This will typically be Cohen’s d for the standardised mean difference in t-tests or the correlation coefficient r.\nSample size: The number of participants or observations in your study.\n\nConveniently, there is an interaction between the four key concepts of Alpha, Power, Effect Size, and Sample Size (APES). If you state three, you can calculate the fourth. Assuming you use the field standards of \\(\\alpha\\) = .05 and power = .80, choosing the final input of sample size or effect size produces one of two informative types of power analysis:\n\nA priori power analysis: You solve power analysis for the number of participants you need for a given value of \\(\\alpha\\), power, and effect size.\nSensitivity power analysis: You solve power analysis for the effect size you can detect for a given value of \\(\\alpha\\), power, and sample size.\n\nFor an example, Mehr et al. (2016, pg. 487) report the following a priori power analysis in their study on the effect of melody on infants:\n\n“Statistical power. The target sample size of 32 was determined before the experiment began, to ensure adequate power to detect a positive selective-attention effect. A similar experiment testing effects of language rather than music (Kinzler et al., 2007) obtained an effect size (d) of 0.54, and a sample of 32 had .84 power to detect an effect of this magnitude.”\n\nWe can reproduce their power analysis using the pwr package for a paired samples t-test (if you have not got to Chapter 10 in data skills yet, do not worry if this looks unfamiliar):\n\npwr.t.test(d = 0.54,\n           sig.level = .05,\n           power = .84,\n           type = \"paired\",\n           alternative = \"two.sided\")\n\n\n     Paired t test power calculation \n\n              n = 31.91057\n              d = 0.54\n      sig.level = 0.05\n          power = 0.84\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\nSince we left the argument n blank, we receive that as the output of our a priori power analysis. We need 31.91 participants, but we always round up to a whole number of participants to avoid underestimating, so we would need 32 participants. The power analysis in Mehr et al. provides one example, but it is not perfect. There are some inputs they do not explicitly specify, so we will return to this example in reporting your power analysis below.\nFor your stage one report (and looking forward to your dissertation), you could report an a priori power analysis to inform how many participants you would need to detect your smallest effect size of interest. Power analysis and pre-registration is most informative in the design phase of research, so you would typically perform a power analysis to inform how many participants you try and recruit.\nJust keep in mind: for the assignment in RM1 you have no control over the final sample size as we collected data for you. This means there might be a difference in your planned sample size from the a priori power analysis and the final sample size you work with. Therefore, we have a section on sensitivity power analysis to consider potential differences in your planned vs final sample size.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting Power Analyses</span>"
    ]
  },
  {
    "objectID": "06-Writing-05-power.html#choosing-a-smallest-effect-size-of-interest",
    "href": "06-Writing-05-power.html#choosing-a-smallest-effect-size-of-interest",
    "title": "14  Reporting Power Analyses",
    "section": "\n14.3 Choosing a smallest effect size of interest",
    "text": "14.3 Choosing a smallest effect size of interest\nFor an a priori power analysis, you need to enter an effect size. The term we use for this is the smallest effect size of interest. It is rare you would know precisely what effect size you were looking for - as you would not need the study if you understood the topic that well. This means your smallest effect size of interest represents the threshold for what effect sizes you want your study sensitive enough to detect. Power exists along a curve, so holding the sample size and all other inputs constant, you would be less likely to detect smaller effects, but more likely to detect effects larger than your smallest effect of interest.\nThe following plot is a power curve showing the relationship between the correlation coefficient r as the effect size and statistical power for a given sample size. Assuming our power analysis suggested we need to collect 60 participants, we would have 80% power to detect effects of r = .36. The smallest effect size of interest is where the two lines meet for your desired level of power (here 80%). As you move down the curve highlighted by the grey region, you would be less likely to detect effects smaller than your smallest effect size of interest. As you move up the curve, you would be more likely to detect effects larger than your smallest effect size of interest. In short, and assuming you want to keep power at 80% or higher, then you would be looking for effect sizes at, or greater than, your smallest effect size of interest.\n\n\n\n\n\n\n\n\nTo demonstrate what this looks like for a larger smallest effect size of interest, if your power analysis suggested we need 30 participants, we would have 80% power to detect effects of r = .49. The smallest effect size of interest is again represented by where the two lines meet. Since we only wanted our design to be sensitive to larger effects, there is a larger grey region to highlight the effects we would be less likely to detect. As you move down the curve, you would be less likely to detect effects smaller than r = .49. As you move up the curve, you would be more likely to detect effects larger than r = .49. In short, you would be still be looking for effect sizes at, or greater than, your smallest effect size of interest, but that threshold shifts to exclude a larger region of smaller effects.\n\n\n\n\n\n\n\n\nAssuming you use the field standards of \\(\\alpha\\) = .05 and power = .80, this leaves the smallest effect size of interest as the main decision you must make. Choosing an effect size is the hardest part of power analysis, but there is no one correct answer, only a difference between justified and unjustified. In your power analysis, we care more about your justification for your choice of effect size rather than the value itself.\nYou could always aim for a tiny effect size but in a real study you are trying to compromise between an informative study and the resources (time / money) you have available. You could always aim for a large effect size, but you might miss potentially informative smaller effects. This means you must choose your smallest effect size of interest based on your understanding of the topic area and consider what effects you would not want to miss out on.\nThere are different strategies for choosing a smallest effect size of interest (see Lakens, 2022 for a full discussion):\n\nIndividual published studies: What effect sizes do similar studies to yours report?\nMeta-analyses: What is the average effect size across several studies on a topic?\nEffect size distributions: For a given topic, what is the distribution of effect sizes for what is considered small, medium, and large?",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting Power Analyses</span>"
    ]
  },
  {
    "objectID": "06-Writing-05-power.html#report-power",
    "href": "06-Writing-05-power.html#report-power",
    "title": "14  Reporting Power Analyses",
    "section": "\n14.4 Reporting your power analysis",
    "text": "14.4 Reporting your power analysis\nIf you do report a power analysis, think about what information would allow the reader to reproduce your power analysis and understand your justification behind each input. Bakker et al. (2020) reviewed power analyses reported in pre-registrations and review boards and highlighted the most common omissions. From a sample of 210 studies, the most common omissions (% is the percentage of studies missing the information) in the features of a power analysis were:\n\nSidedness of the test (78%)\nJustification for effect size (45%)\nType of effect size (30%)\nAlpha value (29%)\nValue of effect size (15%)\nPower / beta value (15%)\nSample size (8%)\n\nBakker et al. observed that the most common omission was whether researchers assumed a one- or two-tailed test and the least common omission was the sample size the power analysis suggested.\nPreviously, we highlighted that Mehr et al. does not provide a complete example of reporting a power analysis. As an activity, we would like you to work through different adaptations we prepared and indicate what information you think is included and what you think is missing. Each adaptation is hidden behind a “show me” tab, so you can view each one in turn and focus on asking yourself what information is missing. We will compare each adaptation side by side afterwards.\n\n14.4.1 Adaptation one\n\n\n\n\n\n\nShow me the first adaptation\n\n\n\n\n\nUsing the field standards of power = .80 and alpha = .05, and an effect size from previous studies, we will require 29 infants in our study.\n\n\n\nIn adaptation one, what information do you think is missing?\n\n\nSidedness of the test? \nIncluded\nMissing\n\n\n\n\n\nJustification for effect size? \nIncluded\nMissing\n\n\n\n\n\nType of effect size? \nIncluded\nMissing\n\n\n\n\n\nAlpha value? \nIncluded\nMissing\n\n\n\n\n\nValue of the effect size? \nIncluded\nMissing\n\n\n\n\n\nPower / beta value? \nIncluded\nMissing\n\n\n\n\n\nSample size? \nIncluded\nMissing\n\n\n\n\n14.4.1.1 Adaptation two\n\n\n\n\n\n\nShow me the second adaptation\n\n\n\n\n\nPrevious related research looking into how infants can develop and show selective-attention suggested a medium sized effect. As such, using the field standards of power = .80 and alpha = .05, and d = 0.54, we will require 29 infants in our study.\n\n\n\nIn adaptation two, what information do you think is missing?\n\n\nSidedness of the test? \nIncluded\nMissing\n\n\n\n\n\nJustification for effect size? \nIncluded\nMissing\n\n\n\n\n\nType of effect size? \nIncluded\nMissing\n\n\n\n\n\nAlpha value? \nIncluded\nMissing\n\n\n\n\n\nValue of the effect size? \nIncluded\nMissing\n\n\n\n\n\nPower / beta value? \nIncluded\nMissing\n\n\n\n\n\nSample size? \nIncluded\nMissing\n\n\n\n\n14.4.1.2 Adaptation three\n\n\n\n\n\n\nShow me the third adaptation\n\n\n\n\n\nPrevious related research looking into how infants can develop and show selective-attention through music (Mehr et al., 2016) and language (Kinzler et al., 2007) suggested a medium sized effect around d = 0.54. As such, using the field standards of power = .80 and alpha = .05, and the suggested effect size from previous studies, we will require 29 infants in our study for a two-tailed test.\n\n\n\n\n\nSidedness of the test? \nIncluded\nMissing\n\n\n\n\n\nJustification for effect size? \nIncluded\nMissing\n\n\n\n\n\nType of effect size? \nIncluded\nMissing\n\n\n\n\n\nAlpha value? \nIncluded\nMissing\n\n\n\n\n\nValue of the effect size? \nIncluded\nMissing\n\n\n\n\n\nPower / beta value? \nIncluded\nMissing\n\n\n\n\n\nSample size? \nIncluded\nMissing\n\n\n\n\n14.4.2 Activity summary\nAdaptation 3 is by no means a perfect example. The justification for the effect size could be more detailed and there are some subtle details Bakker et al. (2020) did not assess in their review. For example, you could mention the statistical test it is based on for absolutely clarity, and justify using the field standard values for alpha and power. To highlight how each adaptation changes, we will start with number one which included the fewest details and it would be difficult to reproduce the power analysis.\n\nUsing the field standards of power = .80 and alpha = .05, and an effect size from previous studies, we will require 29 infants in our study.\n\nWe only have the field standards of 80% power, 5% alpha, and we need 29 participants. There is no mention of the effect size, no justification, and no mention of the test it is based on.\nAdding bold to adaptation two, we add more details.\n\nPrevious related research looking into how infants can develop and show selective-attention suggested a medium sized effect. As such, using the field standards of power = .80 and alpha = .05, and d = 0.54, we will require 29 infants in our study.\n\nWe mention studies on this topic report a medium sized effect, so that could be our smallest effect size of interest. We then specify an effect of d = 0.54 to add another input for our power analysis. However, we are vague about the studies that report the effect and there is no mention of the test or the number of tails it is based on.\nAdding a final round of bold to adaptation three, we add a few more details.\n\nPrevious related research looking into how infants can develop and show selective-attention through music (Mehr et al., 2016) and language (Kinzler et al., 2007) suggested a medium sized effect around d = 0.54. As such, using the field standards of power = .80 and alpha = .05, and the suggested effect size from previous studies, we will require 29 infants in our study for a two-tailed test.\n\nThis time, the explanation could be more detailed for why this value represents the smallest effect size of interest, but we outlined studies to support this decision. We add the number of tails the power analysis is based on at the end, but we do not outline specifically what statistical test it is applied to.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting Power Analyses</span>"
    ]
  },
  {
    "objectID": "06-Writing-05-power.html#sensitivity",
    "href": "06-Writing-05-power.html#sensitivity",
    "title": "14  Reporting Power Analyses",
    "section": "\n14.5 A priori vs sensitivity power analysis",
    "text": "14.5 A priori vs sensitivity power analysis\nOne common question we receive is: “what happens if we do not get the sample size we need from the final data?”. Typically in research, an a priori power analysis is most effective during the design phase. You have the opportunity to design your study and calculate how many participants you must recruit for your desired level of sensitivity, keeping in mind the resources you have available. At this point, you collect data and try to recruit as many participants as your power analysis suggested.\nFor different reasons, your final sample size might be different to the sample size you planned on recruiting. The final sample size could be smaller as you found it more difficult to recruit participants for your target population or there was more missing data than you expected. Alternatively, the final sample size could be larger as more people responded to the advert than you were anticipating. This does not mean your a priori power analysis was a waste of time, but you can consider the difference between your planned sample size and your final sample size.\n\n14.5.1 Example from published research\nFor a nice example from a published study, Wingen et al. (2020, pg. 455) commented on the difference between their planned and final sample size:\n\n“The sample size was set to 266, based on an a priori power analysis for 95% power (one-sided \\(\\alpha\\) of .05) to detect a small to moderate effect of r = .2, that would be typical for similar social psychological research (Richard, Bond, & Stokes-Zoota, 2003). The final sample was slightly larger as is often the case in online studies and consisted of 271 participants (54.3% male; age: M = 33.7 years, SD = 8.9). No participants were excluded from the analyses. A sensitivity analysis showed that our final sample had a high chance (1 - \\(\\beta\\) = .80, one-sided \\(\\alpha\\) = .05) to detect a correlation of r = .15 and a very high chance (1 - \\(\\beta\\) = .95, one-sided \\(\\alpha\\) = .05) to detect r = .20.”\n\nTheir original power analysis suggested they needed 266 participants to detect their smallest effect size of interest. They recruited 271 participants instead, so they commented on what effect size their study would be sensitive to for two values of power.\n\n14.5.2 Mock example with R code and output\nFor an additional example, let’s imagine we were building on the Mehr et al. example we have worked with throughout this section. We can calculate power for a paired samples t-test as above with a smallest effect size of interest of d = 0.54, 84% power, 5% alpha, and a two-tailed test.\n\npwr.t.test(d = 0.54,\n           sig.level = .05,\n           power = .84,\n           type = \"paired\",\n           alternative = \"two.sided\")\n\n\n     Paired t test power calculation \n\n              n = 31.91057\n              d = 0.54\n      sig.level = 0.05\n          power = 0.84\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\nThe a priori power analysis shows we would need to recruit 32 infants to be consistent with our power analysis. However, perhaps we had trouble recruiting infants and we had technical troubles meaning we lost some data. What effect size could we detect if our final sample size was 20?\n\npwr.t.test(n = 20,\n           sig.level = .05,\n           power = .84,\n           type = \"paired\",\n           alternative = \"two.sided\")\n\n\n     Paired t test power calculation \n\n              n = 20\n              d = 0.6965685\n      sig.level = 0.05\n          power = 0.84\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\nThis sensitivity power analysis suggests we would be able to detect an effect size of d = 0.70 with 20 participants, 84% power, 5% alpha, and a two-tailed test. This effect size is larger than our smallest effect size of interest, so we would need to consider whether this lower level of sensitivity is informative and whether it was problematic we were less likely to detect effects smaller than d = 0.70.\nFor your assignment, you might find there is a larger difference between your planned and final sample size than a typical study. This is an educational experience where we have collected data for you and we are guiding you through the skills you will need as an independent researcher for your dissertation and beyond. So, report an a priori power analysis in your stage one report (or stage two report if you do not cover everything in time) based on your smallest effect size of interest, then reflect on what effect size your final sample size and design would be sensitive to detect in your stage two report.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Reporting Power Analyses</span>"
    ]
  },
  {
    "objectID": "06-Writing-06-NHST.html",
    "href": "06-Writing-06-NHST.html",
    "title": "15  Null Hypothesis Significance Testing (NHST)",
    "section": "",
    "text": "15.1 Understanding p-values through simulations\nYou can access the first visualisation via this link: https://rpsychologist.com/pvalue/. We have also recorded a video walking through the visualisation to use alongside the explanations below:\nSimulations are super helpful for learning about statistical concepts since we can create known conditions. In a real experiment, we ultimately do not know for certain whether the null or alternative is true, so we are trying to guide our decision making through hypothesis testing, preparing for different possibilities.\nThere are four main areas:\nHopefully, this will make the probability distribution aspect a little more tangible. In any individual study, we have a bunch of observations, calculate a sample statistic, then calculate the p-value. We either reject the null or not, probability does not apply to individual events. We use NHST to help us make decisions on rejecting the null or not, and that influences what we conclude about the hypothesis in our study.\nIn any one study, it is either statistically significant if the p-value is equal to or below alpha, or not significant if the p-value is above alpha. Probability does not apply to how likely/unlikely the null hypothesis is in any one study. Probability applies to the collective and what we would expect in the long-run.\nWe need simulations to demonstrate this since in real research we do not know with any certainty whether the null is true or false in the population. Here, we can simulate these conditions and see how the concepts behave.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Null Hypothesis Significance Testing (NHST)</span>"
    ]
  },
  {
    "objectID": "06-Writing-06-NHST.html#understanding-p-values-through-simulations",
    "href": "06-Writing-06-NHST.html#understanding-p-values-through-simulations",
    "title": "15  Null Hypothesis Significance Testing (NHST)",
    "section": "",
    "text": "Select a value for Cohen’s d: This is the standardised mean difference / the difference expressed as standard deviations. Setting it 0 (no effect) means the null hypothesis is true since there is no difference in the population. A larger value would mean the alternative is true since we know there is an effect in the population.\nSample observations: Based on the value for Cohen’s d, we sample from a normal distribution. In the control panel, we can change the sample size. Based on the sample size, we sample observations from the distribution.\nCalculate test statistic: From the sample observations, we calculate a test statistic. From the control panel, we can choose from the mean (average of the observations), z-value (average deviation from the null), or p-value (the p-value for the sample).\nCalculate p-value: For each test statistic calculated from the sample observations, this adds to the probability distribution. Every time we draw a sample, it goes through the process above and adds to the distribution.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Null Hypothesis Significance Testing (NHST)</span>"
    ]
  },
  {
    "objectID": "06-Writing-06-NHST.html#understanding-statistical-power-and-significance-testing",
    "href": "06-Writing-06-NHST.html#understanding-statistical-power-and-significance-testing",
    "title": "15  Null Hypothesis Significance Testing (NHST)",
    "section": "15.2 Understanding statistical power and significance testing",
    "text": "15.2 Understanding statistical power and significance testing\nYou can access the second visualisation via this link: https://rpsychologist.com/d3/nhst/. We have also recorded a video walking through the visualisation to use alongside the explanations below:\n\n\nInstead of simulating the behaviour of samples and how they form distributions, this time we are exploring how the four main concepts of hypothesis testing fit together. At the end of part 1 in the lecture, we explained how if you state three of the concepts, you can calculate the fourth. For example, in power analysis, you can calculate how many participants you need based on a given alpha, beta/power, and smallest effect size of interest. Decision making is critical when using hypothesis testing as it’s designed to limit the errors you make when rejecting the null hypothesis or not. Hopefully, you will see the implications of these decisions when playing around with the visualisation.\nYou can choose from the four main hypothesis testing concepts as the one to solve for:\n\nPower: What power do we have for a given alpha, sample size, and effect size? In reality, this is not useful and is known as post-hoc power. When applied to an individual study, it’s an attractive idea, but it omits the long-run aspect of the probability and mistakes the sample estimate for the population value.\nAlpha: What would be the type I error rate for a given power, sample size, and effect size? Like power, this is not normally what you are interested in for the output.\nn: What sample size would we need for a given power, alpha, and effect size? This is the traditional sense of power analysis where we calculate the number of participants we need to conduct an informative study, given your inputs.\nd: What effect size could you detect for a given power, alpha, and sample size? This is the second type of informative output known as a sensitivity power analysis. If you have a known sample size, you can calculate what was the smallest effect size you could reliably detect, given your inputs.\n\nThis visualisation is a useful educational exercise for seeing how the inputs change the output. Just keep in mind it’s aimed at a very limited application, we do not recommend using the sample size output to report for a power analysis. There is a chapter in the Fundamentals of Quantitative Analysis dedicated to power analysis.\nThere is also a button to toggle a one- or two-tailed test. This is useful for seeing how the area of the null distribution changes depending on whether you spend all the alpha in one tail or two.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Null Hypothesis Significance Testing (NHST)</span>"
    ]
  },
  {
    "objectID": "06-Writing-07-Writing.html",
    "href": "06-Writing-07-Writing.html",
    "title": "16  Academic Writing",
    "section": "",
    "text": "16.1 Academic writing\nWhile we encourage you to approach reading journal articles to develop a sense of scientific writing style, they are not always the best examples of how to write well. This means writing for clarity and conciseness, to help communicate your ideas to the reader.\nSome authors approach writing by trying to fill it with as many big words as they can find. We want you to learn the technical terms to use where appropriate, but the writing around them should be clear and concise with effective paragraph structure. Freeling et al. (2021) showed how writing in a more engaging accessible style results in higher readability, understanding, and confidence in a topic. So, there are a few things to aim for and a few things to avoid in your writing.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Academic Writing</span>"
    ]
  },
  {
    "objectID": "06-Writing-07-Writing.html#academic-writing",
    "href": "06-Writing-07-Writing.html#academic-writing",
    "title": "16  Academic Writing",
    "section": "",
    "text": "16.1.1 Aim\n\nWrite precisely and accurately and choose the word/phrase that best expresses your idea.\nUse technical language, with clear definitions where necessary.\nUse short sentences and straightforward sentence structures where possible.\nWrite in a clear, accessible style. Remember, the point of scientific writing is to clearly convey information, not to entertain or to show off your vocabulary.\n\n16.1.2 Try to avoid\n\nColloquial or conversational English.\nUnnecessarily complex language and unnecessary “rhetorical flourishes” such as irony, ambiguity (intentional or otherwise), and informal language.\nAsking rhetorical questions. The purpose of a report or essay is to explain to the reader what something means, not pose a question back at them.\nContractions such as ‘can’t’, ‘don’t’ or ‘isn’t’ - always use the full phrase.\n\n16.1.3 Top Tips to improve your writing\n\nDo not submit the first draft. No-one ever writes anything good on the first attempt. Good writing is all in the editing process, the first draft is just about getting your ideas on the page. We once saw the advice (but cannot remember the source): “the first draft is explaining your ideas to yourself, the editing is about explaining your ideas to the reader”.\nRead your essay out loud as you will easily spot a horrendously long sentence as you lose your breath trying to read it aloud.\nProof-read after a day or so break. If you are too close to it, you might not spot mistakes or where ideas are not expressed clearly for the naive reader.\nAsk a friend to proof-read. This is particularly helpful if they do not study psychology (or if they are doing a different topic than you) because they will only understand it if you have properly explained your key concepts and if the logic flows.\nRead lots of journal articles as you will start to recognise what works and what does not work for you as the reader, so you can start to reflect it in your own writing.\n\n16.1.4 Further resources\nThe Student Learning Development team have several sources of support available:\n\nYou can book 1-to-1 advice and support sessions.\nThere is additional support available for international students.\nThere are pre-recorded classes in a Moodle course you can self-enrol in.\n\nYou are busy enough on this course, but if you want to work on your academic writing, there is an excellent free course on Coursera called Writing in the Sciences. This has 8 modules covering concepts like effective writing, verbs, and sentence structure.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Academic Writing</span>"
    ]
  },
  {
    "objectID": "06-Writing-07-Writing.html#paragraph-structure",
    "href": "06-Writing-07-Writing.html#paragraph-structure",
    "title": "16  Academic Writing",
    "section": "\n16.2 Paragraph structure",
    "text": "16.2 Paragraph structure\nOnce you start organising your ideas into writing, its important to consider good paragraph structure. We recommend learning the PEEL approach to paragraphs:\n\nPoint – Your topic sentence or two starts the paragraph to outline the key point you are making. Readers should be able to skim through your writing and recognise from the first sentence or two what the point of each paragraph is.\nEvidence – Once you outlined the point you are making, its time to explain the evidence relating to your point.\nExplain – Now you have presented the evidence, you need to explain what the evidence means for your overall point.\nLink – Finally, in the final sentence or two, you have a summary sentence to wrap up your paragraph and help transition to the next paragraph.\n\nFor an example, we will break down a paragraph from Robertson and Simmons (2013):\n\nThere are a number of neural theories of autism that aim to explain the unusual sensory processing reported within this population. Enhanced Perceptual Functioning (EPF) theory (Mottron, Dawson, Soulières, Hubert, & Burack, 2006) is based on the premise that individuals with ASD exhibit superior local processing abilities. This theory proposes that ASD stems from a superiority of low-level perception (such as discrimination and pattern perception), resulting in increased attention to lower order cognitive processes, at the expense of higher order ones (eg social interaction) (Mottron & Burack, 2001). In an update to the Enhanced Perceptual Functioning theory, the authors hypothesised that the superior local processing observed in ASD is a result of mandatory global bias in individuals without ASD, even when it is detrimental to task performance (Mottron et al., 2006). The ‘neural noise hypothesis’ also provides an account for atypical sensory reactivity reported in ASD. The concept of a ‘noisy system’ has been proposed in multiple studies and reviews (Dakin & Frith, 2005; Franklin et al., 2010; Sanchez-Marin & Padilla-Medina, 2008; Simmons et al., 2009) to explain the performance of individuals with ASD. When combined with the evidence of increased heterogeneity in ASD, particularly that of intraparticipant variability (Milne, 2011), it was proposed that neural noise could account for the strengths and impairments observed in ASD (Simmons et al., 2007).\n\n\nPoint\n\nThe first sentence outlines the topic of the paragraph.\n\nThere are a number of neural theories of autism that aim to explain the unusual sensory processing reported within this population.\n\n\nEvidence\n\nWe then add evidence to support this point.\n\nThere are a number of neural theories of autism that aim to explain the unusual sensory processing reported within this population. Enhanced Perceptual Functioning (EPF) theory (Mottron, Dawson, Soulières, Hubert, & Burack, 2006) is based on the premise that individuals with ASD exhibit superior local processing abilities. This theory proposes that ASD stems from a superiority of low-level perception (such as discrimination and pattern perception), resulting in increased attention to lower order cognitive processes, at the expense of higher order ones (eg social interaction) (Mottron & Burack, 2001).\n\n\nExplain\n\nOnce you have outlined the evidence, you need to explain what it means for the point you are making.\n\nThere are a number of neural theories of autism that aim to explain the unusual sensory processing reported within this population. Enhanced Perceptual Functioning (EPF) theory (Mottron, Dawson, Soulières, Hubert, & Burack, 2006) is based on the premise that individuals with ASD exhibit superior local processing abilities. This theory proposes that ASD stems from a superiority of low-level perception (such as discrimination and pattern perception), resulting in increased attention to lower order cognitive processes, at the expense of higher order ones (eg social interaction) (Mottron & Burack, 2001). In an update to the Enhanced Perceptual Functioning theory, the authors hypothesised that the superior local processing observed in ASD is a result of mandatory global bias in individuals without ASD, even when it is detrimental to task performance (Mottron et al., 2006). The ‘neural noise hypothesis’ also provides an account for atypical sensory reactivity reported in ASD. The concept of a ‘noisy system’ has been proposed in multiple studies and reviews (Dakin & Frith, 2005; Franklin et al., 2010; Sanchez-Marin & Padilla-Medina, 2008; Simmons et al., 2009) to explain the performance of individuals with ASD.\n\n\nLink\n\nFinally, once you have explained what the evidence means, it is type to wrap up and help transition to the next paragraph.\n\nThere are a number of neural theories of autism that aim to explain the unusual sensory processing reported within this population. Enhanced Perceptual Functioning (EPF) theory (Mottron, Dawson, Soulières, Hubert, & Burack, 2006) is based on the premise that individuals with ASD exhibit superior local processing abilities. This theory proposes that ASD stems from a superiority of low-level perception (such as discrimination and pattern perception), resulting in increased attention to lower order cognitive processes, at the expense of higher order ones (eg social interaction) (Mottron & Burack, 2001). In an update to the Enhanced Perceptual Functioning theory, the authors hypothesised that the superior local processing observed in ASD is a result of mandatory global bias in individuals without ASD, even when it is detrimental to task performance (Mottron et al., 2006). The ‘neural noise hypothesis’ also provides an account for atypical sensory reactivity reported in ASD. The concept of a ‘noisy system’ has been proposed in multiple studies and reviews (Dakin & Frith, 2005; Franklin et al., 2010; Sanchez-Marin & Padilla-Medina, 2008; Simmons et al., 2009) to explain the performance of individuals with ASD. When combined with the evidence of increased heterogeneity in ASD, particularly that of intraparticipant variability (Milne, 2011), it was proposed that neural noise could account for the strengths and impairments observed in ASD (Simmons et al., 2007).\n\nDeveloping good paragraph structure is also a key part of the editing process. It’s perfectly fine to write as much as you can and get your ideas down on a page. However, you then need to go back, proof-read, and edit to make sure your writing is aligned with the PEEL structure.\nKey things to look out for are questioning whether your paragraph contains one key point. If you cannot summarise your paragraph or you are starting to list everything you are covering, its a sign you might need to break down your paragraph into two, and work on new topic and summary/link sentences.\nLikewise, you might see there is a paragraph with just one or two sentences, with little evidence or explanation. This is a sign you might need to add further writing to develop it into a full PEEL paragraph with topic and summary/link sentences.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Academic Writing</span>"
    ]
  },
  {
    "objectID": "06-Writing-07-Writing.html#using-evidence",
    "href": "06-Writing-07-Writing.html#using-evidence",
    "title": "16  Academic Writing",
    "section": "\n16.3 Using evidence",
    "text": "16.3 Using evidence\nAny report you write as a researcher must be evidence-based, otherwise it would be more of an opinion piece. To show what evidence is behind your claims, you must use citations in your report. In this section, we are focusing on the role of citations and how they show what evidence you are using. In the next section on APA formatting, you will learn more about the specific formatting requirements of the citations.\nIt’s not enough to have a single citation at the end of a paragraph, or even a list of citations randomly put in. Every fact, point, and evaluation is likely to have come from someone else’s work or something that has influenced your thinking, so you should cite that source. You need to ensure that you cite the evidence you are using to make your point.\nTry to put the citation near or next to the point you are making to show where that specific point came from, rather than adding a list of citations at the end and expecting the reader to know which citation relates to each claim.\nCompare these sentences:\n\n“Previous research suggests voices can impact our perception of trust (citation), dominance (citation), and attractiveness (citation)”\n“Previous research suggests voices can impact our perception of trust, dominance, and attractiveness (citation; citation; citation)”\n\nThe first sentence says each paper tested one individual variable (trust, dominance or attractiveness). The second sentence says all three papers tested all three variables. Both can be true but you need to keep in mind how citation placement changes the understanding.\nCitations do not have to go just at the end of a sentence. Use them in different places to create a sense of flow and narrative in your writing. If you only use one style of citation, your writing might be less engaging, so try to switch between direct and indirect citations. For a longer demonstration, we will adapt an extract from the following article:\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F., Awtrey, E., Bahník, Š., Bai, F., Bannard, C., Bonnier, E., Carlsson, R., Cheung, F., Christensen, G., Clay, R., Craig, M. A., Dalla Rosa, A., Dam, L., Evans, M. H., Flores Cervantes, I., … Nosek, B. A. (2018). Many Analysts, One Data Set: Making Transparent How Variations in Analytic Choices Affect Results. Advances in Methods and Practices in Psychological Science, 1(3), 337–356. https://doi.org/10.1177/2515245917747646\n\nThink about how the meaning and clarity of who said what changes with citation placement. If unsure, you want to aim for the first version.\n\nOriginal version with bold added to emphasise cited points (note that their citation format is in APA 6th edition and some citations would be formatted slightly different in the 7th edition):\n\n\n“But what if the methodologists are correct? What if scientific results are highly contingent on subjective decisions at the analysis stage? In that case, the process of certifying a particular result on the basis of an idiosyncratic analytic strategy might be fraught with unrecognized uncertainty (Gelman & Loken, 2014), and research findings might be less trustworthy than they at first appear to be (Cumming, 2014). Had the authors made different assumptions, an entirely different result might have been observed (Babtie, Kirk, & Stumpf, 2014).”\n\n\nEdited version with citations moved in the second sentence to add confusion about who says what:\n\n\n“But what if the methodologists are correct? What if scientific results are highly contingent on subjective decisions at the analysis stage? In that case, the process of certifying a particular result on the basis of an idiosyncratic analytic strategy might be fraught with unrecognized uncertainty and research findings might be less trustworthy than they at first appear to be (Cumming, 2014; Gelman & Loken, 2014). Had the authors made different assumptions, an entirely different result might have been observed (Babtie, Kirk, & Stumpf, 2014).”\n\n\nEdited version with all citations moved to the end creating even more confusion as to who said what:\n\n\n“But what if the methodologists are correct? What if scientific results are highly contingent on subjective decisions at the analysis stage? In that case, the process of certifying a particular result on the basis of an idiosyncratic analytic strategy might be fraught with unrecognized uncertainty and research findings might be less trustworthy than they at first appear to be. Had the authors made different assumptions, an entirely different result might have been observed (Babtie, Kirk, & Stumpf, 2014; Cumming, 2014; Gelman & Loken, 2014).”\n\n\nEdited version with no citations which is now just plagiarism when you are not acknowledging the source of information, either intentionally or not:\n\n\n“But what if the methodologists are correct? What if scientific results are highly contingent on subjective decisions at the analysis stage? In that case, the process of certifying a particular result on the basis of an idiosyncratic analytic strategy might be fraught with unrecognized uncertainty and research findings might be less trustworthy than they at first appear to be. Had the authors made different assumptions, an entirely different result might have been observed.”",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Academic Writing</span>"
    ]
  },
  {
    "objectID": "06-Writing-07-Writing.html#apa-formatting",
    "href": "06-Writing-07-Writing.html#apa-formatting",
    "title": "16  Academic Writing",
    "section": "\n16.4 APA formatting",
    "text": "16.4 APA formatting\nWhen you are writing a piece of work and use someone else’s ideas or findings, you must reference them and the specific work you are referring to. In psychology, we use the American Psychological Associations’s (APA) reference style (7th edition). APA style also covers other aspects of formatting such as report headings, presenting tables and figures, and numbers, but we will introduce you to that in future weeks.\nYou may have used other referencing systems in your previous degree (e.g., Harvard), but it is important you use APA for psychology in your current degree programme. Remember, a reference manager can really help with the heavy lifting here and do a lot of the formatting. But you still need to know APA 7 style well enough to spot when there might be errors.\nThere are two things to pay attention to, in-text citations and the reference list.\n\n16.4.1 In-text citations\nIn-text citations are a short version of the source you are referring to in the main text. Citations include the author’s surname and the year of publication.\nDirect citations include the authors’ names as part of the sentence, such as “Karpicke and Roediger (2009) argued…”.\nThey do not contain first names and they typically do not contain initials (the only time you include initials is when you have two authors with the same surname you want to distinguish). There is no article title as it takes up a lot of words and you will be able to see the title in the reference list.\nFor a subtle part of APA style, when two authors are part of the sentence, you use “and” rather than “&” to separate the surnames.\nIndirect citations are when you include the authors’ names and year of publication within brackets. You are still acknowledging the source of evidence, but the surnames are not part of the sentence, such as “…there may be socio-motivational benefits of attending (French & Kennedy, 2017), or…”.\nIndirect citations still do not contain first names nor usually include initials, but this time you use “&” rather than “and” to separate two authors. All the names and year are in parentheses, and there is a comma between the final surname and year.\nThere are slightly different formats for citations depending on whether there is one author, two authors, or three or more authors.\n\nOne author: Jackman (2017) or (Jackman, 2017)\nTwo authors: Jackman and Fassbender (2016) or (Jackman & Fassbender, 2016)\nThree or more authors: Rolfe et al. (2010) or (Rolfe et al., 2010)\n\nThis means you always include all the authors when there are one or two people, but three or more is shortened to first author et al., meaning “and others”.\nSometimes, you will include multiple citations in the same parentheses to show the evidence base behind a given point. If you cite two or more studies, they should be in alphabetical order of the author and separated with a semi-colon, such as “(Phillips et al., 2010; Rolfe et al., 2010)”.\nIf you have two or more studies from the same authors (in the same author order), then you order by year of publication, giving the author’s last names once and adding the date of each subsequent work, such as “(Davies, 2008, 2010, 2012)”.\n\n16.4.2 Reference lists\nA reference list is a list of all the sources you cited in your report. In comparison, a bibliography is a list of all the sources you consulted while writing your report, even when you do not cite them.\nIn psychology, you should only provide a reference list where the references are listed in alphabetical order of the first author’s surname. In this course, you will not need to provide a bibliography.\nAs an example, a reference entry should look like this:\n\nFlake, J. K., & Fried, E. I. (2020). Measurement Schmeasurement: Questionable Measurement Practices and How to Avoid Them. Advances in Methods and Practices in Psychological Science, 3(4), 456–465. https://doi.org/10.1177/2515245920952393\n\nYou start by listing each author by the last name, a comma, their initial(s), and a full stop. Authors are separated by “&”, and after the final author, you include the year of publication in brackets with a full-stop at the end. You have the title of the article which is not in italics. You then have the name of the journal in italics, a comma, and the volume and issue number (in the format “volume number(issue number)”). The issue number is not always available, so you might only include the volume number after the journal name. Finally, you have the page numbers of the article, and DOI (digital object identifier).\n\n\n\n\n\n\nWarning\n\n\n\nThe one thing we cannot easily recreate in the chapters here is a final subtle formatting point. In the reference list, each entry has a hanging indent which you can create in Word or Google Docs. For example, see this resource on how to include a hanging indent in Word.\n\n\nThis demonstrated APA referencing for articles with two numbers, but there are two main differences you will come across.\nThe first is when you have three or more authors, each author is separated by a comma, then the final two authors are separated by “&”, such as:\n\nBostyn, D. H., Sevenhant, S., & Roets, A. (2018). Of Mice, Men, and Trolleys: Hypothetical Judgment Versus Real-Life Behavior in Trolley-Style Moral Dilemmas. Psychological Science, 29(7), 1084-1093. https://doi.org/10.1177/0956797617752640\n\nThe second is when there are many authors. If there are more than 20 authors, the first 19 are reported, you include an ellipsis (…) to show there is a gap, then you report the final author in the list. For example:\n\nEbersole, C. R., Atherton, O. E., Belanger, A. L., Skulborstad, H. M., Allen, J. M., Banks, J. B., Baranski, E., Bernstein, M. J., Bonfiglio, D. B. V., Boucher, L., Brown, E. R., Budiman, N. I., Cairo, A. H., Capaldi, C. A., Chartier, C. R., Chung, J. M., Cicero, D. C., Coleman, J. A., Conway, J. G., … Nosek, B. A. (2016). Many Labs 3: Evaluating participant pool quality across the academic semester via replication. Journal of Experimental Social Psychology, 67, 68–82. https://doi.org/10.1016/j.jesp.2015.10.012\n\n\n16.4.3 Further resources\nThe APA style manual has over 700 pages, so we are not going to cover every type of resource. We have covered journal articles in detail, and the other two sources you will cite most often are books and websites.\n\n\n\n\n\n\nTry this\n\n\n\nIf you needed to cite and reference a book or website, how would you do it? Search the APA style resources to check what information you would need to include compared to a journal article.\n\n\nThere is an APA style website where they have two super useful pages:\n\nReference examples - This page shows examples of citations and references for different sources.\nThe APA style blog - The blog is a useful resource as it includes short articles where people ask questions on how they can format and style certain information. This can be useful for new technology or resources as they cover it before a new edition of the full style guide will be released.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Academic Writing</span>"
    ]
  },
  {
    "objectID": "06-Writing-08-Results1.html",
    "href": "06-Writing-08-Results1.html",
    "title": "17  Structure of the Results",
    "section": "",
    "text": "17.1 Restate your hypothesis from the stage one report\nCompared to your stage one report, you might justify changing which statistical test is most appropriate, but your hypothesis should never change. You might no longer think it is a good idea or it could be expressed better, but that would be a lesson for the future. For your stage two report, your hypothesis should be the exact same one as you predicted in your group for the stage one report (if you had one in the first place). We promote initiatives like registered reports to avoid this kind of thing as changing your hypothesis risks HARKing - hypothesising after the results are known.\nSome things we recommend here you might not see in published articles. It’s rare to see articles restate the hypothesis in the results section after already including it in the introduction, but just because published research could be presented better does not mean we want to reinforce bad habits.\nRestating the hypothesis helps the reader as they might not have remembered it from the introduction, so after reading the method, they might have to skip back to the introduction to remind themselves. So, restating the hypothesis reminds the reader and frames what you are testing in the results.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Structure of the Results</span>"
    ]
  },
  {
    "objectID": "06-Writing-08-Results1.html#restate-your-hypothesis-from-the-stage-one-report",
    "href": "06-Writing-08-Results1.html#restate-your-hypothesis-from-the-stage-one-report",
    "title": "17  Structure of the Results",
    "section": "",
    "text": "Note\n\n\n\nRemember, a research question is essential, but a hypothesis is not. If your study was purely exploratory, it is perfectly legitimate for the aim of your study to simply explore a topic, providing it is labelled as such. Likewise, if you had a clear hypothesis in the introduction, then the aim of your study is more on the confirmatory side. Both are valid aims for a study, you just need to be honest about what the original aim of your study was.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Structure of the Results</span>"
    ]
  },
  {
    "objectID": "06-Writing-08-Results1.html#deviations-from-your-stage-one-report",
    "href": "06-Writing-08-Results1.html#deviations-from-your-stage-one-report",
    "title": "17  Structure of the Results",
    "section": "\n17.2 Deviations from your stage one report",
    "text": "17.2 Deviations from your stage one report\nThe idea behind outlining your plans ahead of time through the registered report format or pre-registering a study is to avoid changing what you planned on doing and intentionally or unintentionally rationalising it after the fact. We know from meta-scientific research (refer back to lecture 1) that changing how you plan on processing and analysing your data can lead to more Type I errors, so we encourage you to be transparent about what you planned and what you actually did.\nYou can still change you mind, there is a common phrase “its a plan, not a prison. However, outlining your plan ahead of time means you can stick to it if you still think your plan is appropriate, or you are forced to explain and justify changes to your plan. If you have no deviations to note and you approached the data analysis in the same way you outlined in the stage one report, then you do not need this section.\nFor communication, avoid referring readers back to the stage one report as a means to cut words. Instead of saying “we changed our exclusion criteria (see stage one report)…”, include the relevant details in the text as one extra sentence could help communication for the reader to understand and avoid having to search for further details to understand your study.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Structure of the Results</span>"
    ]
  },
  {
    "objectID": "06-Writing-08-Results1.html#assumption-checks",
    "href": "06-Writing-08-Results1.html#assumption-checks",
    "title": "17  Structure of the Results",
    "section": "\n17.3 Assumption checks",
    "text": "17.3 Assumption checks\nThis is a component we want to see from you but it is exceptionally rare to see in published articles. When there are strict word counts, this is something people see as expendable, particularly if all the assumption checks past, so it is rare to see unless the authors had to deal with a specific problem.\nWhen we use statistical tests, they make assumptions about the data you are putting into them to behave as intended and give you accurate inferences. This content can be quite short, but we want to see which assumptions you tested, how you tested them, and what the outcome was.\n\n\n\n\n\n\nImportant\n\n\n\nYou need to explain which assumptions you checked, how you checked them, and whether they passed the checks, but you do not need to provide long explanations of what the assumptions are. You are working to a word count, so you can assume the reader knows what the assumptions are, you are just telling them whether you consider them to hold or not.\n\n\nFor example, if you intended to perform a Pearson’s correlation or simple linear regression, you would check for normality of residuals, interval-level data, linearity, and homoscedasticity. You would outline how you checked these, such as looking at diagnostic okits, and whether you still think using a parametric test like Pearson’s is appropriate.\n\n\n\n\n\n\nNote\n\n\n\nYou check most of the assumptions using diagnostic plots and your own interpretation, so often there is no black and white answer. It is a judgement call that you must be able to explain and justify. The assumptions will never be perfect, so it is not about talking yourself out of using a parametric test, just checking it would be appropriate to use.\n\n\nFor checks that involve diagnostic plots, these are not typically included in the main text. It would take up a lot of space, so you add them to an appendix section and after explaining what you checked and what you conclude, refer the reader to the appendix if they want to look at the diagnostic plots themselves.\nThis section ties into any deviations from the stage one report. In the design and data analysis sub-section, you will have explained what statistical test you planned on using. You did not have the data at that point, so it was only your plan. If you checked the assumptions and that test would no longer be appropriate, you can change it, but you need to explain it is a deviation.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Structure of the Results</span>"
    ]
  },
  {
    "objectID": "06-Writing-08-Results1.html#descriptive-statistics",
    "href": "06-Writing-08-Results1.html#descriptive-statistics",
    "title": "17  Structure of the Results",
    "section": "\n17.4 Descriptive statistics",
    "text": "17.4 Descriptive statistics\nDescriptive statistics are summaries of your variables to help explain the context of your study and outline initial trends. For example, the mean and standard deviation (or median and interquartile range) of your variables to summarise how participants responded.\n\n\n\n\n\n\nWarning\n\n\n\nYou can describe general trends from your descriptive statistics to add narrative for the reader, but in isolation, they do not support or reject a hypothesis. Only the inferential statistics support or reject a hypothesis. All you can talk about at this point is whether the pattern is consistent with what you expected or not.\n\n\n\n17.4.1 Descriptive statistics for correlations / continuous predictors\nIn the context of correlations or regression with a continuous predictor, it is normally useful to provide the mean and standard deviation (or median and interquartile range) of your variables. This helps to see how your participants responded to the variables and you could compare how your sample compared to the norms of the scale once you get to the discussion if this is something worth talking about.\nAPA formatting\nThere are a few guiding principles here which the APA style website covers in a short numbers and statistics guide.\nMeans and standard deviations are typically reported to two decimal places. If the number can be larger than 1, then you include a leading zero (e.g., 0.34). but numbers than cannot be larger than 1 exclude a leading zero (e.g., .34). Use the symbol or abbreviation for statistics if there is a mathematical operator (e.g, M = 6.82, SD = 1.25), where the symbol is in italics. However, if you use the term in the main text, then you write it in full rather than the symbol (e.g., “the mean help-seeking rating was 6.82 (SD = 1.25)”).\nYou can include tables to help report descriptive statistics when there is a lot of information to present and you want to show the values for many variables. For this course and assignment, you almost certainly do not need a table as there is not enough information to present when you only have two variables. On the other hand, figures are always useful to show a plot of your data. For a correlation, this is typically a scatterplot showing the relationship between your two variables.\nWe dedicate the next chapter - Data Visualisation - to guidance on formatting tables and figures in APA style.\n\n17.4.2 Descriptive statistics for t-test / categorical predictors\nIn the context of t-tests and regression with a categorical predictor, it is normally useful to provide the mean and standard deviation (or median and interquartile range) of your groups. This helps to see how your participants responded and whether the initial differences are consistent with what you expected, such as whether one group scored higher on average than the second group.\nYou can include tables to help report descriptive statistics when there is a lot of information to present and you want to show the values for many variables or groups. For this course and assignment, you almost certainly do not need a table as there is not enough information to present when you only have two groups. On the other hand, figures are always useful to show a plot of your data. For a t-test, this is typically a violin-boxplot to show the difference and distribution of data between your two groups.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Structure of the Results</span>"
    ]
  },
  {
    "objectID": "06-Writing-08-Results1.html#inferential-statistics",
    "href": "06-Writing-08-Results1.html#inferential-statistics",
    "title": "17  Structure of the Results",
    "section": "\n17.5 Inferential statistics",
    "text": "17.5 Inferential statistics\nAfter presenting your descriptive statistics, you can present your inferential statistical tests to see if you can support or reject your hypothesis. Statistical tests have a standardised format in APA style to ensure you report the key information and readers can easily find what they are looking for.\n\n17.5.1 Correlations and continuous predictors\nIf you report a correlation, the individual tests have standardised formatting.\nPearson’s r\nPearson’s r should be reported as follows: r (303) = -.70, 95% CI = [-.75, -.64], p &lt; .001.\nTo break down each component:\n\nr: Symbol for the test statistic in italics\n(303): Degrees of freedom\n-.70: r value reported to 2 decimals with no leading zero\n95% CI = [-.75, -.64]: 95% confidence interval in square brackets to provide the interval estimation\np &lt; .001: p-values reported to three decimals, where p-values smaller than .001 are reported as p &lt; .001, and p-values larger than .001 are written exact, e.g., p = .023.\n\nSpearman’s rho\nSpearman’s rho is almost identical, but you include a subscript to distinguish it from Pearson’s r: \\(r_s\\) (303) = -.68, 95% CI = [-.74, -.61], p &lt; .001.”\n\n\\(r_s\\): Symbol for the test statistic in italics (here with a subscript to identify it as Spearman’s)\n(303): Degrees of freedom\n-.68: r value reported to 2 decimals with no leading zero\n95% CI = [-.75, -.61]: 95% confidence interval in square brackets to provide the interval estimation\np &lt; .001: p-values reported to three decimals, where p-values smaller than .001 are reported as p &lt; .001, and p-values larger than .001 are written exact, e.g., p = .023.\n\nWhen describing the results of your statistical test in words, remember to mention whether it is statistically significant or not, and the size and direction of the effect size. For example,\n\nUsing a two-tailed Pearson’s correlation, we found a large significant negative correlation between perceived fairness and satisfaction and support for wealth redistribution, r (303) = -.70, 95% CI = [-.75, -.64], p &lt; .001.\n\nWe explain we used a two-tailed test, we used Pearson’s r as the statistical test, it is described as significant to conclude we rejected the null hypothesis, and it is a large negative correlation to comment on the strength and direction of the effect.\n\n\n\n\n\n\nWarning\n\n\n\nRemember in the null hypothesis significance testing framework, we use it to help us make decisions. It has it’s limitations, but it’s designed to control error rates in correctly rejecting the null hypothesis or not. You can either conclude it is statistically significant or not statistically significant for a given alpha. You do not describe it as insignificant, and it is not consistent with the philosophy to try and spin a result as “marginally significant”.\n\n\n\n17.5.2 t-tests and categorical predictors\nIf you report a t-test, the individual tests have standardised formatting.\nStudent or Welch’s t-test\nA t-test should be reported as follows: t (33.43) = -3.48, , p = .001, Cohen’s d = 1.13, 95% CI = [0.45, 1.81].\nTo break down each component:\n\nt: Symbol for the test statistic in italics.\n(33.43): Degrees of freedom which will be a whole number for a Student t-test (e.g., 34) but a decimal for a Welch’s t-test (e.g., 33.43).\n-3.48: t value reported to 2 decimals with a leading zero if applicable, including whether it is positive or negative.\np = .001: p-values reported to three decimals, where p-values smaller than .001 are reported as p &lt; .001, and p-values larger than .001 are written exact, e.g., p = .023.\nCohen’s d = 1.12: Your standardised or unstandardised effect size estimate, here the standardised mean difference between groups known as Cohen’s d. Reported to two decimals with a leading zero since it can be greater than 1.\n95% CI = [0.43, 1.81]: 95% confidence interval in square brackets to provide the interval estimation for the effect size you report.\n\n\n\n\n\n\n\nNote\n\n\n\nDoes it matter if my t-value or effect size is positive or negative? No, it’s the absolute number which shows the size of the effect for a t-test. Both the t-value and effect sizes use group 1 minus group 2 in their equations. So, if group 1 is bigger than group 2, the t-value and effect size will be positive, and if group 2 is bigger than group 1, the t-value and effect size will be negative. The important thing is just be consistent, so if you report a positive t-value, the effect size should also be expressed as a positive difference.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember in the null hypothesis significance testing framework, we use it to help us make decisions. It has it’s limitations, but it’s designed to control error rates in correctly rejecting the null hypothesis or not. You can either conclude it is statistically significant or not statistically significant for a given alpha. You do not describe it as insignificant, and it is not consistent with the philosophy to try and spin a result as “marginally significant”.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Structure of the Results</span>"
    ]
  },
  {
    "objectID": "06-Writing-08-Results1.html#statement-on-your-hypothesis",
    "href": "06-Writing-08-Results1.html#statement-on-your-hypothesis",
    "title": "17  Structure of the Results",
    "section": "\n17.6 Statement on your hypothesis",
    "text": "17.6 Statement on your hypothesis\nNow you have presented the results of your inferential statistics, the final component comments on what it means for your hypothesis. Did it support your prediction or not? This is not meant to be a full exploration, you will have the discussion section for that next, you are just stating whether the results supported your hypothesis or not.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Structure of the Results</span>"
    ]
  },
  {
    "objectID": "06-Writing-08-Results1.html#bringing-it-all-together",
    "href": "06-Writing-08-Results1.html#bringing-it-all-together",
    "title": "17  Structure of the Results",
    "section": "\n17.7 Bringing it all together",
    "text": "17.7 Bringing it all together\nFor statistical tests like correlations, t-tests, and simple linear regression we cover in RM1, the results section will not be very long. We want you to focus on outlining the key information and interpretation, rather than adding unnecessary words. We can summarise the final three components in a short paragraph for both a correlation and t-test context.\n\n17.7.1 Correlations / continuous predictors\n\nThe mean fairness and satisfaction rating was 3.54 (SD = 2.02) and the mean support for wealth redistribution was 3.91 (SD = 1.15). Figure 1 provides a scatterplot showing a negative relationship between the two variables. Using a two-tailed Pearson’s correlation, we found a large significant negative correlation between perceived fairness and satisfaction and support for wealth redistribution, r (303) = .-70, 95% CI = [-.75, -.64], p &lt; .001. This supports our hypothesis that there would be a relationship between perceived fairness and satisfaction and attitudes on wealth redistribution, suggesting that higher levels of support for wealth redistribution are associated with lower levels of perceived fairness and satisfaction of the current system.\n\n\nFigure 1\n\n\nScatterplot showing a negative relationship between support for wealth redistribution and perceived fairness and satisfaction of the current system.\n\n\n\n\n\n\n\n\n\n\n17.7.2 t-tests / categorical predictors\n\nThe mean candidate intellect rating was 5.63 (SD = 1.91) in the audio group and the mean rating in the transcript group was 3.65 (SD = 1.61). Figure 1 provides a violin-boxplot showing the difference between the two groups. We found recruiters who listened to an audio recording rated the candidate’s intellect as 1.99 units higher (95% CI = [0.83, 3.15]) than recruiters who read a transcript, where a two-tailed Welch’s t-test was statistically significant, t (33.43) = 3.48, p = .001, Cohen’s d = 1.12, 95% CI = [0.43, 1.81]. This supports our hypothesis that there would be a difference in intellect ratings between recruiters who hear an audio recording or read a transcript.\n\n\nFigure 1\n\n\nA violin-boxplot showing higher candidate intellect ratings in the audio group compared to the transcript group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nShould I report the mean difference or Cohen’s d for the standardised mean difference? There are different arguments around which effect sizes are most useful, so there is nothing wrong with reporting both if you have the space. Unstandardised effects are easier to understand and in the original units of measurement, meaning it is easier to compare between similar studies. Standardised effect sizes can - in theory - be used to compare effects from different measure and are useful for future power analyses, so it can be useful for the reader to report both. If you need to report just one, think which one will be most useful when it comes to putting your effect size in context in the discussion.\n\n\nAs a parting note, remember we outline these six key components to help you present the key information and inferences to your reader, but there is no one single correct way of presenting the information. The previous paragraph was only an example, and providing you include the key information with appropriate APA formatting and maintain logical flow, there are equally valid ways of presenting your results.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Structure of the Results</span>"
    ]
  },
  {
    "objectID": "06-Writing-09-Results2.html",
    "href": "06-Writing-09-Results2.html",
    "title": "18  Data Visualisation",
    "section": "",
    "text": "18.1 The role of data visualisation and formatting\nFirst, data visualisation is important for you as the researcher. Exploratory data analysis should be the first step in your data analysis toolkit to see what your data look like, check for potential problems, and identify initial patterns.\nTo demonstrate why this is important, the dinosaur dozen shows how the same summary statistics (e.g., mean and standard deviation) can be identical but result from dramatically different data patterns. For example, creating a graph of a star, a cross, and yes, even a dinosaur can have the same underlying mean, standard deviation, and correlation. Yanai and Lercher (2020) found that students would not recognise an image of a gorilla recreated as data points when they were focused on rushing to apply a statistical test. Therefore, exploratory data analysis is important in the initial steps of data analysis to check what patterns are present and if the data properties are consistent with what you expect.\nSecond, data visualisation is important for your reader. Visualisations can communicate your message more effectively than a written summary or a wall of numbers, but it is crucial to balance efficiency with transparency. It can be easy to confuse or mislead people with poorly designed visualisations.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Data Visualisation</span>"
    ]
  },
  {
    "objectID": "06-Writing-09-Results2.html#data-viz",
    "href": "06-Writing-09-Results2.html#data-viz",
    "title": "18  Data Visualisation",
    "section": "",
    "text": "18.1.1 Data visualisation principles\nEffective (or misleading) data visualisation is a whole field of study, so we will just outline a few key principles to keep in mind when designing your plots to help communicate your data as effectively and honestly as possible. If this is something that interests you, we recommend chapter one - looking at data - from Data Visualisation by Healy (2018) and the comprehensive review article The Science of Visual Data Communication: What Works by Franconeri et al. (2021) for further reading.\n\n18.1.1.1 Visual illusions\nYour visual system is pretty powerful and allows you to rapidly search for patterns in visual information. But for the same reasons that make graphs effective at communicating information, design features can also play tricks on the visual system and create illusions.\nWithin the bar bias\nBar plots are extremely common to see in journal articles and the media as they are easy to interpret. They are designed to communicate frequencies or percentages of observations where the top of each bar corresponds to the frequency of each variable or level you are plotting. Bar plots visualise frequencies well but they should not be used to summarise averages of continuous data, such as the mean of different groups. As the height of the bar only corresponds with the value of the mean, it hides other information like the distribution of observations behind the mean, and perception research shows people mistakenly think values within the bars are more likely than values outside the bars.\nFor example, the bars in A below look identical when you just plot the means, but if you superimpose the data points in B, it shows a very different underlying pattern. This shows why it is important to consider what type of plot would effectively communicate the data you are working with and it is best to use something like a violin-boxplot for continuous outcomes.\n\n\n\n\n\n\n\n\nY-axis truncation\nOne of the most powerful and most common illusions that can mislead people is truncated or non-zero axes, where (typically) the y-axis is shortened to zoom in on a smaller range of values. Franconeri et al. (2021) discuss studies that show people overestimate differences between two groups when you tell them the truncation is present and even if you get people to manually enter the values from each bar. For example, the bar plot below shows the same difference across the full 0 to 100 scale (A), then truncated between 45 and 60 to highlight the difference (B).\n\n\n\n\n\n\n\n\nThis is another area where it takes time and experience to recognise where y-axis trunctation is misleading or not. Although we are not trying to turn this into a bar plot witch hunt, as a general rule of thumb, its usually not a good idea to truncate the y-axis of a bar plot as they are meant to display frequencies with a logical zero point. On the other hand, its acceptable to truncate line plots as they are designed to show changes across time.\nColour-vision impairments\nOne important design feature is how you will distinguish between different elements of your graph. Colour can be used to effectively code different groups or conditions, but many analysts do not think carefully about colour combinations. Colour-vision impairments affect a significant number of people, so it is important to consider whether someone who is colour blind could distinguish between groups/conditions and understand the message you are trying to communicate. In the plot below, on the top (A) is a scatterplot using green and purple, which can look identical for some types of colourblindness. On the bottom (B) is the same scatterplot using a colour blind friendly palette of greens.\n\n\n\n\n\n\n\n\n\n18.1.1.2 Highlight comparisons of interest\nIf you create plots with multiple variables, you will have control over which variable you place on the x-axis and which you place on the legend. It is important to think about which comparison you want your readers to make. Comparing features is a serial process which takes time and working memory, so your readers’ eyes must move between the different components and consider which are higher or lower as they move around the graph. This means you should make it easier for your readers to make the key comparisons by using connectivity and proximity.\nIn the graph below, there are two ways of presenting the same data. In plot A, condition is on the x-axis while language is a grouping variable. In plot B, these are flipped with language on the x-axis and condition as a grouping variable. When creating this plot, you would need to consider whether you want to draw people’s attention to the comparison between language groups or between the word/non-word conditions.\nIf you wanted to emphasise the difference between conditions, then plot A forces people to shift their attention back and forth between non-word and word conditions across the whole plot. Compare this to plot B where the two conditions are placed side by side. In this version, it is much easier to compare the two conditions as they are proximal to each other. If you wanted to emphasise language, then the opposite would apply with plot A having language proximal to each other.\n\n\n\n\n\n\n\n\n\n18.1.1.3 Guide viewers to your conceptual message\nFinally, it is important to respect associations between visualisation designs and data types. When interpreting plots, people rely on schemas to interpret the information they are presented. These associations are relatively universal like top vs bottom for the position (closer to the top means a greater value) and light vs dark for luminescence (darker colours on a light background means a greater value). Similarly, plot types are designed to work with certain combinations of data, like a bar plot uses categorical variables for bars and the bar height shows frequencies or your outcome. When you go against these schemas, it can be deeply confusing for your reader.\nThis is another area where subject knowledge is important as some disciplines have their own conventions which can change over time. For example, in EEG research (Electroencephalography - where brain activity is measured with electrodes stuck to the scalp) it was conventional to plot amplitude with negative values at the top and positives values at the bottom (plot A below). This can look a little odd to those unfamiliar with EEG data and breaks conventional understanding that top means higher numbers. Over time though, this convention has changed and more studies report amplitude with positive values at the top (plot B below). This shows how conventions change over time and it is important to keep your audience in mind to make your data visualisation as accessible and intuitive as possible.\n\n\n\n\n\n\n\n\n\n18.1.2 Formatting tables\nAfter working through some data visualisation principles, it is time to highlight key APA formatting details if you want to include them in your report.\nTables are designed to efficiently communicate a large amount of data, when it would take too long to outline in the main text. So, the first key consideration of a table is whether you need one at all. If you are only reporting a few numbers or you include them all in the main text anyway, you do not need a table.\nIf you do have enough information to communicate, then an APA formatted table looks like the figure below and includes the following features:\n\n\n\n\n\n\n\n\n\nIt should be numbered sequentially for the order you place it in the report (e.g., Table 1 comes before Table 2).\nIt includes an informative title in italics to explain to the reader what information it contains.\nThe row and column headers are informative, so the reader can understand the table in isolation.\nThere are no vertical lines and you limit borders to those needed for clarity.\nIf you need to provide further information, you can include a note below the table, such as if you need to define abbreviations. This is not always applicable.\n\nFor full details, the APA style website has a great page on the key features of an APA formatted table.\n\n18.1.3 Formatting figures\nIn contrast to tables, figures are always useful to help communicate your findings and supplement any statistics you report. We recommend including a figure for each main analysis or component of the analysis.\nNote they are called figures and not numbered plots or graphs in APA style. Figure is a more general term as it could contain a plot, a screenshot, or a drawing depending on what you need to communicate your reader. Essentially, it could be anything other than a table, but most of the time in a psychology report you will be communicating a plot.\nAn APA formatted figure looks like below and includes the following features:\n\n\n\n\n\n\n\n\n\nFigures should be numbered sequentially for the order you place them in the report (e.g., Figure 1 comes before Figure 2), and they are number separately to tables (i.e., you can have both a Table 1 and Figure 1).\nIt includes an informative title in italics to explain to the reader what information it contains.\nYou should edit the axis labels so that readers can understand the figure in isolation.\nIf there are specific features like error bars, you should define what they represent in the title or note.\nIf you need to provide supplementary information, you can include a note below the figure, such as if you need to define abbreviations, but this is not always applicable.\n\nFor full details, the APA style website has a great page on the key features of an APA formatted figure.\n\n\n\n\n\n\nTop tip\n\n\n\nTop tip: If you use Word to write your assignments, figure placement can be a nightmare and become separated from the title. So, if you insert a 1x2 table, you can add the figure number and title in the first row and figure image in the second row, then make the borders transparent. This means the title and figure will always be connected.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Data Visualisation</span>"
    ]
  },
  {
    "objectID": "06-Writing-10-Discussion1.html",
    "href": "06-Writing-10-Discussion1.html",
    "title": "19  Structure of the Discussion",
    "section": "",
    "text": "19.1 Brief summary of main findings\nThe first paragraph or two of the discussion summarises your findings without all the statistics you presented in the results. You might mention the key effect size(s), but this is not a repetition of the results section. The idea is to summarise your findings in plain English and link back to your research question and hypothesis (if applicable) so it’s clear to the reader what you conclude.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Structure of the Discussion</span>"
    ]
  },
  {
    "objectID": "06-Writing-10-Discussion1.html#put-your-findings-in-context",
    "href": "06-Writing-10-Discussion1.html#put-your-findings-in-context",
    "title": "19  Structure of the Discussion",
    "section": "\n19.2 Put your findings in context",
    "text": "19.2 Put your findings in context\nThe longest component in the discussion is putting your findings in context compared to previous research and theory. You will reuse many of the references from the introduction as these are the studies that influenced you, so they are going to be the most relevant. However, you can still bring in new references if there is a relevant study you found in the meantime, or you found something you did not expect, so you had to identify additional evidence.\nThe key consideration here is you are explaining to the reader how your work builds on what you already knew. Were your findings consistent with past studies or were they inconsistent? Did you find a smaller or larger effect size than previous studies? If you found different results than previous studies, are there key differences in your methods that might explain those differences?\nDiscussions are quite speculative as you are providing explanations for your findings, but knowledge/research and evaluation skills are still important. It is still crucial to cite evidence in support of your ideas and bring in relevant theory to provide a framework for your explanations wherever possible.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Structure of the Discussion</span>"
    ]
  },
  {
    "objectID": "06-Writing-10-Discussion1.html#consideration-of-any-limitations-generalisability-and-future-directions",
    "href": "06-Writing-10-Discussion1.html#consideration-of-any-limitations-generalisability-and-future-directions",
    "title": "19  Structure of the Discussion",
    "section": "\n19.3 Consideration of any limitations, generalisability, and future directions",
    "text": "19.3 Consideration of any limitations, generalisability, and future directions\nAfter putting your findings in context, you explain to the reader what your study could and could not tell you. Limitations are about highlighting weaknesses in your study and managing expectations, rather than overselling your results.\nIt takes time to develop a sense of what a valid limitation is as its easy to make it sound like your study was useless. No study is perfect but likewise no study can cover everything. You do not need to list everything that was missing or include what you consider personal limitations like data analysis is not your strength.\nWe will spend additional time on this in week 9 to develop a better sense of identifying and evaluating limitations, but for now, the key thing is identifying one or two features of your study’s method that you consider a weaknesses for what you can conclude. For example, you think your measure is useful but maybe you think it might not generalise to real-life behaviour. So, you would outline your limitation, support your reasoning with evidence on the validity of your measure, and link to future research on what you would do in future to address the limitation.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Structure of the Discussion</span>"
    ]
  },
  {
    "objectID": "06-Writing-10-Discussion1.html#conclusion",
    "href": "06-Writing-10-Discussion1.html#conclusion",
    "title": "19  Structure of the Discussion",
    "section": "\n19.4 Conclusion",
    "text": "19.4 Conclusion\nThe final part of your discussion and report is a brief conclusion. This is typically a paragraph or two to remind the reader of your take home message. Consider it an executive summary of what your research question was and what you found in your study. It’s the final thing the reader will see, so recap all the key points you want them to remember.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Structure of the Discussion</span>"
    ]
  },
  {
    "objectID": "06-Writing-11-Abstracts.html",
    "href": "06-Writing-11-Abstracts.html",
    "title": "20  Limitations and Structure of the Abstract",
    "section": "",
    "text": "20.1 Identifying limitations\nLast week, we outlined the structure of the discussion. A key component of the discussion is outlining limitations which are features of your study that may threaten the validity of your findings or how these features affect how much confidence you have in your findings/conclusions. It is not about tearing your study apart or the reader will just think “why did you bother in the first place”, but if you can own your limitations, it shows you have carefully considered what conclusions you can and cannot make, rather than overselling your findings.\nIt takes time and experience to build an understanding of what limitations affect a given area of study or methods, so we wanted to spend extra time on identifying limitations in addition to the chapter on the discussion section.\nBefore we start outlining common types of limitations, it is important for the future when you design your own study that you should consider limitations from the design phase. Once you have conducted the study, there is nothing you can do about them. However, no individual study provides the definitive answer to a research question. You must make decisions and often you must make compromises when designing a study. So, try and avoid as many limitations as you can in the design phase, and for the limitations you cannot avoid, make sure you can justify why you accepted the limitation.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Limitations and Structure of the Abstract</span>"
    ]
  },
  {
    "objectID": "06-Writing-11-Abstracts.html#identifying-limitations",
    "href": "06-Writing-11-Abstracts.html#identifying-limitations",
    "title": "20  Limitations and Structure of the Abstract",
    "section": "",
    "text": "20.1.1 The four validities\nLimitations typically focus on your methods as they are elements you no longer have any control over. Clarke and colleagues have released some excellent articles on limitations in psychology articles and reinforce the idea of the four validities. These are not exhaustive and there are some limitations which cannot be classified this way, but we think it is a good way to develop an appreciation of what limitations are and provide inspiration for what features you might identify as limitations.\nWe covered validity in lecture 2 alongside research design and reliability. Validity relates to the truth of an inference (Clarke et al., 2023), meaning how confident you can be in the conclusions you made from a given finding. The four validities relate to different elements that affect that confidence:\n\nExternal validity - how generalisable you think a finding is.\nConstruct validity - how well a measure or manipulation represents a given psychological construct.\nInternal validity - whether there is evidence of a causal relationship between your variables.\nStatistical conclusion validity - whether your statistical approach can provide valid inferential statistics.\n\nBefore we outline the kind of features that you could question as a limitation, Clarke et al. (2024) provide guidance on how to approach identifying limitations:\n\nFocus on your most important limitations - avoid the temptation to list every limitation you can think of. It is not about undermining your study or distracting the reader, but highlighting one or two in detail and do them justice.\nBe specific - avoid generic limitations that could be applied to almost any study. It is important to contextualise the limitation you identified and explain how it affects what you can conclude from your specific study.\nExplain, don’t excuse - You do not need to spin your limitations as a strength (think of a job interview where someone says “I’m too much of a perfectionist”), the critical reader is interested in how you can explain the implications of your limitations for the conclusions you make.\n\nIf you have time, we recommend reading the article from Clarke et al. (2024) in full as they provide advice on better practice in outlining limitations, but for this chapter, we will summarise their key categories.\n\n20.1.1.1 External validity\n\nSelection bias - Did you use a representative sample of your target population in your study? Does your sample not include traditionally underrepresented or understudied populations?\nLimited generalisability across cultures - Can you apply the findings from the cultural context of your study to another cultural context?\nSituation effects - Would you expect the findings to be consistent across new contexts or time periods?\nLow realism - Could your sample setting and choice of measure generalise from your study to your target setting and construct?\nTheoretical generalisability - Does the theory behind your study apply universally to all humans or would it only apply locally to a specific population?\n\n20.1.1.2 Construct validity\n\nConstruct definition errors and ambiguities - Did you clearly define your psychological construct and choose a measure accordingly?\nInsufficient validity evidence - Is there sufficient validity evidence for your measures and/or manipulations?\nUsing measures/manipulations with little or no validation - If you developed a measure/manipulation specifically for your study, is there evidence it is valid and reliable?\nShort measures - If a measure is too short, is this a limitation or is there sufficient validation evidence?\nOver-reliance on self-reports - If you measure your construct with a self-report method, is this the best way to measure your construct?\n\n20.1.1.3 Internal validity\n\nObservational study - If you did not conduct an experiment or provide specific inferential evidence for a causal relationship, how could your inferences be biased by potential confounding variables?\nReverse causation - If you did not provide specific inferential evidence for a causal relationship, how plausible would each direction of the relationship be?\nUnobserved confounding - If you did not provide specific inferential evidence for a causal relationship, what plausible additional confounding variables could there be?\n\n20.1.1.4 Statistical conclusion validity\n\nExploratory research - Are you making strong conclusions based on unplanned analyses with an unknown false positive error rate?\nUnderpowered research - Did you use a sufficient number of participants to detect your smallest effect size of interest?\nWeak statistical evidence - Do your main conclusions rely on weak statistical evidence, such as a p-value very close to your alpha?\nSmall effect sizes - What is the practical significance of your effect size estimate?\n\n20.1.2 Summary\nHopefully, dedicating extra space to identifying limitations provides inspiration for what features of your study could affect confidence in your findings. Remember this is not about intentionally undermining your study, but instilling trustworthiness by realistically adding caveats for what you can and cannot conclude in your study. The four validities popularised by the work of Clarke et al. are meant to provide a starting point and help calibrate your understanding of what a legitimate limitation is. If you can identify a limitation applicable to your study that is not covered here, you can still outline it, but it is important you are specific and support your evaluation with evidence wherever possible.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Limitations and Structure of the Abstract</span>"
    ]
  },
  {
    "objectID": "06-Writing-11-Abstracts.html#structure-of-the-abstract",
    "href": "06-Writing-11-Abstracts.html#structure-of-the-abstract",
    "title": "20  Limitations and Structure of the Abstract",
    "section": "\n20.2 Structure of the abstract",
    "text": "20.2 Structure of the abstract\nThe abstract is a summary of the entire report. It comes right at the very start and is the first thing people will read. That said, it is normally the last thing that people write as it summarises all the different sections of the report you will have already written.\nThe abstract highlights the key point or points from each section of the report: the introduction, the methods, the results, and the discussion. In other words, Gernsbacher (2018) describes it as “A clear abstract states the study’s primary hypothesis; its major methodology, including its sample size and sampled population; its main findings, along with their summary statistics; and its key implications”. Koopman (1997, cited in Derntl, 2014) suggests the following structure:\n\nMotivation (General Area): Why do we care about the problem and the results?\nProblem (Aim of Paper - Research Question): What problem is the paper trying to solve and what is the scope of the work?\nSolution (Methods): What was done to solve the problem?\nResults: What is the answer to the problem?\nImplications: What implications does the answer imply?\n\nIdeally, you are looking for one or two sentences from each of the different sections. You do not normally just copy and paste a sentence from each part, rather summarising the key information from each part. Remember this is a rough guide for how much detail you need. It would not be a problem if you need three sentences to outline a key component, but you probably do not need six sentences for each. We will now elaborate on those key areas.\nStart off with the background and rationale\n\nHere you are looking for one or two sentences giving the brief background of the study for what we know, then the main problem you wanted to address or issues in the current field - basically your rationale for the current study. This provides an insight into the research question for your study.\n\nThe method\n\nThis is not a highly detailed summary, rather an overview of your approach, stating things like the number of participants, who were they, and what they did.\n\nThe Results\n\nState the main findings and what tests you used. We tend not to outline all the numbers in an abstract, but it can be useful to report key effect sizes. Think of it like a short version of how you would start the discussion section.\n\nBrief interpretation or implications of the study\n\nYou are looking to cover the main outcome of your study, trying to relate that back to theory or the main issue you wanted to address - your rationale. See it as “closing the loop” to see if you addressed your research question.\nTry and avoid ending on limitations as these will be covered in your report. The main point of this final component is to briefly relate your findings to previous research and theory.\nIt is also a waste of words to end on something uninformative like “the implications of the results will be discussed”. We would consider this a given, so try and offer the reader something concrete.\n\nFor some final formatting advice, it is normally written as one paragraph approximately 200-250 words long. For an APA style report:\n\nIt will appear on the first page after your title page.\nWe recommend the single paragraph approach, but some journals request a “structured” abstract where the key components are broken down into little headers. For this course, we would like you to start learning the key components and write it as a single paragraph, but we want to make you aware there are differences in style.\nIt should have the title at the top of the abstract. The title does not count in the 200-250 words.\nYou do not need to add keywords at the end of the abstract. You will see these included in some journal articles, but you do not need them for a student report.\n\n\n20.2.1 Breaking down an example abstract\nLooking at examples can help show how the ideas build up. Here is an adapted example from Tsantani et al (2016) broken down to highlight the key components.\n\n20.2.1.1 Background and rationale\n\nVocal pitch has been found to influence judgments of perceived trustworthiness and dominance from a novel voice. However, the majority of findings arise from using only male voices and it is unclear how the pitch of female voices affects judgements of trust and dominance. Here we explore the influence of average vocal pitch on first-impression judgments of perceived trustworthiness and dominance and hypothesise that there will be a preference for low-pitched voices in both genders regardless of judgement.\n\n\n20.2.1.2 Methods\n\nVocal pitch has been found to influence judgments of perceived trustworthiness and dominance from a novel voice. However, the majority of findings arise from using only male voices and it is unclear how the pitch of female voices affects judgements of trust and dominance. Here we explore the influence of average vocal pitch on first-impression judgments of perceived trustworthiness and dominance and hypothesise that there will be a preference for low-pitched voices in both genders regardless of judgement. 40 pairs of high- and low-pitched temporally reversed recordings of male and female vocal utterances were presented in a two-alternative forced-choice task to 40 participants.\n\n\n20.2.1.3 Results\n\nVocal pitch has been found to influence judgments of perceived trustworthiness and dominance from a novel voice. However, the majority of findings arise from using only male voices and it is unclear how the pitch of female voices affects judgements of trust and dominance. Here we explore the influence of average vocal pitch on first-impression judgments of perceived trustworthiness and dominance and hypothesise that there will be a preference for low-pitched voices in both genders regardless of judgement.40 pairs of high- and low-pitched temporally reversed recordings of male and female vocal utterances were presented in a two-alternative forced-choice task to 40 participants. Through a series of t-tests and Wilcoxon signed-rank tests, we found a tendency for participants to select the low-pitched voice over the high-pitched voice as more trustworthy, for both genders, and more dominant, for male voices only.\n\n\n20.2.1.4 Implications\n\nVocal pitch has been found to influence judgments of perceived trustworthiness and dominance from a novel voice. However, the majority of findings arise from using only male voices and it is unclear how the pitch of female voices affects judgements of trust and dominance. Here we explore the influence of average vocal pitch on first-impression judgments of perceived trustworthiness and dominance and hypothesise that there will be a preference for low-pitched voices in both genders regardless of judgement. 40 pairs of high- and low-pitched temporally reversed recordings of male and female vocal utterances were presented in a two-alternative forced-choice task to 40 participants. Through a series of t-tests and Wilcoxon signed-rank tests, we found a tendency for participants to select the low-pitched voice over the high-pitched voice as more trustworthy, for both genders, and more dominant, for male voices only. We propose that an overall preference for low pitch is a default prior in male voices irrespective of context, whereas pitch preferences in female voices are more context- and situation-dependent. The present study confirms the important role of vocal pitch in the formation of first-impression personality judgments and advances understanding of the impact of context on pitch preferences across genders.\n\n\n20.2.2 Conclusion\nThis is our advice to learn the key components to include in an abstract. However, you will see a lot of variation in how people approach writing abstracts and standards have changed over time. For example, it was rare to include the sample size of your study, but this is now considered essential to include in the abstract. So, while we recommend looking over abstracts in articles from your literature review to develop a sense of style, try and do so critically as they might not be great examples.",
    "crumbs": [
      "Research and Writing Skills",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Limitations and Structure of the Abstract</span>"
    ]
  },
  {
    "objectID": "07-References.html",
    "href": "07-References.html",
    "title": "References",
    "section": "",
    "text": "Aldoh, A., Sparks, P., & Harris, P. R. (2024). Shifting norms,\nstatic behaviour: Effects of dynamic norms on meat consumption.\nRoyal Society Open Science, 11(6), 240407. https://doi.org/10.1098/rsos.240407\n\n\nAlter, U., Dang, C., Kunicki, Z. J., & Counsell, A. (2024). The\nVSSL scale: A brief instructor tool for\nassessing students’ perceived value of software to learning statistics.\nTeaching Statistics, 46(3). https://doi.org/10.1111/test.12374\n\n\nBoateng, G. O., Neilands, T. B., Frongillo, E. A., Melgar-Quiñonez, H.\nR., & Young, S. L. (2018). Best Practices for\nDeveloping and Validating Scales\nfor Health, Social, and\nBehavioral Research: A\nPrimer. Frontiers in Public Health, 6. https://doi.org/10.3389/fpubh.2018.00149\n\n\nBrown, L., & Holloway, I. (2008). The initial stage of the\ninternational sojourn: Excitement or culture shock? British Journal\nof Guidance & Counselling, 36(1), 33–49. https://doi.org/10.1080/03069880701715689\n\n\nDevito, J. A. (2004). The Interpersonal\nCommunication Book (10th ed.). Pearson\nEducation.\n\n\nLomer, S., & Mittelmeier, J. (2023). Mapping the research on\npedagogies with international students in the UK: A\nsystematic literature review. Teaching in Higher Education,\n28(6), 1243–1263. https://doi.org/10.1080/13562517.2021.1872532\n\n\nLysgaand, S. (1955). Adjustment in a foreign society:\nNorwegian Fulbright grantees visiting the\nUnited States. International Social\nScience Bulletin, 7, 45–51.\n\n\nMichie, S., Stralen, M. M. van, & West, R. (2011). The behaviour\nchange wheel: A new method for characterising and designing\nbehaviour change interventions. Implementation Science,\n6(1), 42. https://doi.org/10.1186/1748-5908-6-42\n\n\nMumford, D. B. (1998). The measurement of culture shock. Social\nPsychiatry and Psychiatric Epidemiology, 33(4), 149–154.\nhttps://doi.org/10.1007/s001270050037\n\n\nOberg, K. (1960). Cultural Shock: Adjustment\nto New Cultural Environments.\nPractical Anthropology, os-7(4), 177–182. https://doi.org/10.1177/009182966000700405\n\n\nRass, O., Fridberg, D. J., & O’Donnell, B. F. (2014). Neural\ncorrelates of performance monitoring in daily and intermittent smokers.\nClinical Neurophysiology, 125(7), 1417–1426.\nhttps://doi.org/https://doi.org/10.1016/j.clinph.2013.12.001\n\n\nSparkman, G., & Walton, G. M. (2017). Dynamic Norms\nPromote Sustainable Behavior,\nEven if It Is\nCounternormative. Psychological Science,\n28(11), 1663–1674. https://doi.org/10.1177/0956797617719950\n\n\nWard, C., Bochner, S., & Furnham, A. (2001). The psychology of\nculture shock (2nd ed.). Routledge.\n\n\nZhou, Y., Jindal-Snape, D., Topping, K., & Todman, J. (2008).\nTheoretical models of culture shock and adaptation in international\nstudents in higher education. Studies in Higher Education,\n33(1), 63–75. https://doi.org/10.1080/03075070701794833",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "04-AIS-01-groupagreement.html#developing-a-credit-statement-for-your-stage-1-report",
    "href": "04-AIS-01-groupagreement.html#developing-a-credit-statement-for-your-stage-1-report",
    "title": "4  Group Work Agreement",
    "section": "\n4.5 Developing a CRediT statement for your stage 1 report",
    "text": "4.5 Developing a CRediT statement for your stage 1 report\nThe CRediT (Contributor Roles Taxonomy) was developed to make individual contribution more visible, reduce disagreements over authorship, and encourage fair contribution (Brand et al., 2015). Since then, it has been adopted by a range of academic publishers as a standard way to describe author contributions, such as Elsevier, Wiley, and Taylor and Francis. For example, Stevenson et al. (2025) includes lecturers from the School of Psychology and Neuroscience and you can see a CRediT statement before the reference list.\nCRediT provides a structured way of describing the specific roles people take on within a project. Each group member’s contributions should be listed under the appropriate categories, and individuals may appear in more than one role. The group shares responsibility for ensuring that these descriptions are accurate and agreed upon by everyone.\nThe CRediT statement should be included on the title page of your report, underneath the list of group members. Each contribution should be identified using student IDs rather than names. This ensures clarity and fairness while keeping the report consistent with submission requirements.\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\nConceptualisation\nIdeas; formulation or evolution of overarching research goals and aims\n\n\nMethodology\nDevelopment or design of methodology; creation of models\n\n\nWriting - Original draft\nCreation and/or presentation of the published work, specifically writing the initial draft (including substantive translation).\n\n\nWriting - reviewing & editing\nPreparation, creation and/or presentation of the published work by those from the original research group, specifically critical review, commentary or revision – including pre- or post-publication stages.\n\n\nProject administration\nManagement and coordination responsibility for the research activity planning and execution.\n\n\n\nNote: This table shows the CRediT categories most relevant for the Stage 1 report. Some categories (e.g., Supervision, Funding acquisition) have been removed because they do not apply at this stage. For the full list of CRediT roles, please see the references above. However, if there are other roles in the CRediT taxonomy that are relevant to your Stage 1 report but not included in this table, please feel free to add them.\n\n4.5.1 Breaking down CRediT roles into specific tasks\nThe CRediT statement is designed to show how each group member has contributed to the Stage 1 report. To make contributions clearer and fairer, we have adapted the standard CRediT roles into smaller, more specific tasks that reflect the work you are doing at this stage (Introduction and Method section only). Use these granular tasks as a guide when assigning roles, and feel free to adapt them further if it better reflects your group’s work.\nConceptualisation\n\nContributing ideas for the research question or hypothesis\n\nRefining aim(s) or hypothesis\n\nSuggesting relevant literature, theories, or frameworks\n\nSearching for and selecting background literature\n\nSummarising and evaluating relevant research\n\nCollating references into a reference list (APA 7th edition format)\n\nMethodology\n\nDeciding the content for the Participants, Materials, Procedure, or Design and Data Analysis\n\nWriting - Original draft\n\nWriting the Introduction section (specify component(s) if applicable, such as rationale, hypothesis, etc.)\nWriting the Method section (specify which component(s) if applicable, such as participants, procedure, etc.)\n\nWriting - reviewing & editing\n\nReviewing and revising drafts written by group members\n\nEditing for clarity, structure, and flow\n\nChecking APA style and formatting consistency\n\nProject administration\n\nOrganising meetings and keeping meeting notes\n\nManaging deadlines\n\nAllocating tasks within the group\n\nSubmitting the final report\n\n4.5.2 What will your group do?\nStep 1. Learn the roles\n\nReview the adapted CRediT categories listed above, including the granular tasks (e.g., Conceptualisation – suggesting relevant literature, Methodology – deciding content for participants/procedure/design, Writing – Introduction/Method, Writing – Review & Editing, Project Administration – organising meetings).\n\nStep 2. Discuss contributions\n\nDiscuss who is responsible for each role, or who has already contributed to the Stage 1 report submission.\nBe fair and honest. Keep in mind that some members may be listed under more than one role.\n\nStep 3. Assign roles\n\nDecide which member, identified by their student ID, should be listed under each chosen role.\n\nStep 4. Write the CRediT statement\n\nOn your title page, include a section titled “CRediT authorship contribution statement”. In the template we provide on Moodle, we have already included a CRediT section for you to complete.\nWrite the CRediT statement based on the roles you selected and the contributions of your group members.\n\n4.5.3 Example of a CRediT statement\nExample 1\nID 12345678: Conceptualisation (literature search and summarising), Methodology (deciding content for Participants and Procedure), Writing – Original Draft (writing the Introduction section), Writing – Review & Editing (editing for clarity, structure, and flow).\nID 23456789: Writing – Original Draft (writing the Method section), Writing – Review & Editing (checking APA style and formatting consistency).\nID 34567891: Conceptualisation (contributing ideas for the research question or hypothesis), Methodology (deciding the content for the Materials and Design and Data Analysis).\nID 45678912: Writing – Original Draft (writing the Method section – Procedure).\nExample 2 (with degree of contribution)\nID 12345678: Conceptualisation (lead: literature search and summarising); Methodology (lead: deciding content for Participants and Procedure); Writing – Original Draft (equal: writing the Introduction section); Writing – Review & Editing (equal: editing for clarity, structure, and flow).\nID 23456789: Writing – Original Draft (lead: writing the Method section); Writing – Review & Editing (equal: checking APA style and formatting consistency).\nID 34567891: Conceptualisation (supporting: contributing ideas for the research question/hypothesis); Methodology (supporting: deciding content for the Materials, Design, and Data Analysis).\nID 45678912: Writing – Original Draft (equal: writing the Method section – Procedure).\nNotes on levels of contribution: The levels of contribution (Lead, Equal, Supporting) are only suggestions to help you decide how to describe your group’s work. Use them if they are useful for clarifying contributions, but you do not have to apply them to every task.\n\nLead: You took primary responsibility for this role or task.\nEqual: You shared responsibility equally with one or more group members.\nSupporting: You contributed but another group member had primary responsibility.",
    "crumbs": [
      "Assessment and Feedback Information",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Group Work Agreement</span>"
    ]
  }
]